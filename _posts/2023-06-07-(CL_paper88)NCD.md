---
title: (paper 88) Novel Class Discovery; an Introduction and Key Concepts
categories: [CV, CL, SEMI]
tags: []
excerpt: 2023
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
# Novel Class Discovery: an Introduction and Key Concepts

<br>

## Contents

0. Abstract
1. Introduction
   


<br>

# 0. Abstract

Novel Class Discovery (NCD)

- **labeled set** of **KNOWN classes** & **unlabeled set** of **UNKNOWN classes**

<br>

Comprehensive survey of the NCD

- (1) Define the NCD problem

- (2) Overview of the different families of approaches

  - By how they transfer knowledge from the labeled $\rightarrow$ unlabeled

    ( either learn in 2 stages )

    - (1) Extracting knowledge from the labeled data only & applying it to the unlabeled data
    - (2) Conjointly learning on both sets.

- (3) Introduce some new related tasks 

- (4) Present some common tools and techniques used in NCD

  - ex) pseudo labeling, SSL, CL

<br>

# 1. Introduction

**Real World Problems** : 

$\rightarrow$ Not always possible to have labeled data for all classes of interest

<br>

Open-world Assumption

- Instances outside the initial set of classes may emerge

<br>

![figure2](/assets/img/cv/img401.png)

- Instances from classes **never seen during training** appear at test time
- Ideal model : should classify all cases!

<br>

### What is the issue?

Standard classification model

- incorrectly classify instances that fall outside the known classes as belonging to one of the known classes. 

  $\rightarrow$ produce overconfident incorrect predictions

Researchers are now exploring scenarios where unlabeled data is also available 

<br>

Setting of this paper :

where a labeled set of known classes and an unlabeled set of unknown classes are given during training. 

<br>

Goal : learn to categorize the unlabeled data into the appropriate classes. 

$\rightarrow$ "Novel Class Discovery (NCD)"

<br>

### What is the usual setup of NCD?

![figure2](/assets/img/cv/img402.png)

Training data

- (1) from known classes
- (2) from unknown classes

Test set :

- only samples from unknown classes. 

<br>

NCD scenario belongs to Weakly Supervised Learning

- manage classes that have never appeared during training
- ex) Open-World Learning (OWL)
- ex) Zero-Shot Learning (ZSL)

<br>

Open-World Learning (OWL)

- seek to accurately label samples of classes seen during training, 

  while identifying samples from unknown classes. 

- BUT not tasked with clustering the unknown classes 

  ( + unlabeled data is left unused )

<br>

Zero-Shot Learning (ZSL)

- designed to accurately predict classes that have never appeared during training.

  ( still… some kind of description of these unknown classes is needed to be able to recognize them )

$\leftrightarrow$ NCD has recently gained significant attention due to its practicality and real-world applications.

<br>

### Why does clustering alone fail to produce good results?

Clustering is a direct solution to the NCD problem

Many clustering methods have obtained an accuracy larger than $90 \%$ on the MNIST dataset

( $\leftrightarrow$ but not in complex datasets ) 

<br>

Clustering can fail due to the assumptions of…

- spherical clusters, mixture of Gaussian distributions, shape of the data, similarity measure, etc. 

<br>

![figure2](/assets/img/cv/img403.png)

- Although the clusters formed in this manner will be statistically accurate,

  the semantic categories will not be revealed!

<br>

Need for more refined techniques that can extract from known classes a relevant representation of a class in order to improve the clustering process.

<br>

### To fill these gaps

Novel Class Discovery 

- identify new classes in unlabeled data by exploiting prior knowledge from known classes. 

- key idea )

  - by having a set of known classes, should be able to improve its performance by extracting a general concept of what constitutes a good class. 

  - assumed that the model does not need to be able to distinguish the known from the unknown classes. 

    ( $\leftrightarrow$ Generalized Category Discovery (GCD) )

<br>

Difficulty of a NCD problem :

$\rightarrow$ is set by varying the number of known/unknown classes

- increase in known class = EASIER task

<br>

Influence of the semantic similarity between 

- (1) classes of the labeled sets
- (2) classes of the unlabeled sets

$\rightarrow$ if HIGH similarity, EASIER task

( + LOW semantic similarity : can even have a negative impact )

<br>

### Contributions and Organization

Detailed overview of Novel Class Discovery

Outline the key components present in most NCD methods

- organized by the way they transfer knowledge from the labeled to the unlabeled set. 

Related works in the context of NCD

<br>

# 2. Preliminaries

![figure2](/assets/img/cv/img404.png)

<br>

## (1) A brief history of NCD

2018 article of Hsu et al. [5] 

- transfer learning task where the labels of the target set are not available and must be inferred. 
- methosd : KCL & MCL
  - still regularly used

<br>

"Novel Category Discovery"

- used by Han et al. [18] in 2020
- on this work, Zhong et al. defined "Novel Class Discovery”

<br>

## (2) A formal definition of NCD

During training, the data is provided in two distinct sets, a 

Notation

- labeled set $D^l=\left\{\left(x_i^l, y_i^l\right)\right\}_{i=1}^N$ 
- unlabeled set $D^u=\left\{x_i^u\right\}_{i=1}^M$. 

<br>

Goal : use both $D^l$ and $D^u$ to discover the $C^u$ novel classes

- **usually done by partitioning $D^u$ into $C^u$ clusters and associating labels $y_i^u \in \mathcal{Y}^u=\left\{1, \ldots, C^u\right\}$ to the data in $D^u$.**

<br>

Settings

- No overlap between the classes of $\mathcal{Y}^l$ and $\mathcal{Y}^u$ ( $\mathcal{Y}^l \cap \mathcal{Y}^u=\emptyset$. )
- Not concerned with the accuracy on the classes of $D^l$, 
- Most works : the number of novel classes $C^u$ is assumed to be KNOWN
  - some works attempt to estimate this number.

<br>

## (3) Positioning and key concepts of NCD

![figure2](/assets/img/cv/img405.png)

( Open World Learning is reviewed in Section 6.4 but does not appear in this figure. )

<br>

## (4) Evaluation protocol & metrics in NCD



How to set **unlabeled dataset** ??

- hold out during the training phase a portion of the classes ( from a fully labeled dataset )

  $\rightarrow$ treat them as novel classes & form the unlabeled dataset $D^u$.

- ex) MNIST

  - 0~4 : known classes
  - 5~9 : unknown classes

<br>

Performance metrics

-  only computed on $D^u$

<br>

### a) Clustering accuracy (ACC)

- requires to optimally map the predicted labels to the groundtruth labels

  ( $\because$  cluster numbers won't necessarily match the class numbers )

- can be obtained with the the **Hungarian algorithm**

<br>

$A C C=\frac{1}{M} \sum_{i=1}^M \mathbb{1}\left[y_i^u=\operatorname{map}\left(\hat{y}_i^u\right)\right]$.

- $\operatorname{map}\left(\hat{y}_i^u\right)$ : the mapping of the predicted label for sample $x_i^u$ 
- $M$ : number of samples in the unlabeled set $D^u$.

<br>

### b) Normalized mutual information (NMI)

- correspondence between the predicted and ground-truth labels
- invariant to permutations

<br>

$N M I=\frac{I\left(\hat{y}^u, y^u\right)}{\sqrt{H\left(\hat{y}^u\right) H\left(y^u\right)}}$.

- $I\left(\hat{y}^u, y^u\right)$ : mutual information between $\hat{y}^u$ and $y^u$
- $H\left(y^u\right)$ and $H\left(\hat{y}^u\right)$ : marginal entropies of the empirical distributions of $y^u$ and $\hat{y}^u$ respectively.

<br>

### c) Summary

Both ACC & NMI : range between 0 and 1

- closer to 1, the better

<br>

Other metrics

- Balanced Accuracy (BACC) and the Adjusted Rand Index (ARI). 

  - BACC : for imbalanced class distribution

    ( = calculated as the average of sensitivity and specificity )

  - ARI : normalized measure of agreement between the predicted clusters & GT

    ( ranges from -1 ~ 1 …. 0 = random clustering )

<br>

# 3. Taxonomy of NCD methods

![figure2](/assets/img/cv/img406.png)

In this section, NCD works are organized by the way in which they transfer knowledge from the labeled set $D^l$ to the unlabeled set $D^u$. Also identified by [22], and [23], NCD methods adopt either a oneor two-stage approach. An overview of the methods that are studied in this section is provided in Table 2, along with a brief description of their contributions.

The first NCD works published were generally two-stage approaches, so they are described here first. They tackle the NCD problem in a way similar to cross-task Transfer Learning (TL) methods. They first focus on $D^l$ only (like a source dataset in TL) before exploring $D^u$ (similarly to a target dataset without labels in TL). Within this category, two families of methods can be distinguished: one uses $D^l$ to learn a similarity function, while the other incorporates the features relevant to the classes of $D^l$ into a latent representation.

More recent methods adopt one-stage approaches and process $D^l$ and $D^u$ simultaneously through a shared objective function. All the one-stage methods reviewed here work in a similar manner, where a latent space shared by $D^l$ and $D^u$ is trained by two classification networks with different objectives. These objectives usually include clustering the unlabeled data and maintaining good classification accuracy on the labeled data.
