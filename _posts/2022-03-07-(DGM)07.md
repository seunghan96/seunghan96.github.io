---
title: \[Explicit DGM\] 07. Variants of VAE with Elaborated Losses (2)
categories: [GAN]
tags: [GAN]
excerpt: KAIST 문일철 교수님 강의 참고
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# [Explicit DGM] 07. Variants of VAE with Elaborated Losses (2)

( 참고 : KAIST 문일철 교수님 : 한국어 기계학습 강좌 심화 2)

<br>

## Contents

1. Over-regularized problem with VAE prior
2. Learning in Implicit Model
2. ELBO learning with NN Implicit Prior
2. Summary

<br>

# 1. Over-regularized problem with VAE prior

## (1) Introduction 

지금까지 우리가 사용하던 prior ( $$p_{\lambda}(h)$$ )로, 단순히 표준정규분포에서 샘플하는 것과 같은 간단한 분포였다.

하지만, 우리가 가지고 있는 data distribution $$p_D(e)$$를 사용하여, 보다 나은 optimal한 prior를 설정할수는 없을까?

<br>

ELBO : $$\mathcal{L}(e ; \phi, \theta)=\mathbb{E}_{q_{\phi}(h \mid e)}\left[\log p_{\theta}(e \mid h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p_{\theta}(h)\right)$$

Objective : $$\max _{\phi, \theta} \int p_{D}(e) \mathcal{L}(e ; \phi, \theta) d e$$

<br>

## (2) Optimal Prior

위 objective를 maximize하는 최적의 prior를 구해보자.

$$\begin{aligned}
p_{\lambda}^{*}(h)&=\operatorname{argmax}_{p_{\lambda}(h)} \int p_{D}(e) \mathcal{L}(e ; \phi, \theta) d e \\
&=\operatorname{argmax}_{p_{\lambda}(h)} \int p_{D}(e)\left\{-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p_{\lambda}(h)\right)\right\} d e \\
&=\operatorname{argmax}_{p_{\lambda}(h)} \int p_{D}(e)\left\{-\int q_{\phi}(h \mid e) \ln \frac{q_{\phi}(h \mid e)}{p_{\lambda}(h)} d h\right\} d e \\&=\operatorname{argmax}_{p_{\lambda}(h)} \int p_{D}(e) \mathbb{E}_{q_{\phi}(h \mid e)}\left[\ln p_{\lambda}(h)\right] d e \\
&=\operatorname{argmax}_{p_{\lambda}(h)} \int\left\{\int p_{D}(e) q_{\phi}(h \mid e) d e\right\} \ln p_{\lambda}(h) d h \\&=\operatorname{argmax}_{p_{\lambda}(h)}-H\left(\int p_{D}(e) q_{\phi}(h \mid e) d e, p_{\lambda}(h)\right)
\end{aligned}$$.

<br>

마지막 식의 cross entropy ($$H$$) term에서, $$P=Q$$일때 maximum이 된다는 것을 알 수 있다.

이는 곧, 아래의 식이 **최적의 prior**라는 것을 의미한다.

- $$p_{\lambda}^{*}(h)=\int p_{D}(e) q_{\phi}(h \mid e) d e \equiv q_{\phi}(h)$$.

<br>

## (3) Optimal prior ELBO

[ELBO 비교] 일반 VAE vs Optimal prior VAE

- (일반 VAE) 
  - $$\mathcal{L}(e ; \phi, \theta)=\mathbb{E}_{q_{\phi}(h \mid e)}\left[\log p_{\theta}(e \mid h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p_{\theta}(h)\right)$$.
    - 여기서, regularization term ( KL-d term ) $$D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p_{\theta}(h)\right)$$는 closed form으로 계산 가능
- (Optimal prior VAE)
  - $$\mathcal{L}(e ; \phi, \theta)=\mathbb{E}_{q_{\phi}(h \mid e)}\left[\log p_{\theta}(e \mid h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  q_{\phi}(h)\right)$$.
    - 반면에, 여기서의 $$D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  q_{\phi}(h)\right)$$ 는 closed form 계산 불가

<br>

$$\begin{aligned}  D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  q_{\phi}(h)\right) & =E_{q_{\phi}(h \mid e)}\left[\ln \frac{q_{\phi}(h \mid e)}{q_{\phi}(h)}\right] \\&=\int q_{\phi}(h \mid e) \ln \frac{q_{\phi}(h \mid e) p_{\theta}(h)}{q_{\phi}(h) p(h)} d h\\&=\int q_{\phi}(h \mid e) \ln \frac{q_{\phi}(h \mid e)}{p(h)} d h+\int q_{\phi}(h \mid e) \ln \frac{p(h)}{q_{\phi}(h)} d h \\&=D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p(h)\right)-\mathbb{E}_{q_{\phi}(h \mid e)}\left[\ln \frac{q_{\phi}(h)}{p(h)}\right]\end{aligned}$$.

<br>

위 정리된 식을 보면, **Optimal prior VAE의 ELBO는, 일반 VAE의 ELBO에 “expected density ratio”가 더해진 형태**임을 알 수 있다!

- $$\mathbb{E}_{q_{\phi}(h \mid e)}\left[\ln \frac{q_{\phi}(h)}{p(h)}\right]$$ : expected density ratio

  ( between model & variational distn )

<br>

# 2. Learning in Implicit Model

$$\mathbb{E}_{q_{\phi}(h \mid e)}\left[\ln \frac{q_{\phi}(h)}{p(h)}\right]$$ : **expected density ratio**

$$\rightarrow$$ 이는, “data distn” & “variational distn”에서 나오는 데이터들을 구분하는 classifier를 학습시킴으로써 계산할 수 있다.

( 우리는 이 값을 maximize해야 한다. )

<br>

### Notation

- ( data distn ) $$E_{p}=\left\{e_{1}^{(p)}, \ldots, e_{n}^{(p)}\right\}$$ $$\sim$$ $$p(h)$$

- ( variational distn ) $$E_{q}=\left\{e_{1}^{(q)}, \ldots, e_{n}^{(q)}\right\}$$ $$\sim$$ $$q_{\phi}(h)$$

- 새롭게 도입한 random variable $$y$$
  - $$E_{p}$$ 샘플은 $$y=0$$ ………. $$p(h)=p(h \mid y=0)$$
  - $$E_{q}$$ 샘플은 $$y=1$$ ……….. $$q_{\phi}(h)=p(h \mid y=1)$$
- $$p^{*}(h \mid y) \equiv\left\{\begin{array}{c}q_{\phi}(h), y=1 \\ p(h), y=0\end{array}\right.$$.

<br>

위 Notation을 활용하여, (log) density ratio ( $$r(\boldsymbol{h})=\ln \frac{q_{\phi}(h)}{p(h)}$$ )를 아래와 같이 정리할 수 있다.

$$\frac{q_{\phi}(h)}{p(h)}=\frac{p^{*}(h \mid y=1)}{p^{*}(h \mid y=0)}=\frac{\frac{p^{*}(h, y=1)}{p^{*}(y=1)}}{\frac{p^{*}(h, y=0)}{p^{*}(y=0)}}=\frac{\frac{p^{*}(y=1 \mid h) p^{*}(h)}{p^{*}(y=1)}}{\frac{p^{*}(y=0 \mid h) p^{*}(h)}{p^{*}(y=0)}}=\frac{p^{*}(y=1 \mid h)}{p^{*}(y=0 \mid h)} \cdot \frac{\pi}{1-\pi}=\frac{p^{*}(y=1 \mid \boldsymbol{h})}{p^{*}(y=0 \mid \boldsymbol{h})}=\frac{D(h)}{1-D(h)}$$.

( GAN과의 연관성이 보인다!! )

- $$D(h)=p^{*}(y=1 \mid h)$$,

<br>

이를 통해 density ratio estimation은 **class probability estimation**과 동일한 형태임을 알 수 있다.

( = $$p(y=1 \mid h)$$를 계산하는 문제와 동일 )

따라서, 데이터가 어느 분포에서왔는지 잘 예측하는 discriminator를 잘 학습하면, 최적의 prior를 찾게된다는 것을 알 수 있다.

<br>

# 3. ELBO learning with NN Implicit Prior

우리는, latent variable $$h$$ 가 주어졌을 때, $$y=1$$ 로 예측하는 classifier $$D(h)=p^{*}(y=1 \mid h)$$를 만들면 된다.

이를 위해, 또 다른 NN classifier를 도입한다.

- $$D(h)=\sigma\left(T_{\psi}(h)\right)$$.

<br>

$$T_{\psi}(h)$$를 학습시키는 목적함수는 다음과 같다.

- $$T^{*}(h)=\max _{\psi} \mathbb{E}_{q_{\phi}(h)}\left[\ln \left(\sigma\left(T_{\psi}(h)\right)\right)\right]+\mathbb{E}_{p(h)}\left[\ln \left(1-\sigma\left(T_{\psi}(h)\right)\right)\right]$$.
- 해석 : 
  - $$p$$에서 나온 데이터에 대해서는 $$\sigma\left(T_{\psi}(h)\right)$$가 0이 되도록
  - $$q$$에서 나온 데이터에 대해서는 $$\sigma\left(T_{\psi}(h)\right)$$가 1이 되도록

<br>

Density ratio는 아래와 같이 정리될 수 있다.

- $$ \frac{q_{\phi}(h)}{p(h)}=\frac{D(h)}{1-D(h)}=\frac{\sigma\left(T^{*}(h)\right)}{1-\sigma\left(T^{*}(h)\right)}$$.

<br>

위식을 정리하면, 우리는 아래와 같은 결론을 내릴 수 있다.

$$\sigma\left(T^{*}(h)\right)=\frac{1}{1+\exp \left(-T^{*}(h)\right)}=\frac{q_{\phi}(h)}{p(h)+q_{\phi}(h)}$$.

$$\rightarrow p(h)=q_{\phi}(h) \exp \left(-T^{*}(h)\right)$$.

$$\rightarrow T^{*}(h)=\ln \frac{q_{\phi}(h)}{p(h)}$$.

<br>

지금까지 다룬 내용들을 사용하여, **optimal prior VAE의 ELBO**를 정리하면 아래와 같다.

$$\begin{aligned}
\mathcal{L}(e ; \phi, \theta)&=\mathbb{E}_{q_{\phi}(H \mid E)}\left[\log p_{\theta}(e \mid h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  q_{\phi}(h)\right) \\
&=\mathbb{E}_{q_{\phi}(H \mid E)}\left[\log p_{\theta}(e \mid h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p(h)\right)+\mathbb{E}_{q_{\phi}}(H \mid E)\left[\ln \frac{q_{\phi}(h)}{p(h)}\right] \\
&=\mathbb{E}_{q_{\phi}(H \mid E)}\left[\log p_{\theta}(e \mid h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p(h)\right)+\mathbb{E}_{q_{\phi}(H \mid E)}\left(T^{*}(h)\right] \\
&=\mathbb{E}_{q_{\phi}(H \mid E)}\left[\log p_{\theta}(e \mid h)+T^{*}(h)\right]-D_{K L}\left(q_{\phi}(h \mid e)  \mid \mid  p(h)\right)
\end{aligned}$$.

- (before) $$\mathbb{E}_{q_{\phi}(H \mid E)}\left[\log p_{\theta}(e \mid h)\right]$$
- (after) $$\mathbb{E}_{q_{\phi}(H \mid E)}\left[\log p_{\theta}(e \mid h)+T^{*}(h)\right]$$

이 expectation 값은, $$\phi, \theta$$와 $$\psi$$ 를 교대로 학습함으로써  ( + reparam trick 사용해서 ) 계산할 수 있다.

<br>

# 4. Summary

지금까지 다뤘던 모든 내용들은 **explicit**한 structure였다. 

즉, 분포를 가정하고, 해당 분포의 파라미터를 추정하는 방식이었다.

이는 데이터를 설명하고, hidden representation을 해석하는데에 있어서 유용한 방식이기는 하나, “데이터 생성/샘플링”의 관점에서는, (분포에 대한 가정이라는) 규제 때문에 최선이라고 할 수 없다.



다음에는, GAN으로 대표되는 **implicit model**에 대해서 알아볼 것이다.
