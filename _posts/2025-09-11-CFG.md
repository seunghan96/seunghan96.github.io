---
title: Classifier-Free Guidance
categories: [DIFF, MULT, CV]
tags: []
excerpt: 
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# Classifier-Free Guidance

## Contents

1. 직관
2. 수식
3. Example
4. 해석
5. 장/단점
6. Variants & Extensions

<br>

# **1. 직관 (Intuition)**

- **문제**: Diffusion model은 기본적으로 조건부 생성(예: text-to-image)을 할 수 있음

  $$\rightarrow$$ 다만, **조건을 강하게 따르게 만들기가 쉽지 않음**!!

  - 너무 강하면 품질이 떨어지고
  - 너무 약하면 조건이 잘 반영되지 않음

- **해결**: Classifier-free guidance (CFG)는 

  - **conditional prediction**과 

  - **unconditional prediction**을 

    함께 사용해서, 조건을 더 “강조”할 수 있게 만든 기법!

- **핵심 아이디어**: 모델이 예측한 두 가지 noise 분포를 섞음

  - 조건 없는 (no condition) 예측
  - 조건 있는 (with condition) 예측

  $$\rightarrow$$ ***"둘의 차이"***를 이용해 조건을 강조하는 방향으로 샘플링을 유도.

<br>

# **2. 수식 (Formulation)**

## (1) Diffusion model

Diffusion model은 step $$t$$에서 noise를 예측:

- $$\epsilon_\theta(x_t, t, c)$$.

  - $$x_t$$: Noisy sample at step $$t$$

  - $$c$$: 조건 (예: text prompt), 없으면 $$\varnothing$$

<br>

## (2) CFG 공식

$$\hat{\epsilon}_\theta(x_t, t, c) = \epsilon_\theta(x_t, t, \varnothing) + w \cdot \left( \epsilon_\theta(x_t, t, c) - \epsilon_\theta(x_t, t, \varnothing) \right)$$.

- $$\epsilon_\theta(x_t, t, \varnothing)$$: **"Unconditional"** prediction
- $$\epsilon_\theta(x_t, t, c)$$: **"Conditional"** prediction
- $$w$$: Guidance scale (보통 5~10 사용)

<br>

# 3. Example

조건 (prompt): *“a cat wearing sunglasses”*

- Unconditional 예측: 그냥 **“동물 모양”**에 가까운 fuzzy noise 제거
- Conditional 예측: **“고양이 + 선글라스”** 형태의 구체적인 noise 제거 방향

최종 guidance 예측: 

- **"Unconditional"** 결과에 **"conditional"** 방향을 $$w$$배 강화

<br>

$$w$$의 효과

- $$w=0$$: 조건 무시 (unconditional)
- $$w=1$$: 보통 conditional 결과
- $$w$$ 클수록: 조건을 더 강하게 반영하지만, 너무 크면 artifacts 발생

<br>

# 4. 해석

CFG는 결국 **벡터 보정**!

- $$\epsilon_\theta(x_t, t, c) - \epsilon_\theta(x_t, t, \varnothing)$$ 는 ***“조건이 추가되었을 때 방향 벡터”***라고 볼 수 있음.

- 즉, unconditional noise 제거 방향에서 → conditional 방향으로 ***“얼마나 가야 하는지”***를 보여주는 **gradient-like 신호**.

<br>

CFG는 unconditional 결과에 이 벡터를 $$w$$배 만큼 더해줌:

- [작은 $$w$$] conditional과 unconditional의 차이를 조금만 반영 

  → 조건이 잘 안 드러남.

- [큰 $$w$$] 차이를 크게 반영 

  → 조건을 강하게 따르지만, 분포의 모드(mode)를 벗어나서 비현실적인 샘플(artifact)이 늘어남

<br>

Summary

- **조건 없는 결과 + (조건 있는 결과 - 조건 없는 결과) × w**.
  - 즉, **조건을 반영하는 차이 벡터를 강조**해서 샘플링을 더 조건에 맞게 끌어가는 방법.
- 간단하지만, diffusion 모델이 text prompt나 label 같은 조건을 더 잘 따르게 만들어주는 **핵심 트릭**!

<br>

# 5. 장/단점

장점

- (1) **추가 모델 불필요**

  - classifier guidance처럼 별도의 분류기(classifier)를 학습할 필요가 없음.

  - diffusion 모델 하나만 학습해도 CFG를 적용할 수 있음.

- (2) **간단함**
  - 단순히 두 번 forward pass 해서 noise prediction을 섞어주면 됨.

- (3) **효과적**
  - 특히 text-to-image에서 prompt alignment가 크게 개선됨.

단점

- (1) **추가 연산량**
  - conditional + unconditional 두 번 inference가 필요 → 계산량 2배.
- (2) **과도한 w 사용 시 품질 저하**
  - 이미지가 부자연스럽거나 artifact 발생.

- (3) **모든 조건에 효과적인 건 아님**
  - prompt가 너무 모호하거나, 학습 데이터에 없는 개념이면 guidance scale을 높여도 원하는 결과가 안 나올 수 있음.

<br>

# 6. Variants & Extensions

- **Dynamic CFG**

  - step마다 다른 $$w_t$$ 값을 사용 (예: 초반은 낮게, 후반은 크게).
  - 조건을 점진적으로 강화하여 안정성과 정합성을 둘 다 확보!

- **Classifier Guidance vs. Classifier-Free Guidance**

  - Classifier Guidance: external classifier $$p(c\mid x)$$ gradient 사용.
  - CFG: 분류기 대신 unconditional 모델 출력으로 대체 → **classifier-free**.

- **Guidance in other modalities**

  - 텍스트 생성, 오디오 생성 등 다른 diffusion 기반 생성에도 동일 원리로 적용 가능.
  - 조건(prompt, style, emotion 등)에 따라 unconditional/conditional 차이를 강조.

- **CFG++ / Guidance Distillation**

  - inference 시 두 번 forward pass 대신, 

    미리 guidance 효과를 distill해서 한 번에 생성할 수 있는 연구



