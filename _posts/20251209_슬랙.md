아래의 문제들은 해결되었는가? 

- (1) 중복: O
  - 해결 방식: 추출하면서 중복 체크하기
- (2) 누락: O
  - 특별히 누락이 되는 이슈가 없었음
- (3) 예상 소요시간의 정확성
  - Progress bar는 현재 시간을 제대로 측정못하고 있음.
  - 분수의 분자가 a)가 아니라 b)여야 정확한 시간 측정하는 꼴
  - a) `f"[PROGRESS] {done}/{total} "`
  - b) `f"[PROGRESS] {processed_user_matches}/{total} "`

- (4) ㅇ



기타: 다양한 C의 개수 (=feature/channel의 개수)로 Training을 진행 중

- Caching 이슈 X: C=20,30,40,50,60
- Caching 이슈 O: C=167 (전부 사용한 버전)

<br>

정확히 아래의 코드에서 죽음: `data_factory.py`

- X_train.shape (192027, 167, 2100) 
- X_val.shape (10633, 167, 2100) 
- X_test.shape (10677, 167, 2100)

```os.makedirs(cache_file, exist_ok=True)
np.save(os.path.join(cache_file, 'X_train.npy'), X_train)
np.save(os.path.join(cache_file, 'y_train.npy'), y_train)
np.save(os.path.join(cache_file, 'X_val.npy'), X_val)
np.save(os.path.join(cache_file, 'y_val.npy'), y_val)
...
```

해결 방안: 

- (1) caching을 안하는 방법 
- (2) 여러개로 나눠서 caching



하지만, 현재 C=20,30,40,50,60에 대해서 진행 중이고, 

이에 대한 labeled test set의 F1 score은 전부 비슷한 상황. (물론 EBR은 다를 수 있음. 현재 아직 측정은 안해봤지만)

따라서, C=20~60에 대해서 우선 EBR을 측정을 해본 뒤, 그 성능을 봐서 C=167까지 해볼 필요가 있는지 체크해보는 것도 방안!

