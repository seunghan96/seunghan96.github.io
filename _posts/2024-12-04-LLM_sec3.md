---
title: (LLM 교재) 3.프롬프트 엔지니어링의 첫 번째 단계
categories: [LLM, NLP]
tags: []
excerpt: 쉽고 빠르게 익히는 실전 LLM
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# 프롬프트 엔지니어링의 첫 번째 단계

쉽고 빠르게 익히는 실전 LLM (https://product.kyobobook.co.kr/detail/S000212147276)

<br>

## Contents

- 3-1. Introduction

- 3-2. Prompt Engineering

- 3-3. 여러 모델과 프롬프트 작업하기

- 3-4. ChatGPT와 Q/A 챗봇 만들기

- 3-5. 요약

<br>

# 1. Introduction

(2장: LLM) 쿼리를 통해 관련 문서를 빠르게 찾을 수 있는 **"비대칭 의미 기반 검색 시스템"**을 구축

$$\rightarrow$$ But, 단순히 검색으로 끝나서는 안됨!

<br>

(User experience 향상시키기 위해) ***End-to-End LLM 기반***의 application을 생성해야!

$$\rightarrow$$ Necessity of ***PROMPT ENGINEERING***!!

<br>

# 2. 프롬프트 엔지니어링 (Prompt Engineering)

Prompt Engineering이란?

- 효과적으로 작업을 전달하여,

- **정확하고 유용한 출력**을 반환하도록 유도하는

- **LLM에 대한 입력(프롬프트)**를 만드는 것!

<br>

한 줄 요약: ***원하는 output을 위해 LLM에 input을 구성하는 방법***

<br>

## 1) LLM에서 정렬 (Alignment)

중요성: (LLM이 어떻게 학습되는지 뿐만 아니라) ***LLM이 "어떻게 사람의 입력에 정렬 (alignment)"되는지*** 알아야!

<br>

***Alignment?***

- 모델이 (사용자가 예상한것과 일치하는 방식으로) **입력 프롬프트를 이해**하고 답변하는 것!
- if not, 관련 없거나 잘못된 답변 생성!

<br>

(최근) **정렬 기능과 함께** 개발되는 LLM

- ex) Anthropic의 RLAIF (Constitutional AI-driven Reinforcement Learning from AI Feedback)
- ex) OpenAI의 GPT 계열: RLHF (Reinforcement Learning from Human Feedback)

$$\rightarrow$$ 이러한 정렬 기술은, **특정 프롬프트를 이해하고 답변하는 모델의 능력을 향상**시킴!

<br>

## 2) 직접 요청하기

Prompt engineering의 가장 중요한 규칙: ***요청하는 내용이 최대한 "명확" + "직접적""이어야***

더 명확한 LLM의 답변을 위해, "접두사를 추가"하여 명확하게 표시할 수 있음.

<br>

## 3) Few-shot Learning

작업에 대한 깊은 이해가 필요한 **복잡한 작업**의 경우, **몇 개의 예제**를 LLM에 제공해주면 더 도움이 될 것!

$$\rightarrow$$ LLM이 (일부의 예제를 바탕으로) **추론할 수 있게 될 것!**

<br>

## 4) 출력 구조화

LLM이 너무 지저분/다양한 형식으로 출력한다면?

$$\rightarrow$$ 어느 정도 ***구조화*** 하는 것이 좋음! (e.g., **JSON 형식**으로)

<br>

구조화 되어야, 개발자가 "특정 정보를 더 쉽고/간단하게 추출"할 수 있을 것!

<br>

### 5) 페르소나 지정하기

단어 하나하나에 의해 출력값은 큰 영향을 받음!

따라서, 연구자/실무자는 "LLM을 위한 페르소나"를 만들어줌!

( e.g., 특정 주제, 스타일, 캐릭터 등 )

<br>

예시) 

- 너는 지금부터 **금융 상담원**이야 + query
- 너는 **건방진 상담원**이야 + query

<br>

주의) 페르소나는 항상 긍정적인 목적으로만 사용되는 것은 아님!

$$\rightarrow$$ 윤리성 강화를 위해서 사용될 수도! (잠재적 나쁜말 필터링)

<br>

# 3. 여러 모델과 프롬프트 작업하기

Prompt: LLM의 아키텍처/학습에 따라 크게 달라짐

$$\rightarrow$$ 일부 Prompt는 모델 간에 이전 될 수도 or 재설계해야할 수도!

<br>

이번 섹션: 각 LLM 고유의 특징을 고려하여 효과적인 prompt 개발하기!

<br>

## 1) ChatGPT

일부의 LLM (e.g., ChatGPT) 은, 

- 하나의 "프롬프트"만 받는 것이 아니라
- '시스템','사용자','어시스턴트' 프롬프트를 받을 수 있음

<br>

### 시스템 프롬프트 (System prompt)

역할: 대화의 일반적인 지침을 나타냄

- e.g., "당신은 친절하고 도움이 되는 챗봇입니다"

<br>

### 사용자 & 어시스턴트 프롬프트

- 사용자 & 언어 모델 간의 메세지

<br>

### 2) Cohere

예시: Cohere는 아래와 같이 "English:", "Turkish:"등의 구조화된 지시사항을 필요로 한다

```
Translate to Turkish

English: Where is the nearset restaurant
Turkish:
```

<br>

### 3) 오픈소스 프롬프트 엔지니어링

오픈소스 모델 예시

- GPT-J, FLAN-T5

이러한 모델을 사용할 때, prompt engineering은 pretrain/fine-tune을 최대한 활용하기 위해 매우 중요한 단계!

Closed source 모델과는 다르게, 더 큰 유연성/제어기능 제공하므로, 이용자/개발자가 fine-tuning 중 prompt를 맞춤화하여 출력을 특정 사용 사례에 맞게 조정할 수 있음!

<br>

모델에 대한 파악이 선행되어야!

- ex) GPT-J: Autoregressive-LM이므로, 
  - 직접적인 지시 프롬프트 보다는 
  - few-shot prompt가 더 잘 작동함

- ex) FLAN-T5: 지시적인 prompt를 고려하여 fine-tuning 되었음
  - 따라서, (간단한) 직접적인 지시 프롬프트로도 잘 작동함

<br>

# 4. ChatGPT와 Q/A 챗봇 만들기

## 1) Procedure

- Step 1. System prompt를 디자인

- Step 2. 사용자의 query질문이 들어오면, 이에 알맞는 정보를 DB에서 검색

- Step 3. DB에서 찾은 정보를 System prompt에 삽입

- Step 4. ChatGPT가 해당 프롬프트에 따라 답변하기!

<br>

### 2) 코드

참고: https://github.com/sinanuozdemir/quick-start-guide-to-llms/blob/main/semantic-search-fastapi/conversation_utils.py

<br>

![figure2](/assets/img/llm/img1.png)

<br>

# 5. 요약

LLM의 성능 향상을 위한 프롬프트 엔지니어링

- 정렬 이해하기
- 직접 요청하기
- 퓨샷 학습
- 출력 구조화
- 페르소나 지정
- 여러 모델과 프롬프트 작업하기 등

<br>

