---
title: Sapiens; Foundation for Human Vision Models
categories: [CV, MULT, SSL]
tags: []
excerpt: ECCV 2024
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# Sapiens: Foundation for Human Vision Models

```
Khirodkar, Rawal, et al. "Sapiens: Foundation for human vision models." European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.
```

참고: 

- https://aipapersacademy.com/sapiens/
- https://arxiv.org/pdf/2408.12569

<br>

### Contents

1. Various tasks
2. Humans-300M
   1. Construction
   2. Statistics
   3. Dataset Comparison
3. SSL Pretraining
4. Task-specific Models
5. Experiments

<br>

# 1. Various tasks

Sapiens: Foundation for Human Vision Models

- Family of models that target **four fundamental human-centric tasks**
- by Meta AI

<br>

![figure2](/assets/img/llm/img288.png)

- **Pose Estimation**: Detects the location of key points of the human body in the input image.
- **Body-part Segmentation**: Determines which pixels combine the different body parts.
- **Depth Estimation**: Determines the depth of the pixels
  - front = brighter, back = darker
- **Surface Normal Estimation**: Provides orientation about the shape of the object

<br>

# 2. Humans-300M

## (1) Construction

Curating a Human Images Dataset

![figure2](/assets/img/llm/img287.png)

<br>

## (2) Statistics

![figure2](/assets/img/llm/img289.png)

<br>

## (3) Dataset Comparison

![figure2](/assets/img/llm/img292.png)

<br>

# 3. SSL Pretraining

![figure2](/assets/img/llm/img290.png)

- Pretraining task: MAE (Masked Auto Encoder)
- Encoder: Vision Transformer (ViT) architecture

<br>

# 4. Task-specific Models

Using the pretrained model..

- Add a new **task-specific decoder model**
- For each task: **Small labeled dataset**

$$\rightarrow$$ Do this for 4 different tasks!

<br>

# 5. Experiments

## (1) Reconstructed Results

Reconstructed results (Pretraining quality)

![figure2](/assets/img/llm/img291.png)

<br>

