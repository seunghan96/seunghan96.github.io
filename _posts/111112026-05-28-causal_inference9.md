---
title: Causal Inference - Part 8
categories: [ML, TS]
tags: []
excerpt: Causal Discovery - PC 알고리즘, FCI 알고리즘
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
# Causal Inference - Part 8

좋습니다!

이제 PC, FCI와는 다른 방식의 인과 구조 추론 알고리즘인 **GES (Greedy Equivalence Search)** 를 자세히 소개해드릴게요.



------





# **✅ GES (Greedy Equivalence Search)**





------





## **✅ 1. 핵심 아이디어**





> **GES는 “인과 그래프를 직접 구성하는 것이 아니라”,**

> **가능한 그래프 구조들의 공간을 탐색하면서**

> **점수가 가장 좋은 DAG(혹은 동치 클래스)를 선택하는 방식**입니다.





- 조건부 독립성 검정을 하지 않고,

- **스코어 함수(예: BIC, AIC)** 를 사용하여

  **구조를 선택**합니다.





즉, GES는 **score-based** 방식의 대표 알고리즘입니다.



------





## **✅ 2. 주요 단계 (요약)**





GES는 **두 단계로 나뉩니다**:

| **단계**              | **설명**                                 |
| --------------------- | ---------------------------------------- |
| **1. Forward Phase**  | 엣지를 하나씩 **추가하면서 점수를 올림** |
| **2. Backward Phase** | 엣지를 **제거하면서 점수를 더 개선**     |



- 최종적으로 점수가 가장 높은 **DAG의 동치 클래스(완전 PDAG)** 를 반환





------





## **✅ 3. 주요 단계 (핵심) with 수식**







### **📌 입력: 관측 데이터** \mathcal{D}**, 변수 집합** V





------





### **📌 Step 1: 초기 그래프**





- 초기 상태: **빈 그래프** (엣지 없음)





------





### **📌 Step 2: Forward Phase**





반복적으로:



G_{t+1} = \arg\max_{G’ \in \mathcal{N}^{+}(G_t)} \text{Score}(G’, \mathcal{D})



- \mathcal{N}^{+}(G_t): G_t에 **엣지를 추가**한 이웃 그래프들의 집합
- 가장 점수가 높은 그래프를 선택 (greedy 방식)





------





### **📌 Step 3: Backward Phase**





반복적으로:



G_{t+1} = \arg\max_{G’ \in \mathcal{N}^{-}(G_t)} \text{Score}(G’, \mathcal{D})



- \mathcal{N}^{-}(G_t): G_t에서 **엣지를 제거**한 이웃 그래프들
- 점수가 더 높아지면 업데이트





------





### **📌 Step 4: 출력**





- 최종 그래프는 DAG의 **Markov equivalence class** (완전 PDAG)





------





## **✅ 4. 사용되는 스코어 함수**





대표적으로:



\text{BIC}(G) = \log \mathcal{L}(G \mid \mathcal{D}) - \frac{d}{2} \log N



- \log \mathcal{L}: G에 대한 로그 우도
- d: 모델의 자유도 (파라미터 수)
- N: 샘플 수





> **모델 적합도와 복잡도를 균형 있게 고려**하여 가장 좋은 구조를 선택



------





## **✅ 5. 장점 / 단점**



| **항목**                                    | **설명** |
| ------------------------------------------- | -------- |
| ✅ 장점                                      |          |
| – 조건부 독립 검정에 의존하지 않음          |          |
| – 통계적 점수 기반 → 비교적 robust          |          |
| – 구조적 오류보다 **점수 기반 의사결정**    |          |
| ❌ 단점                                      |          |
| – 탐색 공간이 매우 큼 (변수 많으면 느림)    |          |
| – 숨은 변수 처리 ❌ (기본 GES는 관측 변수만) |          |
| – 점수 함수에 따라 성능 편차 있음           |          |



------





## **✅ 6. PC/FCI vs GES 요약 비교**



| **요소**       | **PC / FCI**           | **GES**                   |
| -------------- | ---------------------- | ------------------------- |
| 방식           | 조건부 독립 검정 기반  | 점수 기반 (BIC 등)        |
| 방향성 부여    | 논리 추론              | 점수 최대화 방향          |
| 숨은 변수 대응 | FCI만 가능             | ❌                         |
| 연산 효율      | 빠름 (PC) / 중간 (FCI) | 느림 (탐색 공간 큼)       |
| 해석력         | 조건부 독립 해석 가능  | 점수 기반 → 해석은 어려움 |



------





## **✅ 사용 예시 (Python causal-learn)**



```
from causallearn.search.ScoreBased.GES import ges
from causallearn.utils.ScoreUtils import local_score_BIC

score_func = local_score_BIC(data, k=1)  # k=1 for linear regression
graph = ges(data, score_func)
graph.draw()
```



------





## **✅ 언제 GES를 쓰면 좋은가?**





- 변수 수가 **너무 많지 않고**, 샘플 수가 **충분할 때**
- 조건부 독립 검정에 확신이 없을 때
- 특정 점수 기준(BIC 등)으로 구조를 최적화하고 싶을 때





------



다음은 **NOTEARS (최적화 기반 Causal Discovery)** 로 넘어가볼까요?

“다음”이라고 말씀해주시면 이어서 설명드릴게요!



좋습니다!

그럼 **GES (Greedy Equivalence Search)** 알고리즘을 좀 더 **구체적인 구조 예시**와 **동작 방식** 중심으로 차근차근 설명해드릴게요.

단순한 요약이 아닌 **“어떻게 작동하는지”를 예시로 보여주는 방식**입니다.



------





## **✅ GES를 이해하기 위한 준비**





**GES는 “그래프 공간을 탐색해서 최적의 인과 구조(DAG)를 찾는 알고리즘”**입니다.

단, 이 탐색은 전수 탐색이 아니라 **“탐욕적(greedy)”** 으로

매번 점수가 가장 높아지는 방향으로만 한 걸음씩 움직입니다.



------





## **🧪 예시로 이해하기 (3개 변수: A, B, C)**





초기 상태:



- 변수: A, B, C

- 초기 그래프: **엣지 없음**

  → 즉, A ⊥ B ⊥ C







### **🎯 목표**





> A, B, C 사이의 인과 DAG을 찾되,

> 그 구조의 **BIC 점수가 가장 높은 것**을 선택하자.



------





## **✅ 단계 1: Forward Phase –** 

## **엣지 추가로 점수 올리기**





초기:

```
A    B    C
(엣지 없음)
```

이제 GES는 가능한 모든 **엣지 추가 조합**을 시도합니다:



- A → B
- A → C
- B → A
- B → C
- C → A
- C → B





각 구조에 대해 **BIC 점수를 계산**합니다.





### **예: BIC(A → B)가 가장 높게 개선된다면**





→ 업데이트:

```
A → B
C
```

다시 가능한 엣지 추가 조합을 시도:



- A → C
- B → C
- C → A
- C → B





→ 그 중 B → C가 점수를 가장 많이 올린다면

```
A → B → C
```



### **🔁 이 과정을 더 이상 점수가 오르지 않을 때까지 반복**





------





## **✅ 단계 2: Backward Phase –** 

## **엣지 제거로 점수 더 올리기**





이제부터는 **엣지를 하나씩 제거**해가며

**점수가 더 올라가는 구조**가 있는지 확인합니다.



예:



- A → B 제거 시 BIC가 더 올라가면 → 제거





→ 예를 들어 제거 후 최종 구조가:

```
B → C
A    (독립)
```

→ 그게 최종 출력 그래프



------





## **✅ 스코어 함수: BIC 예시 수식**





\text{BIC}(G) = \log \mathcal{L}(G \mid \mathcal{D}) - \frac{d}{2} \log N



- \log \mathcal{L}: 데이터가 이 구조 하에서 나올 가능성
- d: 모델 복잡도 (엣지 수, 부모 수 등)
- N: 샘플 수





**즉: 구조가 데이터를 잘 설명하면서도, 간단할수록 점수가 높습니다.**



------





## **✅ GES의 핵심 특징 요약**



| **특징**             | **설명**                                                |
| -------------------- | ------------------------------------------------------- |
| DAG 구조를 직접 탐색 | 점수가 높아지는 방향으로 DAG를 구성                     |
| 탐욕적               | 매 단계마다 로컬 최적 선택 (전역 최적 아님)             |
| 확률 모델 기반       | 조건부 독립 검정 대신 **점수 함수(BIC)** 사용           |
| 연산량               | 그래프 후보가 많을수록 커짐 (고차원에서는 느림)         |
| 출력                 | 가장 높은 점수의 DAG (또는 그에 속한 equivalence class) |



------





## **✅ 예제 실행 흐름 요약 (3변수)**





1. 시작: **빈 그래프**
2. 가능한 엣지 추가 조합 6개 중 **BIC 최대 구조 선택**
3. 또 가능한 엣지 추가 → 점수 최대 구조로 업데이트
4. 더 이상 점수 안 오르면 **backward 시작**
5. 하나씩 제거 → 점수 더 오르면 반영
6. **최종 그래프 출력**





------





## **✅ 시각적 변화 예시**







### **초기:**



```
A   B   C
```



### **Forward:**



```
A → B
A → B → C
```



### **Backward:**



```
A     B → C
```



------





## **✅ 비교: PC vs GES**



| **요소**       | **PC**                     | **GES**                 |
| -------------- | -------------------------- | ----------------------- |
| 핵심 기준      | 조건부 독립성              | 점수 최대화 (BIC 등)    |
| 구조 탐색      | 독립 검정으로 엣지 제거    | DAG 구조 추가/제거 탐색 |
| 방향성 부여    | 규칙 기반 (v-structure 등) | 점수가 올라가는 방향    |
| 숨은 변수 대응 | FCI로 가능                 | 기본 GES는 ❌            |



------





## **✅ 결론**





> GES는 “점수 기반으로 DAG 구조를 직접 탐색하는 알고리즘”입니다.

> 독립성 검정에 의존하지 않기 때문에 **노이즈에 강하고**,

> **확률 모델 기반의 인과 구조 추론**이 가능하지만,

> 탐색 공간이 크기 때문에 **변수 수가 많을수록 속도는 느려질 수 있습니다.**



------



원하시면:



- 실제 Python GES 코드 예제 실행
- PC/FCI와 동일 데이터에 대한 비교 실험
- BIC score 변화 과정 시각화





도 이어서 도와드릴게요!
