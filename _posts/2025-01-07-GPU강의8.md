---
title: 최적화 기법 심화2 - LLM을 위한 데이터 전처리
categories: [DLF, LLM, PYTHON, MULT]
tags: []
excerpt: 
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<br>

# LLM을 위한 데이터 전처리

## Contents

1. Data의 Quality

2. SFT Data 구축 시

3. Data 구축의 핵심

   1. Diversity

   2. Data Pruning

   3. 기타: Hashing

4. Prompt
   1. Prompt의 중요성
   1. Prompt Template: Alpaca
   1. Prompt Template: Jeopardy
   1. Prompt Template: Chat
   1. Comparison

<br>

# 1. Data의 Quality

High Quality의 기준은?

- by LLM?

  $$\rightarrow$$  Not always! (매번 평가값이 다를 수 있음)

- by human evaluation?

<br>

# 2. SFT Data 구축 시

**우선 "SFT를 잘 해야"**, 추후에 RLHF나 DPO로 했을 때 성능도 잘 오른다!

$$\rightarrow$$ 따라서, ***"SFT를 위한 Data"도 잘 선정해야!***

<br>

**Questions**:

- 단순히 주관적으로 고른다?
- 무조건 대량이 좋다?
- 무조건 답변의 길이가 긴 것이 좋다?

<br>

단순히 GPT를 사용해서 데이터 생성?

$$\rightarrow$$ **License 위반 issue!**

<br>

# 3. Data 구축의 핵심

## (1) Diversity

### a) General

***"다양한 도메인"***의 데이터를 담는 것은 중요하다!

$$\rightarrow$$ 다양한 상황에 잘 대처하고 답변할 수 있게 하기 위해! (**Generalization**)

- 다양한 "내용" & 다양한 "task" 모두 필요!

<br>

**"다양한 도메인"**이란?

- Reasoning, World Knowledge and Factuality, Mathematics, Coding, Chatting ....

<br>

### b) Domain-specific

**Domain-specific한 모델**의 경우에는?

$$\rightarrow$$ 데이터의 diversity는 **"작업 task"**로 나눠서 다양성을 꾀할 수 있음.

- e.g., Summarization, Word-to-Text, NLI, Common Reasoning..

<br>

![figure2](/assets/img/llm/img629.png)

<br>

## (2) Data Pruning

### a) **Data pruning** ( or **Data curation** )

- 학습에 "유의미한 영향을 미치지 않는" **데이터를 제거**하는 작업
- 제거의 기준?
  - **(1) Duplicated data**
  - **(2) Quality**
- Duplicated data?
  - 유사한 의미의 데이터
  - 유사한 task의 similarity가 높은 데이터

<br>

### b) Duplication 판단 기준

- **(1) N-gram overlap**
  
  - **N개의 연속된 단어/token**의 묶음으로 분할
  - 두 개의 텍스트가 주어졌을 때, **N-gram이 얼마나 겹치는지** 측정
  
- **(2) Similarity**
  
  - Sequence에 대한 유사성을 Jaccard/Cosine similarity로 측정
  
  - 고정된 size의 embedding vector로 매핑 후 비교
  
    $$\rightarrow$$ (잠재 공간 상 비교이므로) heuristic한 방법론이긴 함

- **(3) Near Dedup Algorithm**
  - 중복성이 높은 문서 쌍에 대해 편집거리 계산
  - LSH 알고리즘 & 유사한 문서를 쌍으로 하여 그룹핑
  - Keyword: ***Hash, MinHash, LSH (아래 참고)***

- **(4) Nvidia Nemo - Cuartor**
  - LLM을 위한 데이터셋 준비
  - GPU 가속을 활용하여, 대규모 데이터셋 큐레이션을 지원

<br>

## (3) 기타: Hashing

### a) **Hash**

- **정의:** "임의의 크기"의 데이터(문자열, 문서 등)를 **"고정된 크기의 숫자"로 변환**하는 함수.
- **특징:** 같은 입력은 항상 같은 hash 값을 갖지만, 조금만 달라져도 완전히 다른 값이 나옴(충돌 가능).
- 예시:
  - `"hello"` → `123456`
  - `"hella"` → `987654`
- **한계:** 일반적인 hash 함수(MD5, SHA 등)는 유사한 데이터라도 hash 값이 완전히 달라져서 **유사한 문서를 찾는 데 부적합**함.

<br>

### b) **MinHash**

- **정의:** 문서 간 **Jaccard 유사도를 추정하는** hash 방법.

- **어떻게 작동?**

  1. 문서를 여러 개의 **"Shingle" (단어 또는 n-gram 단위 토큰)**로 쪼갠다.

     ```
     문서 A: {hello, world, bye}
     문서 B: {hello, there, world}
     ```

  2. 각 Shingle에 대해 여러 개의 hash 함수를 적용한다.

     | 단어  | 해시 함수 1: `h1(x) = (3x + 1) mod 5` | 해시 함수 2: `h2(x) = (2x + 2) mod 5` |
     | ----- | ------------------------------------- | ------------------------------------- |
     | hello | `(3*1 + 1) mod 5 = 4`                 | `(2*1 + 2) mod 5 = 4`                 |
     | world | `(3*2 + 1) mod 5 = 2`                 | `(2*2 + 2) mod 5 = 1`                 |
     | bye   | `(3*3 + 1) mod 5 = 0`                 | `(2*3 + 2) mod 5 = 3`                 |
     | there | `(3*4 + 1) mod 5 = 3`                 | `(2*4 + 2) mod 5 = 0`                 |

  3. 각 hash 함수별로 가장 작은 hash 값을 저장한다.

     | 문서                             | 해시 함수 1 (최솟값) | 해시 함수 2 (최솟값) | MinHash Signature |
     | -------------------------------- | -------------------- | -------------------- | ----------------- |
     | 문서 A (`{hello, world, bye}`)   | `min(4, 2, 0) = 0`   | `min(4, 1, 3) = 1`   | `(0, 1)`          |
     | 문서 B (`{hello, there, world}`) | `min(4, 3, 2) = 2`   | `min(4, 0, 1) = 0`   | `(2, 0)`          |

     

  4. 두 문서의 MinHash 값이 얼마나 겹치는지(Jaccard similarity)를 보면 유사도를 알 수 있음.

     - 두 MinHash Signature:

       - 문서 A: `(0, 1)`

       - 문서 B: `(2, 0)`

     - **겹치는 비율 = 0/2 = 0.0** (0% 유사)

  5. (추가) 실제 자카드 유사도와의 비교

     ```
     J(A, B) = |A ∩ B| / |A ∪ B| = |{hello, world}| / |{hello, world, bye, there}| = 2/4 = 0.5
     ```

     - MinHash로 추정한 유사도(0.0)와 실제 유사도(0.5)가 다르지만, 더 많은 해시 함수를 사용하면 정확도가 올라간다!

- **요약:**

  ```
  문서 A: "hello world"  
  문서 B: "hello there world"
  ```

  - Shingle 집합:
    - A → `{hello, world, hello world}`
    - B → `{hello, there, world, hello there, there world, hello there world}`
  - MinHash 값을 구한 후, **겹치는 비율**을 통해 A와 B의 유사도를 추정 가능.

- **장점:**

  - hash값만 비교해서 유사도를 빠르게 계산할 수 있음.
  - 문서 크기가 커도 계산량이 상대적으로 작음.

<br>

### c) **LSH (Locality-Sensitive Hashing)**

- **정의:** 비슷한 데이터를 같은 hash 버킷으로 묶는 기법.

- **왜 필요?**

  - 수백만 개의 문서가 있다고 할 때, **모든 문서쌍을 비교하면 계산량이 너무 많음**
  - **MinHash를 사용하면 유사도를 빠르게 추정할 수 있지만**, 모든 문서와 비교해야 한다면 여전히 시간이 오래 걸림
  - LSH는 이를 해결하기 위해 **유사한 문서만 같은 해시 버킷에 넣어서 비교할 후보를 줄이는 방식**을 사용

- **어떻게 작동?**

  1. **MinHash Signature 생성**

     - 여러 개의 MinHash 값(예: 100개)이 있으면 이를 몇 개의 그룹(예: 5개)으로 나눈다.

     | 문서   | MinHash Signature             |
     | ------ | ----------------------------- |
     | 문서 A | `(0, 1, 3, 5, 7, 9, 11, 13)`  |
     | 문서 B | `(2, 0, 3, 6, 7, 10, 11, 15)` |
     | 문서 C | `(0, 1, 3, 5, 7, 9, 11, 12)`  |

  2. **각 그룹을 하나의 hash 값으로 변환**해 여러 개의 hash 테이블에 저장한다.

     - ex) Signature를 4개의 그룹으로 나눔.

     | 문서   | Band 1   | Band 2   | Band 3    | Band 4     |
     | ------ | -------- | -------- | --------- | ---------- |
     | 문서 A | `(0, 1)` | `(3, 5)` | `(7, 9)`  | `(11, 13)` |
     | 문서 B | `(2, 0)` | `(3, 6)` | `(7, 10)` | `(11, 15)` |
     | 문서 C | `(0, 1)` | `(3, 5)` | `(7, 9)`  | `(11, 12)` |

  3.  같은 Band에서 같은 해시 값을 가진 문서끼리 같은 버킷에 저장

  - **Band 1 (해시 함수 적용 결과)**
    - `문서 A: (0,1)` → 버킷 1
    - `문서 B: (2,0)` → 버킷 2
    - `문서 C: (0,1)` → 버킷 1
  - **Band 2 (해시 함수 적용 결과)**
    - `문서 A: (3,5)` → 버킷 3
    - `문서 B: (3,6)` → 버킷 4
    - `문서 C: (3,5)` → 버킷 3
  - **Band 3**
    - `문서 A: (7,9)` → 버킷 5
    - `문서 B: (7,10)` → 버킷 6
    - `문서 C: (7,9)` → 버킷 5
  - **Band 4**
    - `문서 A: (11,13)` → 버킷 7
    - `문서 B: (11,15)` → 버킷 8
    - `문서 C: (11,12)` → 버킷 9

  4. **유사한 문서만 비교**

     ( 새로운 문서가 들어오면 각 hash 테이블을 탐색해 같은 hash 값을 가진 후보 문서를 빠르게 찾음 )

     - 문서 A와 C는 Band 1, 2, 3에서 같은 버킷에 들어갔으므로 **유사한 문서로 판단**.
     - 문서 B는 A, C와 거의 겹치지 않으므로 비교 대상에서 제외됨.

- **장점**: 불필요한 비교를 줄이고, 유사한 문서만 빠르게 찾을 수 있음

  - 전체 문서를 비교하는 것보다 **훨씬 빠름**.
  - 대량의 데이터에서 **근사 중복(near duplicate)** 문서를 효과적으로 찾을 수 있음.

- 요약:

  | 단계                                              | 설명                                 |
  | ------------------------------------------------- | ------------------------------------ |
  | **1. MinHash Signature 생성**                     | 각 문서의 MinHash Signature를 계산   |
  | **2. Band로 나누기**                              | Signature를 여러 그룹(Band)으로 나눔 |
  | **3. 같은 Band에서 같은 값이면 같은 버킷에 저장** | 유사한 문서끼리 같은 버킷에 배치     |
  | **4. 같은 버킷에 있는 문서끼리 비교**             | 전체 비교 없이 유사한 문서만 찾음    |

<br>

### d) Summary

| 개념        | 역할                           | 특징                                       |
| ----------- | ------------------------------ | ------------------------------------------ |
| **Hash**    | 데이터를 고정 길이 숫자로 변환 | 작은 차이에도 값이 완전히 달라짐           |
| **MinHash** | 문서 간 유사도 추정            | 자카드 유사도를 근사적으로 계산            |
| **LSH**     | 유사한 문서를 빠르게 찾음      | MinHash를 그룹으로 나눠 hash 테이블을 생성 |

- **MinHash**는 유사도를 계산하는 데 사용
- **LSH**는 이를 활용해 빠르게 유사한 문서를 찾는 데 사용

<br>

# 4. Prompt

## (1) Prompt의 중요성

LLM에 학습에 **매우 중요**한 역할을 한다!

$$\rightarrow$$ 따라서, ***Prompt를 잘 정의***하고 활용해야!

<br>

대표적인 Template

- **Alpaca** template
- **Jeopardy** template
- **Chat** template

<br>

## (2) Prompt Template: Alpaca

- (1) 특징

  - Stanford Alpaca 모델에서 사용한 형태

  - **"Instruction tuning"**을 위한 prompt 구조

- (2) 구성
  - 명령어(Instruction)
  - 입력(Input)
  - 출력(Output)
- (3) 장점
  - **Instruction-following 성능**을 향상시키는 데 적합
  - **명확한 구조**로 prompt 설계가 용이함.

- (4) 단점
  - 자유로운 대화 X, 특정 지시를 수행 O에 초점이 맞춰져 있음.

```css
Below is an instruction that describes a task. Write a response that appropriately completes the request.  

### Instruction:  
{instruction}  

### Input:  
{input}  

### Response:  

```

<br>

**Further details**

- `alpaca_chat`: **대화형** 챗봇과 같은 상황에서 사용되는 템플릿
- `alpaca_chat.load_qa`:  **질문-응답 태스크**에 사용
  - 질문에 대한 대답을 정확히 제공하는 데 초점을 맞춘 템플릿
- `alpaca_chat.load_camel_ai`: Camel AI와 연동된 대화형 프롬프트를 처리하는 템플릿
- `alpaca_w_system.load_open_orca`: OpenOrca와 연계된 시스템에서 사용하는 템플릿

<br>

## (3) Prompt Template: Jeopardy

- (1) 특징

  - 퀴즈 쇼 *Jeopardy!* 스타일

    ( = 일반적인 질문이 아닌 **"답변을 주고 질문을 생성"**하는 방식 )

  - 주어진 정보를 기반으로 질문을 유추하는 **"역발상형"** prompt

- (2) 구성

  - 정답
  - 질문

- (3) 장점

  - **창의적인 질문**을 유도하는 데 적합
  - **"질문 생성"** 및 데이터 증강(task augmentation)에 유용

- (4) 단점

  - 일반적인 대화형 AI보다는 특정한 교육 및 퀴즈 응용에 적합

```css
Answer: {answer}  
Question:  
```

<br>

## (4) Prompt Template: Chat 

- (1) 특징:
  - 일반적인 **대화형 LLM**을 위한 프롬프트 구조
- (2) 구성:
  - **시스템 메시지(System)**
  - 사용자 입력(User)
  - 모델 응답(Assistant)
- (3) 장점
  - **대화형 AI**에서 널리 사용 (multi-turn에 good)
  - (**"시스템 메시지"**를 통해) AI의 톤과 성격을 조정 가능
- (4) 단점:
  - 특정한 지시를 따르는 모델 X **대화 흐름 O**에 초점

<br>

## (4) Comparison

| Template     | 목적                  | 주요 활용                    | 특징                                                    |
| ------------ | --------------------- | ---------------------------- | ------------------------------------------------------- |
| **Alpaca**   | Instruction Following | Task Completion, Fine-tuning | **명확한 지시** 기반, Instruction, Input, Response 구조 |
| **Jeopardy** | Question Generation   | Quiz, Data Augmentation      | 답변을 주고 **질문을 생성**하는 방식                    |
| **Chat**     | Conversational AI     | Chatbots, Assistants         | 시스템 메시지를 포함한 **대화 중심** 구조               |

**결론**:

- **Alpaca**는 지시를 따르는 AI 모델 학습에 적합
- **Jeopardy**는 질문 생성 및 퀴즈 응용에 특화
- **Chat**은 대화형 AI 모델을 개발하는 데 가장 적합

<br>

# Reference

https://fastcampus.co.kr/data_online_gpu
