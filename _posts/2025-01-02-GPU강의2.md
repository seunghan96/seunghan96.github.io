---
title: LLM 모델 파인튜닝을 위한 GPU 최적화 (2)
categories: [DLF, LLM, PYTHON, MULT]
tags: []
excerpt: GPU vs CPU
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# 2. GPU vs CPU

<br>

## Contents

# 개요

1. LLM의 개념과 배경
   1. NLP Tasks
   2. LLM이란
   3. LLM의 두 부류
   4. LLM의 현업에서의 현실
   5. 현업에서 LLM을 활용하기 위해
   6. LLM의 향후 기술 전망
2. LLM의 역사와 발전 배경
   1. 아키텍처 흐름
   2. Transformer의 활용
   3. LLM의 등장 흐름 1
   4. LLM의 등장 흐름 2
   5. LLM의 등장 흐름 3
3. LLM의 Components
   1. LLM 작동 방식 및 원리
   2. Tokenizer
   3. Decoding Strategy
4. GPU 자원 & LLM
   1. LLM의 GPU 의존성
   2. ROPE
   3. Llama 2 vs. Llama 3.1

<br>

![figure2](/assets/img/llm/img360.png)

# 1. GPU vs. CPU

## (1) GPU의 개념

그래픽 처리 장치 (Graphics Processing Unit)

- 그래픽스 & 이미지 처리 작업을 신속하게 하기 위해 설계된 전자 회로
- AI, ML, DL등 다양한 분야에서 활용
- (2024 현재) 2003년 이후 성능 약 7천배 향상

<br>

## (2) CPU의 개념

중앙 처리 장치 (Central Processing Unit)

- 연산 &  데이터 처리를 담당하는 두뇌 역할
- 가장 복잡하고 성능이 높은 제품
- 프로그램 명령어 실행 & 데이터 처리 & 다른 부품들과의 통신 관리

- 실행 과정
  - Step 1) 명령어 페치 (Fetch)
  - Step 2) 명령어 해석 (Decode)
  - Step 3) 명령어 실행 (Execute)
  - Step 4) 결과 저장 (WRITEBACK)

<br>

## (3) CPU vs. GPU

| **항목**        | **CPU**                                               | **GPU**                                                    |
| --------------- | ----------------------------------------------------- | ---------------------------------------------------------- |
| **주요 역할**   | 일반적 연산작업 및 제어                               | 그래픽 렌더링 및 병렬 연산                                 |
| **연산 유형**   | 직렬 연산 (순차적으로)                                | 병렬 연산 (동시에 여러 개의 연산)                          |
| **코어 수**     | 일반적으로 4~16개                                     | 수백~수천 개 이상                                          |
| **클럭 속도**   | 높음 (3~5 GHz)                                        | 상대적으로 낮음 (1~2 GHz)                                  |
| **처리 효율성** | 고속 직렬 연산에 최적화, 복잡한 연산 및 제어에 효과적 | 병렬 연산에 최적화, 단순 연산을 대규모로 처리              |
| **발열**        | 발열량 상대적으로 적음                                | 발열이 많음, 고성능 냉각 시스템 필요                       |
| **사용 사례**   | 운영체제 실행, 애플리케이션 실행, 시스템 제어 관리    | 3D 그래픽 렌더링, 머신 러닝 및 딥러닝, 비디오 처리 및 게임 |

<br>

# 2. GPU 구성요소 정리

## (1) **커널 (Kernel)**

- **정의**: GPU에서 실행되는 **함수(코드)**
- **역할**: GPU에서 병렬로 실행될 **작업**을 정의하며, 실행 시 **GPU의 스레드들이 동시에 해당 작업을 수행**
- **계층 위치**: 가장 상위 레벨, 스레드들의 작업을 지시.

<br>

## (2) **스레드 (Thread)**

- **정의**: GPU에서 병렬 실행되는 **최소 실행 단위**
- **역할**: 커널의 코드를 실행하며, 각 스레드는 **고유의 데이터를 처리**
- **계층 위치**: **워프** 안에 속함.
- **특징**: 각각 독립적으로 동작하나, 병렬 실행 효율성을 위해 그룹으로 묶임.

<br>

## (3) **워프 (Warp)**

- **정의**: **32개의 스레드**가 모여 이루어진 실행 단위. (NVIDIA GPU 기준)
- **역할**: GPU 하드웨어 스케줄러가 한 번에 처리하는 기본 실행 단위.
- **계층 위치**: **SM** 안에 여러 워프가 존재.
- **특징**: 워프에 포함된 모든 스레드가 **동시에 같은 명령어를 실행**.

<br>

## (4) **SM (Streaming Multiprocessor)**

- **정의**: GPU 내에서 워프를 실행하고, 병렬 연산을 처리하는 하드웨어 모듈.
- **역할**: 워프를 관리하며, 내부의 CUDA 코어를 통해 연산을 수행.
- **계층 위치**: GPU는 여러 SM으로 구성됨. 각 SM은 여러 워프를 관리.
- 구성 요소
  - **CUDA 코어**: 기본 연산 수행.
  - **레지스터 파일**: 스레드의 데이터를 저장.
  - **공유 메모리**: SM 내의 스레드들이 데이터를 공유.

<br>

## (5) **CUDA 코어**

- **정의**: SM 내부에서 연산을 담당하는 기본 연산 장치.
- **역할**: 산술 및 논리 연산(ALU)을 수행.
- **계층 위치**: SM 안에 다수의 CUDA 코어가 존재.
- **특징**: 병렬 연산의 핵심 단위.

<br>

### 계층 관계 요약 (위에서 아래로)

1. 커널: GPU에서 실행되는 병렬 코드.
2. 스레드: 커널을 실행하는 기본 단위.
3. 워프: 32개의 스레드 그룹.
4. SM (Streaming Multiprocessor): 다수의 워프를 관리하고 연산 처리.
5. CUDA 코어: SM 내부의 연산 장치.



### 비유: 회사 조직 구조로 설명

- **커널**: 회사 전체 프로젝트.
- **스레드**: 프로젝트를 수행하는 직원 한 명.
- **워프**: 팀 단위 (32명의 직원).
- **SM**: 부서(팀들을 관리).
- **CUDA 코어**: 직원의 업무 능력(연산 처리).

<br>

# 3. GPU 작동 원리 및 순서

**Step 1) 작업 분할 및 할당**

- **1-1) 명령 디코딩**: CPU는 (고수준의) 명령어를 디코딩하여 **GPU가 처리할 수 있는 작업 단위(="커널")**로 분할
- **1-2) 커널 런칭**: CPU는 이러한 **"커널을 GPU에 보냄"**
- **1-3) 스레드 블록 및 그리드**: 커널은 다시 **"스레드 블록"**으로 나누어짐. 이러한 스레드 블록은 **"그리드"**를 형성
  - 스레드 블록: 독립적으로 실행될 수 있는 작업 단위

<br>

**Step 2) 데이터 로드 및 준비**

- **2-1) 메모리 할당**: GPU 메모리에 데이터를 할당하여 필요한 연산 준비
- **2-2) 메모리 계층**: GPU는 다양한 메모리 계층을 가짐
  - e.g., 글로벌 메모리, 공유 메모리, 레지스터 등
- **2-3) 메모리 최적화**: 메모리 접근 패턴을 최적화 & 데이터 접근 시간 줄임 & 병목현상 최적화

<br>

**Step 3) 병렬 연산 수행**

- **3-1) SM 내부 구조**: 각 SM은 수십~수백개의 CUDA 코어를 포함
  - SM =  **Streaming Multiprocessor** (병렬 처리를 수행하는 기본 단위)
  - 이 코어들은 독립적으로 작동하여 병렬 연산을 수행
- **3-2) 와프 스케줄링**
  - CUDA 코어는 와프(warp)단위로 스케줄링 됨
  - 각 와프는 32개의 스레드로 구성. 동일한 명령어를 동시에 실행
- **3-3) SIMT 아키텍처**
  - SIMT = Single Instruction Multiple Threads
  - 단일 명령어를 여러 스레드가 동시에 실행

<br>

**Step 4) 캐시 시스템 활용**

- 4-1) L1 캐시: 각 SM별로 존재. 데이터에 빠르게 접근
- 4-2) L2 캐시: GPU 전체에 걸쳐 중앙에 위치
  - 여러 SM 간의 데이터를 공유
  - L1 캐시 미스가 발생 시 데이터 제공
  - L1 캐시보다 용량이 크지만 느림
- 4-3) 동적 캐시 관리
  - GPU는 실행 중에 데이터 접근 패턴을 분석하여 캐시를 동적으로 관리 & 최적화

<br>

**Step 5) 특화 유닛 활용**

- 5-1) 텍스처 유닛: 그래픽 구현 특화
- 5-2) 텐서 코어: 딥러닝 모델 학습/추론 속도 향상

<br>

**Step 6) 결과 통합 및 출력**

- 6-1) 스레드 간 동기화
  - 각 스레드의 결과를 통합 & 최종 결과 생성할 것이므로, 스레드 간의 동기화가 필요!
- 6-2) 결과 저장 및 전송
  - 통합된 결과는 GPU 메모리에 저장
  - 필요에 따라 CPU/Display로 출력

<br>

**Step 7) 상호작용과 피드백 루프**

- 7-1) CPU와의 협력
- 7-2) 피드백 루프

<br>

# Reference

https://fastcampus.co.kr/data_online_gpu
