---
title: THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics
categories: [LLM, MULT, TS]
tags: []
excerpt: CIKM 2025
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics (CIKM 2025)

https://arxiv.org/pdf/2508.16936



# 0. Abstract

- **문제 의식**: 범용 LLM embedding은 **금융 자산의 도메인 특성**과 **테마적 뉘앙스**를 충분히 포착 X

- **제안**: **THEME** 프레임워크 

  - 테마와 구성 종목의 **계층적 관계**를 활용한 **hierarchical CL**으로 embedding을 fine-tuning
  - 이후 **stock returns**를 결합해 embedding을 정련

- **핵심 메커니즘**: 

  - (1) 테마–주식 **semantic alignment**

  - (2) **temporal dynamics(수익률)** 반영 

    → **테마 적합 + 수익 잠재력**을 함께 담는 표현 학습

- **성과 1 (Retrieval)**: 테마 자산 검색에서 **최신 LLM** 대비 **유의미한 성능 향상**을 달성. 

- **성과 2 (Portfolio)**: THEME로 구성한 포트폴리오가 **매력적인 성과**

- **의의**: 텍스트 기반 **thematic relationships**와 **시장 수익률 동학**을 **공동 모델링**

  $$\rightarrow$$ 실무 투자 응용에 특화된 **stock embeddings**을 제공

<br>

# 1. Introduction

## **1) 문제 정의와 배경**

**Thematic investing**: 

- 정의)  **구조적(Structural) 트렌드** 중심으로 종목을 고르고 포트폴리오를 구성
  - AI, Renewable Energy, Cybersecurity

- 특징)  (전통적인 **sector-based**와 달리) **cross-sector**이고 **동적**임 

<br>

## 2) 기존의 한계점

(1) 기존 portfolio 구성의 한계

- 기존 실무는 **정적 ETF 구성**이나 **전문가 리스트**에 의존 

  → 새로운 기업의 등장, 테마의 미세한 변동을 **제때 반영하지 못함**. 

  → 그 결과 **timeliness**와 **representativeness**가 떨어질 수 있음. 

<br>

(2) LLM의 한계

- 범용 LLM embedding은 강력

- 하지만, **일반 금융 텍스트의 의미 공간**과 **개별 금융자산(주식)의 의미 공간**이 **근본적으로 다를 수 있음** 

  → **테마-주식**의 미묘한 관계를 충분히 포착하지 못함

<br>

## **3) 핵심 가설**

아래의 두 가지를 동시에 학습 시키면

- (1) **Text semantics (장기적 구조·정체성)**
- (2) **Return dynamics (단기적 시장 신호)**

테마에 **의미적으로 맞고** **수익률 잠재력**도 반영된 **stock embeddings**를 만들 수 있다. 

<br>

## **4) Proposal: THEME 프레임워크 개요**

**Hierarchical CL** 두 단계:

1. **Thematic Alignment (Semantic)**: 
   - 테마 설명문과 기업 텍스트 프로필 (SEC filings, business description, news 등)로 **테마 ↔ 주식**을 의미 공간에서 정렬.
2. **Temporal Refinement (Returns)**: 
   - 최근 **수익률 시계열**을 입력으로 받아 **단기적 투자 적합성**을 반영해 embedding을 미세 조정.

→ 최종적으로 **thematically aligned + return-aware** embedding 확보.  

<br>

**왜 hierarchical?**

- 테마 ↔ 구성 종목의 **계층적 관계**를 학습 신호로 직접 활용

  - 상위: 테마
  - 하위: 종목

- **1단계(semantic)**로 정적 의미를 먼저 붙잡고

- **2단계(temporal)**로 최근 시장 동학을 반영

  $$\rightarrow$$ Progressive refinement

<br>

## **4) 직관적 효과 (그림 요약)**

![image-20251018180123275](/Users/seunghan96/Library/Application Support/typora-user-images/image-20251018180123275.png).

- **Figure 1 (t-SNE)**: 

  - 적용 이전) 범용 embedding: 테마별로 군집이 흐릿함 (섹터 섞임)

  - 적용 이후) **FinTech, Future Vehicles** 같은 **테마 클러스터가 또렷**

    $$\rightarrow$$ **해석가능성**과 **retrieval 품질**이 동시에 상승

- **Figure 2 (시스템 사용 흐름)**:

  - Step 1) 사용자가 “AI software and chipmakers” 같은 **자연어 테마 질의**를 던지면 
  - Step 2) THEME가 쿼리를 embedding 
  - Step 3) **semantic + financial relevance** 기준으로 **Top-k** 종목을 검색 
  - Step 4) **포트폴리오 구성**에 바로 활용 


<br>

## **5) 데이터 자산: TRS (Thematic Representation Set)**

- **1,153개의 실제 테마 ETF** (구성 종목 + 텍스트 설명).

- **산업/섹터 taxonomies**와 **news-derived themes**를 추가
- 각 종목은 **SEC filings + 뉴스**를 모아 **multi-theme** 속성으로 프로필화 (전통적 단일 섹터 귀속의 제약을 완화).
- **동적으로 업데이트**되어 신생 테마에도 대응 

<br>

## 6) Contribution

- **Unified semantic-temporal** 테마 모델링: 
  - (1) 텍스트와 (2) 수익률을 결합한 **contrastive** 학습 $$\rightarrow$$ 으로 **theme-aware + responsive** embedding. 
- **Finance-tuned embedding space**: 
  - 범용 embedding이 놓치는 **도메인 특화 의미 구조**를 학습
  - **해석성과 retrieval** 개선
- **Hierarchical modeling**: 
  - **테마 ↔ 하위 테마/구성 종목**의 레벨 구조를 반영한 **multi-level contrastive** 설계

- **TRS 데이터셋**: 
  - ETF 한계를 넘어 **산업 분류 + 뉴스**로 **테마 커버리지**를 확대

- **Real-world evaluation**: 
  - **thematic retrieval**과 **포트폴리오 성과** 모두에서 일관된 우수성


<br>

## **7) 왜 Quant 관점에서 중요한가?**

- **Alpha signal 결합**: 
  - (1) **semantic exposure**(장기 구조)
  - (2) **short-term momentum/mean-reversion** (단기 신호)
  - 이 둘을 **하나의 embedding 공간**에 내재화 → **ranking/selection**에 바로 사용 가능

- **시스템 통합성**: 
  - **사전 계산(pre-compute)**한 embedding
  - **REST API**로 **실시간 후보군 스크리닝**, **룰 기반/ML 랭커**와 손쉬운 결합


<br>

# 2. Related Works

## (1) Thematic Investing의 기존 접근들

Thematic investing이란?

- 특정 **메가트렌드(예: AI, 그린에너지, 블록체인)** 에 맞춰 포트폴리오를 구성하는 전략.

<br>

최근 트렌드: **테마가 산업 경계를 넘나듦**

- 예를 들어 “AI 테마”엔 반도체, 클라우드, 소프트웨어 회사가 다 포함됨.
- 1 트렌드 = N개의 산업

<br>

기존 방식은 주로:

- a) **전문가 큐레이션 리스트**
- b) **고정된 산업 분류(NAICS, GICS 등)** 를 사용해 왔는데

$$\rightarrow$$ 한계점: 이건 **다양한 산업을 포괄하기 어렵고**, **신흥 기업이나 새로운 테마를 반영하지 못함**. 

<br>

## (2) Text-based Thematic Modeling

**NLP 기법 활용 시도**

- 최근 연구들: 기업의 **SEC filings, 사업 설명문, 뉴스 텍스트** 등을 활용

  $$\rightarrow$$ 기업 간의 **semantic similarity**를 계산함으로써 **테마 관련성**을 파악

<br>

**예시 연구들**

- **Rao et al. (2023)**: 도메인 특화 LMs로 기업 설명문을 분석해 테마 관련성을 추론.
- **Vamvourellis et al. (2023)**: SEC filings 기반 Transformer embedding으로 **기존 산업 분류를 재현 + 새로운 cross-sector 관계 발견**.
- **Takayanagi et al. (2024, SETN)**: 텍스트 embedding + 기업 네트워크 구조를 결합해 **하이브리드 stock representation**을 구축.

<br>

한계점들

- 위 연구들은 **“static text similarity”**에 기반함

  - 금융 시장은 **비정상(non-stationary)** & 기업의 **테마 연관성 자체가 시간에 따라 변함**. (dynamic)

- e.g., 한 기업이 EV 부품에서 AI SoC로 pivot할 수 있음 

  → static embedding은 이런 변화에 둔감

<br>

## (3) Time-aware Embedding Approaches

- **Motivation**: 금융 데이터는 시간에 따라 의미가 바뀜 → “temporal context” 반영 필요.
- **SimStock (Hwang et al., 2023)**
  - self-supervised temporal representation 학습을 통해, **시간 변화에 민감한 stock embedding**을 생성.
  - 테마 기반 인덱스 추적 성능 향상.
- **Trend-following 현실**
  - 실제 thematic fund들도 **단기 신호(news sentiment, price momentum)** 등을 반영해 **periodic rebalancing** 수행.
  - 하지만 대부분 rule-based 방식이라, **semantic structure**와 **market dynamics**를 통합적으로 다루진 않음. 

<br>

## (4) LLMs for Financial Applications

- 최근 GPT-4, Gemini, BloombergGPT 등 **대규모 언어모델(LLM)** 들이 금융 영역에서도 활용되기 시작.  
- **가능성:**
  - LLM은 방대한 사전지식을 통해 **문맥 기반 thematic relevance**를 이해할 잠재력 보유.
  - 하지만…
    - 최신 공시자료나 quantitative signal(예: momentum, volatility)에 접근 불가.
    - 도메인 특화 미세조정이 부족.
    - 결과적으로 **불완전하거나 일관성 없는 출력**을 생성함.
- **BloombergGPT (Wu et al., 2023)**
  - 금융 도메인 전용 LLM의 성공 사례지만,
    - **테마 주식 선택(task-specific fine-tuning)** 까지는 탐구되지 않음.

<br>

## **5) 기존 접근들의 근본 한계 요약**

| **한계**                       | **설명**                                                     |
| ------------------------------ | ------------------------------------------------------------ |
| **Static Text Representation** | 기업의 thematic 속성이 시간 변화에 반응하지 못함             |
| **No Temporal Integration**    | 단기 수익률·모멘텀 등 시장 신호가 embedding에 반영되지 않음  |
| **LLM Domain Gap**             | 범용 LLM은 금융 맥락에서의 nuance와 quantitative pattern 이해 부족 |
| **Lack of Unified Framework**  | semantic + temporal modeling이 통합된 시스템 부재            |

<br>

## **(6) THEME의 위치**

***“Semantic NLP + Explicit Temporal Modeling”***

을 결합한 **최초의 통합 프레임워크**로 제시됨. 

- 텍스트를 통해 **장기적 thematic 의미**를 학습하고,
- 주가 수익률을 통해 **단기적 시장 적응력**을 부여.

<br>

$$\rightarrow$$ (1) **semantic relevance** 와 (2) **temporal responsiveness**를 모두 반영하는 **unified stock representation**을 구현

<br>

## **(7) THEME이 기존 연구 대비 차별화되는 포인트**

| **구분**            | **기존 연구**               | **THEME**                                      |
| ------------------- | --------------------------- | ---------------------------------------------- |
| Representation Type | Static (text-only)          | **Dynamic** (semantic + temporal)              |
| Learning Scheme     | Single-stage contrastive    | **Two-stage** hierarchical contrastive         |
| Domain Adaptation   | 일반 LLM fine-tuning        | **금융 도메인** + **Return-aware** fine-tuning |
| Output Usage        | Clustering / classification | **Retrieval + portfolio construction**         |
| Dataset             | ETF constituents only       | **TRS (ETF + taxonomy + news)**                |

<br>

**THEME이 단순히 LLM fine-tuning이 아니라, **

**“market-aware NLP representation”을 만드는 첫 시도**!

$$\rightarrow$$ 즉, **LLM이 이해하지 못하는 금융 동학**을 embedding space에 직접 주입

<br>

# 3. Methodology

## (1) Stage 1: Thematic Alignment

Semantic Embedding Learning

- **Semantic layer**를 학습하는 부분
- 핵심 아이디어: “테마(Theme)”와 “주식(Stock)”을 **같은 의미 공간(embedding space)**에 위치시키기
  - 같은 테마에 속하는 종목들이 **가까이**
  - 다른 테마는 **멀리** 있도록 학습

<br>

### a) Motivation

- 특징: 일반적인 금융 텍스트(기업 설명, 공시, 뉴스 등)는 **주식의 본질적 테마적 속성**을 담고 있음.
- 기존 LLM 한계점: 하지만 범용 embedding은 이런 관계를 잘 반영하지 못함.
- 해결책: **CL**을 이용해 테마 ↔ 주식 간 의미 정렬을 수행
- 결과: “같은 테마 내 기업들은 비슷한 의미 벡터를 가지게” 학습함.

<br>

### b) Notation

- Theme set: $$T = \{t_1, t_2, …, t_M\}$$
- Stock set: $$S = \{s_1, s_2, …, s_N\}$$
- 각 theme $$t_i$$ 는 ETF 또는 TRS 데이터에서 얻은 텍스트 설명
- 각 stock $$s_j$$ 는 기업 설명문 + SEC filings + 뉴스 등을 통합한 텍스트 프로필

<br>

### c) 모델 구조

- **기반 모델(Backbone)**: 사전학습된 대형 embedding 모델 $$f_{\Phi}(\cdot)$$
  - 예: bge-small, Linq-Embed-Mistral 등
- **LoRA (Low-Rank Adaptation)** 적용 
  - LoRA adapter 파라미터 $$\theta$$ 만 학습.
- 최종 모델: $$f’_{\theta}(\cdot)$$
  - $$z_i = f’_{\theta}(t_i) \in \mathbb{R}^d$$
  - $$h_j = f’_{\theta}(s_j) \in \mathbb{R}^d$$

<br>

### d) CL loss

개념

- **Positive pair**: 같은 테마 내 (Theme, Stock) 쌍
- **Negative pair**: 다른 테마 에 속한 Stock

<br>

목표:  anchor(theme) 는 

- 자신의 구성 종목 positive embedding 은 끌어당기고
- 다른 negative 는 밀어냄.

<br>

수식: $$\mathcal{L}_{align} = - \log \frac{\exp(\text{sim}(z_i, h^+_j)/\tau)} {\exp(\text{sim}(z_i, h^+_j)/\tau) + \sum_k \exp(\text{sim}(z_i, h^-_k)/\tau)}$$.

<br>

### e) 효과

- 테마 설명 벡터 $$z_i$$ 가 **semantic anchor** 역할.

- LoRA fine-tuning 덕분에 **빠른 업데이트**, **새로운 테마의 적응** 가능.

- 결과적으로:

  - **같은 테마 기업끼리 근접**

  - **서로 무관한 테마 기업은 멀리**

    → 테마별 명확한 semantic cluster 형성.

- (Figure 3의 왼쪽 블록 참조) “Stage 1: Thematic Alignment” 부분은 gold/AI/REITs 테마 별로 embedding 정렬 시각화. 

<br>

Stage 1 요약:

- “**텍스트 기반 semantic 의미 정렬**” 단계
- 테마 설명문과 기업 텍스트를 같은 embedding 공간으로 매핑해 CL loss로 정렬
- LoRA를 사용해 효율적 도메인 적응을 달성

<br>

## (2) Stage 2: Temporal Refinement

한 줄 요약: **Return-aware Embedding Fine-tuning)**

- 단순히 “semantic similarity”가 아니라
- **수익률(return) 패턴까지 학습해 투자 적합성까지 반영**

<br>

### a) Motivation

- Stage 1의 결과:

  - **의미적으로 유사한 테마와 기업**을 잘 매칭
  - 하지만, 여전히 **시장 수익률의 단기적 변화**에는 둔감

- 금융시장은 **비정상(non-stationary)**!!

  - 기업의 테마 연관성과 실제 수익 간의 관계가 시간에 따라 바뀜

  → 따라서 **semantic embedding**을 **최근 수익률 신호(temporal dynamics)**로 정제해야!

<br>

### b) 구조 개요

두 가지를 입력 받음

- (1) Stage 1의 결과 $$h_j$$ (semantic embedding)
- (2) 최근 **L일간 일별 수익률 벡터** $$r_j$$

$$\rightarrow$$ 이 두 정보를 결합하는 **lightweight adapter** $$A_\phi$$

<br>

모델: $$h’_j = A\phi(h_j, r_j)$$

- $$A_\phi$$: 2-layer MLP 구조의 adapter (trainable)
- $$r_j$$: 주식 $$s_j$$의 최근 $$L$$일간 수익률 (lookback window)
- $$h’_j$$: 최종 fusion embedding (semantic + temporal 결합 표현)

<br>

### c) 학습 방식: Triplet Loss로 순위 학습 (Ranking-based)

개념

- Anchor: 테마 embedding $$z_i$$
- Positive: 동일 테마 내 **단기적으로 높은 수익률을 기록한 주식**
- Negative: 동일 테마 내 **낮은 수익률을 기록한 주식**

<br>

결론: 같은 테마 안에서라도, 

- “더 잘 나가는 종목”을 anchor에 가깝게 만들고

- “덜 오른 종목”은 멀리하도록 학습

<br>

### d) Loss 함수

$$\mathcal{L}_{triplet} = \left[ \text{sim}(z_i, h’_n) - \text{sim}(z_i, h’p) + m \right]_+$$.

- $$m$$: margin

- 목적: anchor–positive 유사도 > anchor–negative 유사도 + margin

  → **랭킹 기반 학습(Ranking Loss)** 구조

<br>

### e) 학습 데이터 구성

- **Lookback period** $$L$$: 과거 60 거래일 (최근 추세 반영)
- **Forward horizon** $$H$$: 미래 14일 수익률 (단기 수익성 판단)
- Ranking 산정 방식? (각 테마별 constituent stocks 중에서)
  - $$r_{14d}^{future}$$ 가 더 높은 종목을 positive, 낮은 종목을 negative로
- 결론: Triplet $$(z_i, h’_p, h’_n)$$

<br>

### f) 핵심 효과

| **구분**              | **설명**                                          |
| --------------------- | ------------------------------------------------- |
| **Semantic 유지**     | Stage 1의 의미 구조는 유지 (LoRA backbone freeze) |
| **Temporal 추가**     | Adapter만 학습하여 수익률 신호를 주입             |
| **Interpretability**  | 테마 의미가 유지되므로 embedding 공간 해석 가능   |
| **Market adaptivity** | 최근 시장 흐름(returns)에 반응하는 표현 생성      |

결과적으로 이 단계에서 생성된 $$h’_j$$는

- “테마적으로 일관되고, 단기적으로 투자 매력도가 높은 종목”을 embedding 공간상에서 가까이 배치

<br>

### g) Figure 3

![image-20251018183828975](/Users/seunghan96/Library/Application Support/typora-user-images/image-20251018183828975.png).

요약

- 왼쪽: Stage 1 (Thematic alignment)
- 오른쪽: Stage 2 (Temporal refinement via adapter)

- “High Return” 종목은 anchor(Theme)에 끌리고, “Low Return” 종목은 밀려나는 구조

<br>

### h) Stage 2 요약

- **semantic embedding을 short-term return 정보로 fine-tune하는 과정**
- Contrastive 구조를 유지하면서 **temporal alpha signal**을 embedding에 주입하는 단계

$$\rightarrow$$ 이를 통해 **semantic + temporal fusion representation**을 완성

<br>

## (3) Stage 3: Inference Pipeline

목표: 학습이 끝난 embedding 모델을 이용해서, **사용자 질의(theme query)** 로부터 **테마 관련성이 높고 투자 가치가 있는 종목**을 자동 검색(retrieve)

<br>

### a) 입력과 출력 구조

- [입력] 사용자가 정의한 **자연어 테마 쿼리** $$q$$
  - e.g., “AI software and chipmakers”, “renewable battery materials”

- [출력] THEME이 반환하는 **Top-K candidate stocks**,
  - 즉 테마에 semantic하게 맞고, return dynamics까지 반영된 주식 리스트

<br>

### b) Procedures

Step 1) **쿼리 인코딩**: $$z_q = f’_\theta(q)$$

- LoRA-finetuned semantic encoder f’_\theta(\cdot) 로 query를 embedding 벡터 z_q 로 변환.

- 이때 query는 테마 설명문과 동일한 공간에서 표현됨 (Stage 1과 같은 embedding space).

<br>

Step 2) **사전 계산된 주식 embedding 검색**

- 모든 주식은 미리 **Stage 2까지 학습된 embedding** h’_j 로 변환되어 저장되어 있음.

- 따라서 실시간으로 수천 개 주식을 다시 encode할 필요 없이, precomputed index에서 검색 가능.

<br>

Step 3) **유사도 기반 Retrieval**

- 각 stock embedding h’_j 와 query embedding z_q 사이의 cosine similarity 계산:

  $$\text{sim}(z_q, h’_j) = \frac{z_q \cdot h’_j}{\mid \mid z_q\mid \mid \mid \mid h’_j\mid \mid }$$

- 유사도 상위 K개 종목을 선택:

  $$\text{Top-}K = \text{argmax}_j\, \text{sim}(z_q, h’_j)$$

- 이 과정은 **Information Retrieval(IR)** 문제로 볼 수 있음.

<br>

Step 4) **결과 활용**

- 선택된 Top-K 종목은 downstream 응용으로 전달됨:
  - **Thematic Screening** (테마별 종목 필터링)
  - **Portfolio Construction** (테마 포트폴리오 구성)
  - **Index Design / ETF Backtesting**

<br>

특징 및 장점

| **항목**                  | **설명**                                                     |
| ------------------------- | ------------------------------------------------------------ |
| **Real-time scalability** | 모든 embedding을 사전 계산(pre-compute)해, 검색 시 O(N) 수준의 빠른 유사도 계산만 수행 |
| **Query flexibility**     | “AI chipmakers”, “carbon capture startups”처럼 **자연어 질의**를 그대로 입력 가능 |
| **Interpretability**      | semantic alignment 덕분에 유사도 기반 검색 결과가 **테마적으로 해석 가능** |
| **Integration readiness** | REST API 기반 시스템으로, 투자 리서치 플랫폼이나 자동화된 포트폴리오 엔진에 바로 통합 가능 |

<br>

## (4) System Implementation and Integration

단순한 연구 모델이 아니라 **"실제 금융 시스템에서 동작 가능한 구조"**로 구현

<br>

### a) 시스템 아키텍처 개요

- THEME은 **클라우드 기반, 모듈형(modular) 구조**로 설계

- 다른 말로 하면,

  - (1) 모델 학습과 추론
  - (2) 데이터 업데이트
  - (3) 사용자 쿼리 처리를 

  **분리된 서비스**로 구성해 확장성과 유지보수성을 확보

<br>

### b) **주요 구성 요소**

| **구성 요소**         | **역할**                                                 |
| --------------------- | -------------------------------------------------------- |
| **Embedding Service** | Stage 1·2에서 학습된 모델로 테마/주식 텍스트를 embedding |
| **Similarity Engine** | cosine similarity 기반 검색 수행                         |
| **API Layer (REST)**  | 외부에서 질의(query) 요청을 받고 결과 반환               |
| **Feedback Module**   | 사용자 피드백을 받아 재학습 데이터로 활용                |
| **Database (TRS)**    | ETF, 산업 taxonomy, 뉴스 기반 테마–주식 관계 저장        |

<br>

### c) 성능 및 확장성 (Scalability)

(1) **embedding 계산 복잡도**: 

- Stock 수 N에 대해 **선형 스케일(O(N))**

  → 수천~수만 개의 주식 universe에도 실시간 응답 가능.

<br>

(2) **사전 계산 (Pre-computation)**:

- 모든 stock embedding h’_j을 사전에 계산해 저장.
- 사용 시에는 query embedding z_q만 계산하므로 **latency가 매우 낮음**.

<br>

(3) **클라우드 네이티브 구조**:

- GPU inference 서버와 scalable storage로 구성 

  → **자동 확장(auto-scaling)** 과 **배치 업데이트(batch refresh)** 가능.

<br>

### d) 통합 (Integration)

THEME은 **금융 애플리케이션 전체 생태계에 쉽게 통합**될 수 있도록 설계되어 있습니다.

<br>

### **적용 가능한 워크플로우**

1. **Discretionary Research**
   - 애널리스트가 직접 테마를 정의하고, THEME으로 관련 종목을 조회 → 후보 리스트 생성.
2. **Systematic Portfolio Engine**
   - 자동화된 리밸런싱 시스템에 API로 연결 → 테마별 포트폴리오를 정기적으로 업데이트.
3. **Personalized Investing**
   - 개인 투자자용 앱에서, “AI in healthcare” 같은 자연어 질의로 **맞춤형 테마 포트폴리오 추천**.

<br>

### e) 피드백 및 지속적 학습 (Feedback loop)

- 사용자가 제공하는 테마 쿼리, 선택된 종목, 실제 성과 등을 **로그로 수집**.

- 이 데이터는 새로운 TRS 샘플로 편입되어

  → 다음 세대 THEME 모델 학습에 반영.

- 즉, 시스템이 점점 **더 똑똑해지고 시장 변화에 적응**하게 됨.

<br>

### f) 추가로 통합 가능한 실시간 데이터 소스

- **ESG events**: 환경/사회적 사건 (예: 탄소 배출 이슈)

- **Earnings announcements**: 실적 발표 정보

- **Patent activity**: 신기술 관련 특허 데이터

  → 이를 통해 **event-driven rebalancing**, **theme-based risk monitoring**,

  **semantic pre-filtering for financial NLP pipelines** 등의 고급 기능을 지원할 수 있음.

<br>

요약하면:

> **Stage 3.4**는 THEME이 실험실 모델을 넘어

> **실시간 테마 탐색 및 포트폴리오 구성 시스템으로 완전 구현 가능함**을 보여줍니다.

> REST API와 모듈형 아키텍처로 다양한 금융 플랫폼에 통합될 수 있으며,

> 실시간 ESG나 earnings 이벤트 기반 확장성도 내장되어 있습니다.

<br>

# 4. Experiments

## (1) Experimental Setup

### a) 데이터 구성

| **데이터셋**                          | **내용**                             | **역할**                                  |
| ------------------------------------- | ------------------------------------ | ----------------------------------------- |
| **ETF Set**                           | 1,153개 실제 테마 ETF (약 3,000종목) | 실제 테마-주식 관계의 기본 레퍼런스       |
| **TRS (Thematic Representation Set)** | ETF + 산업 taxonomy + 뉴스 기반 확장 | coverage 확대 및 편향 완화                |
| **시계열 데이터**                     | 과거 2년간 일일 주가 수익률          | Stage 2의 temporal refinement 학습에 사용 |

- **Train / Validation / Test split**: (678 / 97 / 194 ETF)

- **Lookback window**: $$L = 60$$ 거래일

  → 최근 3개월 정도의 수익률 패턴

- **Forward horizon**: $$H = 14$$ 거래일

  → 이후 2주간의 수익률을 예측

<br>

Task 한 줄 요약:

- 최근 60일 동안 주가가 어떻게 움직였는지를 보고,
- “앞으로 14일 동안 수익률이 더 좋은 종목”을 positive로 학습

<br>

### b) 평가 지표 (Metrics)

두 축으로 평가

- (1) Retrieval Quality (검색 품질)
- (2) Portfolio Performance (투자 성과)

<br>

**(1) Retrieval Quality (검색 품질)**

- THEME이 “주어진 테마 설명”으로부터 관련 주식을 얼마나 잘 찾아내는지 평가.

| **Metric**          | **설명**                                    | **직관적 의미**                          |
| ------------------- | ------------------------------------------- | ---------------------------------------- |
| **Hit Rate (HR@k)** | “Top-k 결과 중 최소 1개가 실제 정답일 확률” | 테마에 맞는 주식을 **하나라도 건졌는가** |
| **Precision (P@k)** | “Top-k 결과 중 정답 비율”                   | **정확히 맞춘 비율**이 얼마나 되는가     |

e.g.,

- [Recall 개념] HR@5 = 0.8 → 80%의 테마 쿼리에서 Top-5 안에 실제 관련 종목이 최소 하나 존재.
  - “놓치지 않고 잘 찾는가(HR)”
- [Precision 개념] P@5 = 0.4 → Top-5 중 2개(40%)가 실제 관련 종목
  - “정확히 맞게 고르는가(P)” 

<br>

**(2) Portfolio Performance (투자 성과)**

- 검색 결과를 실제 포트폴리오로 구성했을 때의 **금융적 성과**를 평가

| **Metric**                 | **수식**                                                     | **의미**                                         |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------ |
| **Cumulative Return (CR)** | $$CR_t = \prod_{i=1}^{t}(1 + r_i) - 1$$                      | 누적 수익률. 전체 기간 동안 얼마 벌었는가        |
| **Sharpe Ratio (SR)**      | $$SR = \frac{\bar{r}}{\sigma_r} \sqrt{252}$$                 | 위험 대비 수익. (하루 평균 수익 ÷ 수익률 변동성) |
| **Max Drawdown (MDD)**     | $$MDD = \min_t \left(\frac{V_t}{\max_{s \le t} V_s} - 1\right)$$ | 최대 손실 폭. (가장 큰 낙폭)                     |

- **Cumulative Return ↑** → 전체적으로 돈을 벌었다
- **Sharpe Ratio ↑** → 변동성(위험) 대비 효율적으로 수익을 냄
  - e.g., SR=0.75면, “동일 위험 수준에서 시장 평균보다 75% 높은 초과수익”.
- **Max Drawdown ↓** → 낙폭이 적어서 더 안정적
  - e.g., MDD=-0.25면, “가장 큰 손실 시점에 -25%까지 떨어졌음”.

<br>

Summary

- THEME은 단순히 주식 리스트를 잘 찾는 데 그치지 않고, 

  실제 수익률·위험 지표에서도 기존보다 개선되는지를 검증

- Retrieval(정확도) + Portfolio(수익성) 두 관점 모두를 평가

<br>

## (2) Experiment1: Retrieval Performance

- THEME이 **테마 기반 "주식 검색"**에서 실제로 얼마나 잘 작동하는지

<br>

### a) 목표

Q) 주어진 “테마 설명문”을 입력으로 했을 때, THEME이 "기존 embedding 모델이나 LLM"보다 **테마에 맞는 주식들을 더 정확히 찾아낼 수 있는가?**

( = “semantic alignment” 성능을 검증하는 실험 )

-  **수익률(temporal 신호)**이 아니라, **Stage 1에서 학습된 의미적 구조** 중심

<br>

### b) 비교 모델 구성

THEME은 **model-agnostic framework**

- 다양한 크기와 특성의 embedding 모델에 적용 가능!

<br>

세 부류의 모델을 비교

| **모델 유형**                        | **예시 모델**                                           | **설명**                                         |
| ------------------------------------ | ------------------------------------------------------- | ------------------------------------------------ |
| **① Domain-specific models**         | Fin-E5, Voyage-2-Finance                                | 금융 텍스트로만 학습된 사전 모델                 |
| **② General embedding models**       | bge-small, bilingual-embedding, multilingual-e5, stella | 일반 도메인 텍스트 embedding 모델                |
| **③ Large LLMs (instruction tuned)** | GPT-4.1, Gemini-2.5                                     | 범용 LLM 기반 텍스트 embedding (수십억 파라미터) |

- 각 모델에 **THEME fine-tuning을 적용 전/후** 성능을 비교 (즉, “Vanilla vs. THEME-applied”)

<br>

### c) 평가 지표

- **Hit Rate (HR@k)**: “테마에 해당하는 주식이 Top-k 결과 중 하나라도 포함되었는가?” (*Recall 성격의 지표.*)
- **Precision (P@k)**: “Top-k 중 실제 테마 관련 주식의 비율” (*정확도 성격의 지표.*)

→ 둘 다 **k = {3, 5, 10}** 에서 평가.

<br>

### d) 결과 요약 (Table 1 기준)

| **모델**                       | **HR@3 (전→후)** | **P@3 (전→후)** | **특징**                            |
| ------------------------------ | ---------------- | --------------- | ----------------------------------- |
| **Linq-Embed-Mistral (7B)**    | 0.52 → **0.82**  | 0.35 → **0.63** | 대형 embedding 모델 중 가장 큰 향상 |
| **bge-small-en-v1.5 (33M)**    | 0.14 → **0.60**  | 0.06 → **0.36** | 소형 모델에서도 대폭 향상           |
| **SFR-Embedding-Mistral (7B)** | 0.37 → **0.79**  | 0.21 → **0.61** | 대규모 모델 일관적 향상             |
| **GritLM-7B**                  | 0.08 → **0.82**  | 0.03 → **0.60** | 극적인 개선 (약 10배 상승)          |
| **GPT-4.1 (LLM)**              | 0.71             | 0.52            | baseline, fine-tuning 불가          |
| **Gemini-2.5 (LLM)**           | 0.65             | 0.40            | baseline 수준 유지                  |

<br>

### e) 결과 해석

1. **THEME 적용 전 대비 성능 상승폭이 매우 큼**

   - HR@3과 P@3 모두 **평균적으로 50~200% 이상 개선**.
   - 즉, “주어진 테마에 실제로 속한 종목”을 더 정확히 찾아냄.

2. **작은 모델에서도 대형 LLM보다 우수**

   - THEME을 적용한 **33M 파라미터 모델(bge-small)**이 **GPT-4.1보다 높은 HR, P** 달성.
   - 이는 THEME이 **parameter scaling보다 domain adaptation**에 더 효과적임을 의미.

3. **모델 종류에 독립적인 효과**

   - embedding backbone이 Mistral, E5, BGE 등 어떤 것이든

     THEME fine-tuning을 통해 일관된 향상 달성 → “model-agnostic” 특성 입증.

4. **도메인 특화 signal의 중요성**

   - 범용 LLM은 “언어적 유사성”은 잡지만,

     **시장/산업-specific nuance**를 포착하지 못함.

   - THEME은 contrastive learning으로 **theme–stock 관계**를 직접 학습하여

     금융 도메인 의미 구조를 보정.

<br>

### f) 시사점

| **요약 포인트**               | **의미**                                                     |
| ----------------------------- | ------------------------------------------------------------ |
| **Semantic fidelity 향상**    | 테마 중심의 의미 공간이 명확하게 형성됨 (t-SNE 클러스터 참조) |
| **모델 크기보다 구조가 중요** | LoRA 기반 domain fine-tuning이 scaling보다 효과적            |
| **Practical retrieval 가능**  | 실제 ETF나 리서치 시스템에서 테마 종목 검색에 바로 활용 가능 |

<br>

### g) Summary

**THEME은 테마 기반 주식 검색(task of thematic stock retrieval)**에서

- 기존의 어떤 LLM·embedding 모델보다 정확도가 높고,
- 특히 작은 모델에서도 큰 개선을 보여 “도메인 적응의 힘”을 입증

<br>

## (3) Experiment 2 — Portfolio Construction

THEME이 단순히 “테마 관련 주식 검색”에 그치지 않고 **실제 투자 성과(returns)**로 이어지는지를 평가

- Sharpe Ratio, Cumulative Return, MDD 등의 **투자 성과 지표**

<br>

### a) 실험 목표

***“THEME으로 검색된 주식들이 실제로 투자 수익률이 높은가?”***

- 단순 semantic relevance가 아니라 **financial utility (금융적 효용)** 을 검증

<br>

Stage 2에서 수익률(return) 신호를 학습시킴

$$\therefore$$ THEME이 잘 작동한다면 **retrieval → 실제 수익**이 자연스럽게 연결되어야!

<br>

### b) 실험 절차

평가 기간

- **2024년 4월 23일 ~ 2025년 4월 29일**
- 총 1년간의 **rolling window test**

<br>

Procedure

- Step 1) 특정 테마 anchor (예: “AI Hardware”)에 대해 THEME이 Top-K 종목을 검색함.

- Step 2) 이 K개의 주식으로 **equal-weighted 포트폴리오** 구성.
  
- Step 3) 다음 14거래일 동안의 평균 수익률을 기록.

- Step 4) 다시 윈도우를 이동시켜 전체 테스트 기간 동안 반복.

- Step 5) 이렇게 얻은 포트폴리오의 **일별 수익률 시계열**로 **Sharpe Ratio, Cumulative Return, MDD**를 계산.

<br>

### c) 결과

| **Model**                      | **SR@3** | **CR@3** | **MDD@3** | **요약**                   |
| ------------------------------ | -------- | -------- | --------- | -------------------------- |
| Linq-Embed-Mistral (vanilla)   | 0.49     | 0.09     | -0.26     | baseline                   |
| **Linq-Embed-Mistral + THEME** | **0.59** | **0.12** | **-0.25** | Sharpe↑, 안정성 유지       |
| gte-Qwen2-7B (vanilla)         | 0.50     | 0.09     | -0.24     | baseline                   |
| **gte-Qwen2-7B + THEME**       | **0.76** | **0.16** | **-0.24** | 효율성과 수익 모두 향상    |
| GritLM-7B (vanilla)**          | 0.57     | 0.12     | -0.24     | 이미 강력한 baseline       |
| **GritLM-7B + THEME**          | 0.60     | 0.12     | -0.27     | 향상폭은 작음 (saturation) |

참고: 실제 ETF 평균 성과:

- Sharpe Ratio ≈ 0.48, CR ≈ 0.067, MDD ≈ -0.2368

  → THEME 기반 포트폴리오가 **실제 ETF 대비 Sharpe 약 1.5배** 높음.

<br>

### d) 결과 해석

1. **Sharpe Ratio 대폭 향상**

   - THEME이 단순히 “의미상 테마에 맞는 종목”뿐 아니라

     “단기적으로 수익률이 높은 종목”을 함께 찾도록 학습되었음을 입증.

2. **Cumulative Return 상승**

   - 단순 ETF 투자보다 평균적으로 **약 1.7~2배 높은 누적 수익률** 달성.

3. **MDD 개선 or 유지**

   - Sharpe이 오르면서도 낙폭이 커지지 않음 → “위험대비 수익 개선”.

4. **모델 의존성**

   - 성능이 낮은 baseline일수록 향상폭이 큼.
   - 이미 강력한 GritLM-7B 같은 모델은 개선 폭이 작지만 여전히 긍정적.
   

<br>

### e) 해석 (Quant 관점 요약)

| **관점**            | **해석**                                                     |
| ------------------- | ------------------------------------------------------------ |
| **Financial**       | THEME embedding은 “semantic relevance + return signal”을 통합하여 실제 수익으로 이어짐 |
| **Quantitative**    | SR 증가 → 알파(alpha) 시그널 존재, 즉 **시장 대비 초과수익 가능성** |
| **Risk Management** | MDD 유지 또는 감소 → 모델이 **시장 하락 구간에도 안정적**    |
| **Practical**       | TRS 기반 theme retrieval만으로도 “ETF 수준 이상”의 전략 구현 가능 |

<br>

한 줄 요약: **THEM E은 단순 검색 모델이 아니라, 실제 투자 가능한 수준의 “return-aware stock retrieval system”**

$$\rightarrow$$ 즉, LLM을 **semantic financial alpha generator**!

<br>

## (4) Ablation Studies

### a) Anchor Strategy: Theme-based vs. Stock–Stock Alignment

CL은 “anchor–positive–negative” 삼중 구조로 학습

<br>

기존의 주식 관련 연구들: **Stock–Stock Alignment (SSA)** 구조를 사용

| **설정**                | **anchor**  | **positive**            | **negative**     |
| ----------------------- | ----------- | ----------------------- | ---------------- |
| **SSA (기존)**          | 한 종목     | 같은 ETF 안의 다른 종목 | 다른 ETF의 종목  |
| **Theme-based (THEME)** | 테마 설명문 | 해당 테마에 속한 종목   | 다른 테마의 종목 |

THEME은 anchor로 “**추상적 테마 의미(text)**”를 사용

- 이로써 “언어적으로 정의된 테마”와 “실제 주식” 사이의 연결을 직접 학습

<br>

왜 중요한가?

- Stock–Stock 구조

  - **단순히 비슷한 ETF 구성**만 학습 

    → 로컬한 유사도에 집중.

- Theme-based 구조

  - **텍스트 기반 의미 공간**을 중심으로 학습 

    → 보다 **일반화 가능한 semantic structure**를 형성

<br>

Theme-anchor는 “AI, 반도체, 친환경” 같은 **자연어 테마 정의**를 바로 인식할 수 있는 능력을 부여

<br>

결과

| **Model**                 | **ΔP@3**   | **ΔP@5**   | **ΔP@10**  | **해석**                   |
| ------------------------- | ---------- | ---------- | ---------- | -------------------------- |
| **bge-small-en-v1.5**     | +0.107     | +0.143     | +0.170     | 작은 모델에서도 큰 향상    |
| **multilingual-e5-large** | +0.138     | +0.124     | +0.136     |                            |
| **gte-Qwen2-1.5B**        | +0.191     | +0.191     | +0.179     | 대형 LLM에서도 일관된 개선 |
| **GritLM-7B**             | **+0.426** | **+0.428** | **+0.416** | 가장 큰 개선폭             |
| **Linq-Embed-Mistral**    | +0.069     | +0.065     | +0.076     | 안정적 향상                |

ΔP@k는 Theme-based anchor 설정 시 **Precision 향상폭**

<br>

해석

- 모든 모델에서 theme-anchor 설정이 **stock-stock 대비 성능 우위**.
- 특히 **GritLM-7B**의 경우 +0.42 수준의 큰 폭 향상 → “텍스트 테마 설명”을 anchor로 쓸 때 모델이 훨씬 풍부한 의미 관계를 학습한다!
- **소형 모델**에서도 개선폭이 크므로, anchor 전략의 효과는 **scaling-independent**.

<br>

결론: **Theme-based anchoring**은 **“테마 의미 공간”**을 중심으로 CL을 수행하게 하여, **semantic generalization과 retrieval precision을 동시에 높이는 핵심 설계요소**입니다.

<br>

### b) Dataset Strategy: ETF-only vs. TRS

- ETF 데이터셋만 사용할 경우 → “인기 테마(IT, Clean Energy 등)”에 편향.
- 이를 보완하기 위해 THEME은 **TRS (Thematic Representation Set)** 사용.
  - ETF 구성 + 산업 분류체계(NAICS, GICS) + 뉴스 기반 테마 확장.
  - **Emerging/Niche themes** 도 포함 (“Space Tech”, “Agri-AI”, 등).

<br>

실험 설정

- 동일한 모델(backbone)과 학습 절차를 유지
- **데이터셋만 교체(ETF-only ↔ TRS)** 하여 성능 비교.

<br>

결과

| **Model**                 | **ΔP@3**                    | **ΔP@5**                                   | **ΔP@10** | **해석**             |
| ------------------------- | --------------------------- | ------------------------------------------ | --------- | -------------------- |
| **bge-small-en-v1.5**     | +0.071                      | +0.119                                     | +0.150    | 가장 큰 개선         |
| **multilingual-e5-large** | +0.071                      | +0.058                                     | +0.060    | consistent           |
| **gte-Qwen2-7B**          | +0.067                      | +0.069                                     | +0.048    | 대형 모델에서도 향상 |
| **평균적 추세**           | 약 **+0.05~0.12** 수준 향상 | 데이터 다양성이 성능을 안정적으로 끌어올림 |           |                      |

결론

- TRS가 ETF-only보다 **항상 더 높은 Precision** 제공.

- 특히 소형 모델일수록 효과 큼 

  → 더 풍부한 학습 데이터로 **representation robustness** 향상.

- TRS 덕분에 “기존 ETF에 없는 새로운 테마”도 처리 가능 (out-of-sample generalization).

<br>

요약:

-  **TRS 데이터셋**은 학습 데이터의 **coverage와 다양성**을 크게 확장해,
- CL이 더 풍부한 semantic relationship을 학습하도록 돕습니다.

$$\rightarrow$$ THEME의 **일관된 일반화 성능**의 핵심 요인

<br>

### c) Summary

| **구성요소**         | **역할**                                             | **결과**                       |
| -------------------- | ---------------------------------------------------- | ------------------------------ |
| **Anchor Strategy**  | Theme-based alignment로 semantic generalization 강화 | 모든 모델에서 P@k 상승         |
| **Dataset Strategy** | TRS로 theme coverage 확장                            | ETF-only 대비 +0.05~+0.12 향상 |
| **공통점**           | scaling-independent, consistent improvement          | 작은 모델에서도 큰 향상        |

<br>

즉, **THEME의 두 설계 축**은

1. “무엇을 anchor로 삼느냐” (Theme-level meaning 중심 학습),

2. “무엇으로 학습하느냐” (다양한 TRS 데이터로 학습),

   이 두 요소가 **retrieval precision 향상과 일반화 능력**을 결정짓는 핵심이라는 결론입니다.

<br>

