---
title: (sLM-6) Prompt Engineering
categories: [LLM, MULT, NLP]
tags: []
excerpt: Flash Attention 개념, 코드 실습
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
# Prompt Engineering

## Contents

1. Prompt Engineering (PE) 기초
2. Prompt Engineering (PE) 코드

<br>

# 1. Prompt Engineering (PE) 기초

### a) Special Token

더 이상 나눠지지 않는 하나의 Token

역할: "특별한 의미를 표현, 작업을 위한 **신호 역할**"

- ex) LLaMA3-Instruct
  - `<|begin_of_text|>`: Prompt의 시작을 알리는 token
  - `<|start_header_id|>system<|end_header_id|>`: System 메세지를 알리는 토큰

<br>

### b) Multi-turn PE

여러 차례의 **대화 턴 (turn)**을 통해 LLM에 정보 제공

Example)

```
user: 미국의 수도가 어디야?
assistant: 미국의 수도는 워싱턴 D.C.입니다.
user: 그럼 한국은?
-----------------
assistant: 한국의 수도는 서울입니다.
```

<br>

### c) Zero-shot / Few-shot PE

- Zero-shot: 따로 예제 제공 X이, 응답 생성을 요청

- Few-shot: 소수의 예제 제공 O이, 응답 생성을 요청

<br>

### d) Chain-of-Thought (CoT) PE

Not only 최종 답변, But also 추론 과정 (Reasoning process)

효과

- 추론 과정의 투명성
- 복잡한 문제 해결 능력
- 학습 효율성 향상

<br>

### e) Generated Knowledge PE

Procedure

- Step 1) LLM으로부터 "지식 생성"을 먼저 요구하고
- Step 2) 생성된 지식을 Prompt에 포함하여 답변을 생성하도록 요구

<br>

### f) Self-Ask PE

LLM이 "스스로 질문을 던지며" 문제 해결을 하면서, 최종적으로 답변을 생성

![figure2](/assets/img/llm/img712.png)

<br>

# 2. Prompt Engineering (PE) 코드 실습 개요

1. LLaMA-3-8B (Multi-turn PE, Few-shot PE)
2. Mistral-7B (CoT PE, Zero-shot PE)
3. Phi-3-3.8B (Multi-turn PE, Generated Knowledge PE)
4. Gemma 7B (Few-shot PE, Self-Ask PE, Chaining)

<br>

### Reference

- [패스트캠퍼스] 8개의 sLM모델로 끝내는 sLM 파인튜닝
