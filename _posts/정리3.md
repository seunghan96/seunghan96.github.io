# 교훈 정리

## (1) WaveNet (2016)

- https://seunghan96.github.io/ts/Wavenet(2016)/
- **dilated causal convolution**



## (2) TCK & TKAE (2019)

- Learning Representations of multivariate time series with missing data (2019)
- https://seunghan96.github.io/ts/TKAE(2019)/
- **가변 길의의 input & missing data 잘다룸**
- TKAE ( = Temporal Kernelized Autoencoder )



## (3) TLAE (2021)

- Temporal Latent AutoEncoder : A Method For Probabilistic MTS Forecasting
- https://seunghan96.github.io/ts/TLAE(2021)/
- **MTS를 low rank matrix로 factorize하자**
- TRMF ( Temporal Regularized Mactrix Factorizion ) : $\mathbf{Y}$ = $\mathbf{F} \mathbf{X}$ 로 분해
- TLAE 한 줄 요약 : $\mathbf{Y} \rightarrow \mathbf{X} \rightarrow \hat{\mathbf{X}} \rightarrow \hat{\mathbf{Y}}$.
  - (1) $\mathbf{Y}_{B}=\left[\mathbf{y}_{1}, \ldots, \mathbf{y}_{b}\right] \in \mathbb{R}^{n \times b}$  임베딩하고,
  - (2) $\mathbf{X}_{B}=\left[\mathbf{x}_{1}, \ldots, \mathbf{x}_{b}\right] \in \mathbb{R}^{d \times b}$ 를 둘로 나누고 (앞/뒤)
  - (3) (앞)으로 (뒤) 예측하고  ( $\hat{\mathbf{x}}_{i+1}=h_{\mathrm{W}}\left(\mathrm{x}_{i-L+1}, \ldots, \mathbf{x}_{i}\right)$ )
  - (4) $\mathbf{x}_{1}, \ldots, \mathbf{x}_{L}$ & $\hat{\mathbf{x}}_{L+1}, \ldots, \hat{\mathbf{x}}_{b}$ 로 $\hat{\mathbf{Y}}_{B}$ 예측
- 이때 위의 (3) 과정에서 probabilistic forecasting ( mu, sigma 예측 )
  - VAE와 유사



## (4) HIVAE (2020)

- Handling Incomplete Heterogeneous Data using VAEs
- https://seunghan96.github.io/ts/HIVAE(2020)/
- VAE의 문제점 : heterogeneous ( cont + disc ) & missing data 취급못해



## (5) GP-VAE (2020)

- GP-VAE ; Deep Probabilistic Time Series Imputation
- https://seunghan96.github.io/ts/GPVAE(2020)/

- 목적 : 차원 축소 & imputation

<br>

## (6) AST (2020)

- Adversarial Sparse Transformer (=AST) for TS Forecasting
- https://seunghan96.github.io/ts/AST(2020)/
- **AST** based on **GANs**
  - generator : sparse transformer
  - discriminator : improve prediction

- 목적 : horizon 만큼 multi-step forecast, for **each quantile**
- X : 1~15 , Y : 16~20이라 했으면,
  - generator loss : Y & Y hat
  - discriminator loss : X+Y & X+Yhat
- **Sparse Transformer : 집중 안헐거는 참조 X**

<br>

## (7) Transformer + MTS (2020)

- A Transformer-based Framework for Multivariate Time Series Representation Learning
- https://seunghan96.github.io/ts/TransformerTS(2020)/
- **UNsupervised** 러닝 : missing value imputation
  - masking하고, 그 부분 맞추기

<br>

## (8) Informer (2021)

- Informer ; Beyond Efficient Transformer for Long Sequence Time-Series Forecasting
- https://seunghan96.github.io/ts/Informer(2021)/
- 핵심 : Transformer를 더 efficient하게!

<br>

## (9) IQN-RNN (2021) 

- Probabilistic TS forecasting with Implicit Quantile Networks

- **univariate** method 
- probabilistic output by **IQN**
- loss function : **CRPS ( = Continuous Ranked Probability Score )**
- 

.

<br>

## (10) SCINet (2021)

- Time Series is a Special Sequence ; Forecasting with Sample Convolution and Interaction
- https://seunghan96.github.io/ts/SCINET(2021)/
- SCINet ( Sample Convolution and Interaction Network )
  - hierarchical TSF framework ( binary tree )
  - SCI-Block
- step1) Input을 두 개의 sub-sequence로 쪼개기 (splitting)
- Step2) 각각 처리한뒤
- step3) 나중에 incorporate (interactive learning)

<img src="https://seunghan96.github.io/assets/img/ts/img19.png" width="400"/>



## (11) Deep AR (2019)

- https://seunghan96.github.io/ts/DeepAR(2019)/
- probabilistic forecasting



## (12) Nbeats & NbeatsX

- 생략



## (13) Split Networks = Multi-task learning TS (2019)

- Multi-step Forecasting via Multi-task Learning 
- https://seunghan96.github.io/ts/Multi-step-Forecasting-via-Multi-task-Learning/
- 총 task의 수 : KxH
  - K : 시계열 개수 ( 그닥 확장 불가능할 듯 )
  - H : 예측 시계열 길이
- loss에 다른 가중치 : **exponential weighting**
  - 뒤에 있는거 맞추기 더 어려우므로

<br>

## (14) MTL-Trans (2021)

- Multi-Task Time Series Forecasting with Shared Attention
- https://seunghan96.github.io/ts/Multi-Task-Time-Series-Forecasting-with-Shared-Attention/
- **attention기반의 MTL**
- propose 2 different attention sharing architectures

<img src="https://seunghan96.github.io/assets/img/ts/img59.png" width="400"/>



## (15) Dilated RNN (2017)

- dilated recurrent skip-connection



## (16) Multi-task + MTS ( Imputation & Forecast ) ( 2021 )

- End-to-end Multi-task Learning of Missing Value Imputation and Forecasting in Time-Series Data
- https://seunghan96.github.io/ts/End-to-end-Multi-task-Learning-of-Missing-Value-Imputation-and-Forecasting-in-Time-Series-Data/
- 복잡해서 블로그 참조



## (17) TimeGAN (2019)

- https://seunghan96.github.io/ts/TimeGAN/
- UNsupervised + supervised 둘 다 활용
- TimeGAN = Autoregressive + GAN
- 

