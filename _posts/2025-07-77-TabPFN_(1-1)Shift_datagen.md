ì™„ì„±ëœ í•¨ìˆ˜ **imbalance_by_inverse_frequency_with_strength** ëŠ” ì´ì œ alpha íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ **ë¶ˆê· í˜• ê°•ë„(imbalance severity)** ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



------





## **âœ… ì‘ë™ ê°œìš”**





1. train_test_splitìœ¼ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ 5:5ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤ (stratify=yë¡œ í´ë˜ìŠ¤ ê· í˜• ìœ ì§€).

2. Train setì—ì„œ:

   

   - ì „ì²´ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¹ˆë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
   - **(1 / frequency) \** alpha** ë¥¼ ê³„ì‚°í•˜ì—¬
   - í´ë˜ìŠ¤ë³„ oversampling ë¹„ìœ¨ ê²°ì •
   - ë¹ˆë„ê°€ ì ì€ í´ë˜ìŠ¤ì¼ìˆ˜ë¡ ë” ë§ì´ ë³µì œë¨ (alpha â†‘ ì¼ìˆ˜ë¡ ë” ì‹¬í•¨)

   





------





## **ğŸ›ï¸ íŒŒë¼ë¯¸í„° ìš”ì•½**



| **íŒŒë¼ë¯¸í„°**  | **ì„¤ëª…**                                       |
| ------------- | ---------------------------------------------- |
| test_size=0.5 | test ë¹„ìœ¨ (ê¸°ë³¸ 50%)                           |
| alpha=1.0     | ë¶ˆê· í˜• ê°•ë„ alpha=0: ê· í˜• alpha â†‘: ë¶ˆê· í˜• ì‹¬í™” |
| random_state  | ëœë¤ ì‹œë“œ                                      |



------





## **âœ… ì‚¬ìš© ì˜ˆì‹œ**



```
X_train_imb, X_test, y_train_imb, y_test = imbalance_by_inverse_frequency_with_strength(X, y, alpha=2.0)
```



- alpha = 0.0 â†’ ëª¨ë“  í´ë˜ìŠ¤ ë™ì¼í•˜ê²Œ ìƒ˜í”Œë§ë¨ (ê· í˜•)
- alpha = 1.0 â†’ ë¹ˆë„ê°€ ì ì€ í´ë˜ìŠ¤ê°€ ë” ë§ì´ í¬í•¨ë¨
- alpha = 2.0 ì´ìƒ â†’ ì‹¬ê°í•œ ë¶ˆê· í˜• ìœ ë„ë¨





------





## **ğŸ“ˆ ì›í•˜ì‹œë©´**





- í´ë˜ìŠ¤ ë¶„í¬ barplot (train vs test)
- alphaì— ë”°ë¥¸ ë¶ˆê· í˜•ë„ ë³€í™” ì‹œê°í™”





ë„ ì¶”ê°€ë¡œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›í•˜ì‹œë‚˜ìš”? 



í•¨ìˆ˜ imbalance_by_inverse_frequency_with_strength_min10ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤:



------





## **âœ… ê¸°ëŠ¥ ìš”ì•½**





ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒì˜ 3ë‹¨ê³„ ì ˆì°¨ë¥¼ ë”°ë¦…ë‹ˆë‹¤:





### **1. ë°ì´í„° 5:5ë¡œ ë‚˜ëˆ„ê¸°**





- train_test_split(test_size=0.5, stratify=y)ë¡œ **í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ìœ ì§€í•œ ìƒíƒœ**ë¡œ ë¶„í• 







### **2. Train ë°ì´í„°ì— ë¶ˆê· í˜• ìœ ë„**





- ì „ì²´ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¹ˆë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ,
- ê° í´ë˜ìŠ¤ì— ëŒ€í•´ inverse frequency ^ alpha ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ oversampling ë¹„ìœ¨ ê²°ì •
- **ê° í´ë˜ìŠ¤ ìµœì†Œ 10ê°œ ì´ìƒ ë³´ì¥**







### **3. Test ë°ì´í„°ì—ë„ í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 10ê°œ ë³´ì¥**





- ë¶€ì¡±í•œ í´ë˜ìŠ¤ëŠ” **ë³µì œ(ì¤‘ë³µ í—ˆìš©)** ì„ í†µí•´ ì±„ì›€





------





## **âš™ï¸ ì£¼ìš” íŒŒë¼ë¯¸í„°**



| **íŒŒë¼ë¯¸í„°**   | **ì„¤ëª…**                                          |
| -------------- | ------------------------------------------------- |
| alpha=0.0      | ê· í˜• (ëª¨ë“  í´ë˜ìŠ¤ ë™ì¼í•˜ê²Œ ë³µì œ)                  |
| alpha=1.0 ì´ìƒ | ë¹ˆë„ ì ì€ í´ë˜ìŠ¤ì¼ìˆ˜ë¡ ë” ë§ì´ ë³µì œ â†’ ë¶ˆê· í˜• ì‹¬í™” |
| min=10         | ê° í´ë˜ìŠ¤ê°€ train/testì— ìµœì†Œ 10ê°œëŠ” ìˆë„ë¡ ë³´ì¥  |



------





## **âœ… ì‚¬ìš© ì˜ˆì‹œ**



```
X_train_imb, X_test, y_train_imb, y_test = imbalance_by_inverse_frequency_with_strength_min10(
    X, y, alpha=2.0
)
```



------



í•„ìš”í•˜ì‹œë©´:



- train/test í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜
- alpha ê°’ì— ë”°ë¥¸ imbalance ë³€í™” ì‹¤í—˜ìš© loop





ë„ ì¶”ê°€ë¡œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 



ì¢‹ìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” imbalance_by_inverse_frequency_with_strength í•¨ìˆ˜ì˜ **ìˆ˜ì‹ í‘œí˜„**ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” min 10ê°œ ë³´ì¥ ì¡°ê±´ì€ ì œì™¸í•˜ê³ , **í´ë˜ìŠ¤ë³„ inverse frequencyë¥¼ ê¸°ë°˜ìœ¼ë¡œ oversampling ë¹„ìœ¨ì„ ì¡°ì ˆí•˜ëŠ” ë°©ì‹**ë§Œ ìˆ˜ì‹í™”í•˜ì˜€ìŠµë‹ˆë‹¤.



------





## **ğŸ“˜ ìˆ˜ì‹ ì •ì˜**







### **ì£¼ì–´ì§„ ì •ë³´**





- ì „ì²´ ë°ì´í„°ì…‹:

  \mathcal{D} = \{(x_i, y_i)\}_{i=1}^N

- í´ë˜ìŠ¤ ì§‘í•©:

  \mathcal{C} = \{c_1, c_2, \dots, c_K\}

- í´ë˜ìŠ¤ c_kì˜ ë¹ˆë„ (ì „ì²´ ë°ì´í„° ê¸°ì¤€):

  f_k = \frac{|\{i : y_i = c_k\}|}{N}





------





## **ğŸ§  Oversampling ë¹„ìœ¨ ê³„ì‚°**

### **1. ê° í´ë˜ìŠ¤ì˜ ê°€ì¤‘ì¹˜ ì •ì˜ (Inverse frequency with strength Î±)**

$w_k = \left(\frac{1}{f_k}\right)^\alpha$

- $\alpha$ = 0ì´ë©´ ê· ë“± ê°€ì¤‘ì¹˜ â†’ ëª¨ë“  í´ë˜ìŠ¤ ë™ì¼
- $\alpha > 0$ì´ë©´ rare classì¼ìˆ˜ë¡ ë” ë†’ì€ ê°€ì¤‘ì¹˜





### **2. ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜**

$\tilde{w}_k = \frac{w_k}{\sum_{j=1}^K w_j}$.





### **3. í´ë˜ìŠ¤ë³„ oversampling ìˆ˜ (train ì´ ìƒ˜í”Œ ìˆ˜ë¥¼** N_{\text{train}}**ì´ë¼ í•  ë•Œ)**

$n_k = \left\lfloor \tilde{w}_k \cdot N_{\text{train}} \right\rfloor$.

- ê° í´ë˜ìŠ¤ $c_k$ì— ëŒ€í•´, $n_k$ê°œ ìƒ˜í”Œì„ ë³µì œ ì¶”ì¶œ (with replacement)
- ì „ì²´ì ìœ¼ë¡œëŠ” $\sum_{k=1}^K n_k \approx N_{\text{train}}$





## **âœ… ê²°ê³¼**

- train setì€ $\{(x_i, y_i)\}$ ì¤‘ oversampledëœ n_kê°œì”© í´ë˜ìŠ¤ë³„ í¬í•¨
- test setì€ train_test_splitì„ í†µí•´ ë¬´ì‘ìœ„ ê· ë“± ë¶„í• ë¨







ë‚˜ëŠ” tabular dataì˜ y class labelì˜ distribution shift ìƒí™©ì„ ê°€ì •í•˜ê³ ì, ê¸°ì¡´ì˜ ë°ì´í„°ì…‹ì˜ ë¶„ë¦¬ ë°©ì‹ì— ë³€í™”ë¥¼ ì£¼ì—ˆì–´.

- (ê¸°ì¡´) train:test = 50:50ìœ¼ë¡œ ë‚˜ëˆ”.
  - ë”°ë¼ì„œ, estimated ê°’ìœ¼ë¡œ, trainê³¼ testì˜ y label ë¶„í¬ëŠ” ê°™ì„ ê²ƒ.
- (ë³€í™”) ì•„ë˜ì˜ `imbalance_by_inverse_frequency_with_strength_min10` í•¨ìˆ˜
  - Step 1) train:test = 50:50ìœ¼ë¡œ ë‚˜ëˆ”.
    - (ê¸°ì¡´)ê³¼ ë™ì¼í•˜ê²Œ 50:50ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì´ìœ ëŠ”, ìµœì¢…ì ìœ¼ë¡œ test ì„±ëŠ¥ì„ ì¸¡ì •í•  ë•Œ, (ê¸°ì¡´)ì˜ ë°©ì‹ê³¼ ì°¨ì´ê°€ ë‚˜ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•´ì„œ, testëŠ” ìµœëŒ€í•œ ë³€í™”ë¥¼ ì£¼ì§€ ì•Šê²Œ í•˜ë ¤ê³  í–ˆìŒ.
  - Step 2) train ë°ì´í„°ì…‹ì„ oversampling í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ imbalanceë¥¼ ìœ ë„í•¨.



ì•„ë˜ì˜ `imbalance_by_inverse_frequency_with_strength_min10` ë¥¼ í†µí•´, ë‚´ê°€ ì–´ë– í•œ ì‹ìœ¼ë¡œ ë³€í™”ë¥¼ ì£¼ì—ˆëŠ”ì§€

- (1) ìˆ˜ì‹ (Mathematical expression)ìœ¼ë¡œ ì„¤ëª…
- (2) ì œì•ˆí•œ ë¶„ë¦¬ë°©ì‹ì˜ ë³€í™”ì— ëŒ€í•œ ì˜ì–´ ì„¤ëª… (in paragraph)
- (3) ì œì•ˆí•œ ë¶„ë¦¬ë°©ì‹ì˜ ë³€í™”ì— ëŒ€í•œ ì˜ì–´ ì„¤ëª… (in brief itemized format)
- (4) ì œì•ˆí•œ ë¶„ë¦¬ë°©ì‹ì˜ ë³€í™”ì— ëŒ€í•œ ì˜ì–´ ì„¤ëª… (in detailed itemized format)

ì´ ë„¤ ê°€ì§€ë¥¼ ì°¨ë¡€ë¡œ ì„¤ëª…í•´ì¤˜.



ì´ì œ `imbalance_by_inverse_frequency_with_strength_min10` ë¥¼ ë³´ì—¬ì¤„ê²Œ.

```
def imbalance_by_inverse_frequency_with_strength_min10(X, y, test_size=0.5, alpha=1.0, random_state=42):
    """
    Step 1: Split data into train/test using scikit-learn's train_test_split with 50:50 ratio.
    Step 2: Induce class imbalance in the training set by oversampling inversely to class frequency^alpha,
            while ensuring each class has at least 10 samples in both train and test sets.

    Parameters:
    - X, y: input features and labels
    - test_size: proportion for the test set (default 0.5)
    - alpha: imbalance strength (0 = uniform, higher = stronger imbalance)
    - random_state: random seed for reproducibility

    Returns:
    - X_train_imbalanced, X_test_final, y_train_imbalanced, y_test_final
    """
    from sklearn.model_selection import train_test_split
    from sklearn.utils import shuffle
    import numpy as np

    X = np.asarray(X)
    y = np.asarray(y)

    # Step 1: 50-50 stratified split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, stratify=y, random_state=random_state
    )

    # Step 2: Compute inverse-frequency^alpha weights from full data
    class_labels, counts = np.unique(y, return_counts=True)
    freqs = counts / counts.sum()
    imbalance_weights = (1.0 / freqs) ** alpha
    imbalance_weights = imbalance_weights / imbalance_weights.sum()

    # Determine number of samples to draw from each class in train set
    total_train_samples = len(y_train)
    samples_per_class = {
        cls: max(10, int(imbalance_weights[i] * total_train_samples))
        for i, cls in enumerate(class_labels)
    }

    # Oversample train set
    X_train_imbalanced, y_train_imbalanced = [], []
    rng = np.random.default_rng(random_state)
    for cls in class_labels:
        cls_indices = np.where(y_train == cls)[0]
        n_samples = samples_per_class[cls]

        if len(cls_indices) == 0:
            continue

        resampled_idx = rng.choice(cls_indices, size=n_samples, replace=True)
        X_train_imbalanced.append(X_train[resampled_idx])
        y_train_imbalanced.append(y_train[resampled_idx])

    # Step 3: Filter test set to ensure at least 10 samples per class
    X_test_filtered, y_test_filtered = [], []
    for cls in class_labels:
        cls_indices = np.where(y_test == cls)[0]
        if len(cls_indices) >= 10:
            X_test_filtered.append(X_test[cls_indices])
            y_test_filtered.append(y_test[cls_indices])
        else:
            # Fill with duplicated samples if fewer than 10
            resampled_idx = rng.choice(cls_indices, size=10, replace=True)
            X_test_filtered.append(X_test[resampled_idx])
            y_test_filtered.append(y_test[resampled_idx])

    return (
        np.vstack(X_train_imbalanced),
        np.vstack(X_test_filtered),
        np.hstack(y_train_imbalanced),
        np.hstack(y_test_filtered)
    )
```





ì•„ë˜ëŠ” ì£¼ì‹  í•¨ìˆ˜ imbalance_by_inverse_frequency_with_strength_min10 ì— ëŒ€í•œ ìš”ì²­í•œ ë„¤ ê°€ì§€ í•­ëª©ì…ë‹ˆë‹¤:



------





## **âœ… (1) ìˆ˜ì‹ í‘œí˜„ (Mathematical Expression)**

ì£¼ì–´ì§„ ì „ì²´ í´ë˜ìŠ¤ ë¶„í¬ $p(y = c_k) = f_k$ (í´ë˜ìŠ¤ ë¹ˆë„ ë¹„ìœ¨) ì— ëŒ€í•´,

í›ˆë ¨ ë°ì´í„°ì˜ í´ë˜ìŠ¤ $c_k$ì— ëŒ€í•œ **oversampling ìˆ˜**ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤:



w_k = \left( \frac{1}{f_k} \right)^\alpha, \quad \tilde{w}k = \frac{w_k}{\sum{j} w_j}



n_k^{\text{train}} = \max\left(10, \left\lfloor \tilde{w}k \cdot N{\text{train}} \right\rfloor\right)



- f_k: ì „ì²´ ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ c_kì˜ ë¹„ìœ¨
- \alpha: imbalance ì¡°ì ˆ ê°•ë„
- N_{\text{train}}: split ì´í›„ train setì˜ ì´ ìƒ˜í”Œ ìˆ˜
- n_k^{\text{train}}: oversamplingëœ train ë°ì´í„°ì—ì„œ í´ë˜ìŠ¤ c_kì˜ ìƒ˜í”Œ ìˆ˜





â†’ ì´ë¡œ ì¸í•´ ì‹¤ì œ train ë¶„í¬ëŠ”:



\hat{p}_{\text{train}}(y = c_k) = \frac{n_k^{\text{train}}}{\sum_j n_j^{\text{train}}}



â€» test setì€ stratified split í›„ ê° í´ë˜ìŠ¤ ìµœì†Œ 10ê°œ ì´ìƒì´ ë˜ë„ë¡ ë³´ì¥ (resample í¬í•¨)



------





## **âœ… (2) Paragraph ì„¤ëª… (in English)**





In the original setup, the dataset was divided evenly into training and testing sets (50:50), preserving the label distribution in both subsets. To simulate a label distribution shift while keeping the test distribution consistent, we introduced a new data splitting scheme via the imbalance_by_inverse_frequency_with_strength_min10 function. First, a stratified 50:50 split ensures a fair test set. Then, class imbalance is artificially introduced into the training set by oversampling classes inversely proportional to their original frequencies raised to a tunable power \alpha. As a result, rare classes become overrepresented in the training set while the test set remains close to the original distribution, thereby simulating a label shift scenario between training and testing.



------





## **âœ… (3) Brief Itemized Summary (in English)**





- Original split: 50:50 train:test with preserved class distribution

- New split:

  

  - Still 50:50 to keep test evaluation comparable
  - Induce imbalance in train via inverse-frequency-based oversampling

  

- Rare classes are overrepresented in train

- Test remains close to original label distribution





------





## **âœ… (4) Detailed Itemized Explanation (in English)**



\begin{itemize}
    \item \textbf{Original splitting:} The dataset is divided into training and test subsets with a 50:50 ratio using stratified sampling, ensuring the label distributions are approximately equal.
    \item \textbf{Motivation for change:} To simulate label distribution shift between training and test without altering the test set too much, while still allowing fair evaluation.
    \item \textbf{Step 1 (Split):} The 50:50 stratified split is retained to ensure the test set reflects the same distribution as the original data.
    \item \textbf{Step 2 (Train imbalance):} The training set is oversampled such that the number of samples per class is proportional to the inverse of their original class frequencies raised to the power of \( \alpha \). This makes rare classes more frequent in the training set.
    \item \textbf{Step 3 (Test guarantee):} The test set is filtered (or resampled if necessary) to guarantee a minimum of 10 samples per class, preserving class diversity.
    \item \textbf{Result:} The label distribution in the training set is skewed (according to \( \alpha \)), while the test set remains balanced, effectively simulating a distribution shift setting.
\end{itemize}



------

# ìµœì¢…

## Label Shift Simulation via Inverse Frequency Oversampling

To simulate a distribution shift between training and test sets, we modify the standard stratified split by applying inverse-frequency-based oversampling to the training set. The process is as follows:

Given an original dataset with features $X$ and labels $y$, we first split it into training and test sets using a stratified 50:50 split, following the previous works. 

Let $\mathcal{C} = \{c_1, c_2, \ldots, c_K\}$ denote the set of class labels, and $f_k$ be the empirical frequency of class $c_k$ in the full dataset:
$f_k = \frac{|\{i : y_i = c_k\}|}{N}$, where $N$ is the total number of samples.

To induce class imbalance in the training set, we define oversampling weights using an inverse frequency scaling:
$w_k = \left( \frac{1}{f_k} \right)^\alpha, \quad \tilde{w}_k = \frac{w_k}{\sum_{j=1}^{K} w_j}$,
where $\alpha \geq 0$ controls the imbalance strength. 

A higher value of $\alpha$ leads to stronger overrepresentation of rare classes.

The number of training samples drawn for each class is then given by:
$n_k^{\text{train}} = \max\left(10, \left\lfloor \tilde{w}_k \cdot N_{\text{train}} \right\rfloor \right)$,
ensuring that each class has at least 10 samples. 

Oversampling is performed with replacement.

Meanwhile, the test set remains close to the original label distribution due to the stratified split. To ensure adequate representation, we resample any class with fewer than 10 test instances to guarantee a minimum of 10 per class.

This results in a training set with an intentionally skewed label distribution, while maintaining a balanced test set, thereby creating a controlled label shift scenario.



# ìµœìµœì¢…

### Inducing Label Distribution Shift via Controlled Oversampling

- [ê°œìš”] To simulate label distribution shift between training and test data,  we construct a procedure that selectively alters the class distribution of the training set while preserving that of the test set. 

- [Step 1] First, the original dataset $(X, y)$ is split into training and test subsets using a stratified 50:50 split, following prior work to ensure that the test set preserves the original label distribution and enables fair comparison across experimental settings. 
- [Step 2] After the split, we induce a distribution shift between the training and test label distributions by oversampling each class in the training set according to the inverse of its empirical frequency.



[Step2 -detail] 

- Specifically, let $\mathcal{C} = \{c_1, c_2, \ldots, c_K\}$ denote the set of class labels, and $f_k$ be the relative frequency of class $c_k$ in the original dataset: $f_k = \frac{|\{i : y_i = c_k\}|}{N}$ where $N$ = total number of samples.
- To control the degree of shift, we compute the normalized oversampling weights as: $w_k = \left( \frac{1}{f_k} \right)^\alpha$,  $\tilde{w}_k = \frac{w_k}{\sum_{j=1}^{K} w_j}$ where $\alpha \geq 0$ is a scalar hyperparameter.  We then draw $n_k^{\text{train}} = \left\lfloor \tilde{w}_k \cdot N_{\text{train}} \right\rfloor $ samples for each class $k$ in the training set.
- The result is a training set whose class distribution intentionally deviates from the original, while the test set remains stratified and optionally resampled to ensure a minimum of 10 examples per class.




The parameter $\alpha$ serves as an **imbalance strength factor**, controlling how strongly rare classes are emphasized in the training set. 

- When $\alpha = 0$, each class is sampled uniformly, maintaining a balanced training distribution. 
- As $\alpha$ increases, the sampling becomes more biased toward rare classes, amplifying the disparity between training and test label distributions. 
- Thus, larger values of $\alpha$ correspond to more severe label shift scenarios.



```


```



N_train ì¸ë±ìŠ¤ ë½‘ì•„ì„œ inference ì‹œì—ë„ ì ìš©

ì–´ë–»ê²Œ ê³ ì •ë˜ê²Œ?

<img src="/Users/seunghan96/Library/Application Support/typora-user-images/image-20250622161805417.png" alt="image-20250622161805417" style="zoom:50%;" />
