---
title: R-CNN
categories: [DL,CV]
tags: [Deep Learning, CV]
excerpt: Object Detection, R-CNN
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# [ R-CNN ]

### Region-Based Convolutional Neural Network

- 2014년 CVPR에서 등장한 모델

<br>

# 1. 구조

![figure2](/assets/img/cv/cv56.png)

- (Step 1) Bounding Box 생성

- (Step 2) warping 시킴

- (Step 3) CNN 모델에 집어넣음

- (Step 4) Classification

Region Proposal을 한 뒤, Classification을 하는 **2-stage detector**이다

<br>

# 2. (Step 1,2) Region Proposal

"**물체의 영역/위치**를 찾아내는 Module" ( 물체의 class와는 무관 )

![figure2](/assets/img/cv/cv57.png)

Region Proposal : 위 그림에서 처럼, 관심 있는 영역 (Region of Interest)를 proposal하게 된다.

( with Selective Search )

<br>

### Selective Search

- 객체의 주변과 색감/질감 차이/에워싸임 여부 등을 파악

  $$\rightarrow$$ 이를 통해 물체의 위치를 파악!

- 처음에는 여러 개의 Bounding Box를 생성

- 이들을 조금씩 합쳐나가서 거대한 소수의 Bounding Box로 만듬

![figure2](/assets/img/cv/cv58.png)

<br>

### Warping Images

![figure2](/assets/img/cv/cv59.png)

- bounding box의 크기들은 모두 다르다

- 그래도, CNN의 input으로 넣기 위해, 위의 크기와 무관하게 CNN의 input size로 일치시켜서 왜곡해서 집어넣는다.

  ( 비율, 위치 등의 문제가 왜곡될 수 밖에 없다 )

<br>

# 3. (Step 3) CNN

Alex Net의 structure를 사용하여 feature를 뽑아냈다.

![figure2](/assets/img/cv/cv60.png)

<br>

# 4. (Step 4) Classification

![figure2](/assets/img/cv/cv61.png)

overfitting 방지를 위해, NN 대신 고전적인 SVM을 사용하였다

<br>

문제점 : CNN과 SVM 학습이 별도로 이루어지게 된다

<br>

# 5. Bounding Box Regression

**key : 물체의 위치를 찾아내는 것을 Regression 문제로써 푼다!**

( 물체의 위치(중앙점), 높이, 너비를 예측하는 문제로써 푼다 )

- 위에서 언급한 Selective Search Bounding Box는 너무 rough하게 찾아낸 다.

- 따라서, 물체의 위치를 보다 정확하게 파악하기 위해, Bounding Box Regression을 사용한다.

![figure2](/assets/img/cv/cv62.png)

<br>

Notation : 

- $$x,y$$ (위치) 
- $$w$$ (너비)
- $$h$$ (높이)
- $$P$$(선택된 bounding box)
- $$G$$ (실제 bounding box)

<br>

$$\left\{\left(P^{i}, G^{i}\right)\right\}_{i=1, \ldots, N}$$, where $$P^{i}=\left(P_{x}^{i}, P_{y}^{i}, P_{w}^{i}, P_{h}^{i}\right)$$.

<br>

예측 값들

- $$\hat{G}_{x} =P_{w} d_{x}(P)+P_{x}$$.

- $$\hat{G}_{y} =P_{h} d_{y}(P)+P_{y}$$.

- $$\hat{G}_{w} =P_{w} \exp \left(d_{w}(P)\right)$$.

- $$\hat{G}_{h} =P_{h} \exp \left(d_{h}(P)\right)$$.

<br>

위 예측 값들을 $$t$$ 로 변환한 뒤, 

- $$t_{x} =\left(G_{x}-P_{x}\right) / P_{w}$$.
- $$t_{y} =\left(G_{y}-P_{y}\right) / P_{h}$$.
- $$t_{w} =\log \left(G_{w} / P_{w}\right)$$.
- $$t_{h} =\log \left(G_{h} / P_{h}\right)$$.

<br>

아래의 loss function을 minimize하는 방향으로 최적의 parameter를 찾아낸다.

- $$\mathbf{w}_{\star}=\underset{\hat{\mathbf{w}}_{\star}}{\operatorname{argmin}} \sum_{i}^{N}\left(t_{\star}^{i}-\hat{\mathbf{w}}_{\star}^{\mathrm{T}} \boldsymbol{\phi}_{5}\left(P^{i}\right)\right)^{2}+\lambda\left\|\hat{\mathbf{w}}_{\star}\right\|^{2}$$.

<br>

# 6. Disadvantages

- 1) 오랜 학습 시간

  - selective search로 2000개의 bounding box를 찾아냄

    ( + 이에 대해 모두 CNN 돌림 )

- 2) 복잡한 알고리즘

  - Multi-stage Training
  - CNN, SVM, Bounding Box Regression, 3가지 모델 모두 사용

- 3) Back-prop 불가

  - SVM, Bounding Box regression 때문에 한번에 back-prop 불가!

  