---
title: Dynamic Expandable Representation (DER)
categories: [CONT, CV]
tags: []
excerpt: CVPR 2021 Oral
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<br>

# Dynamic Expandable Representation (DER) (CVPR 2021 Oral)

https://arxiv.org/abs/2103.16788

```
Yan, Shipeng, Jiangwei Xie, and Xuming He. "Der: Dynamically expandable representation for class incremental learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.
```

<br>

# Contents

0. Abstract

1. Introduction
2. Methodology
   1. Problem Setup & Method Overview
   2. Expandable Representation Learning
   3. Dynamic Expansion

3. Experiments
   1. Dataset
   2. Dataset for CL
   3. Results


<br>

# Abstract

DER (Dynamically Expandable Representation)

- **Problem definition**: 제한된 메모리 환경에서의 CIL
- **Key Idea**: 
  - 각 CIL 단계에서 기존의 representation 고정 +  
    새로운 학습 가능한 feature extractor를 추가하여 representation을 확장

<br>

# 1. Introduction

문제 상황: **안정성-가소성(stability-plasticity) 딜레마**

기존 방법론의 한계점

- (1) Regularization
  - 중요한 가중치의 변화를 억제하지만, 모델의 가소성을 제한
- (2) Knowledge distillation: 
  - 이전 모델의 출력을 보존하지만, 오래된 개념의 특성 퇴화로 인해 망각에 취약

<br>

DER의 해결책

- 두 단계의 학습 전략 (Two-stage strategy)
- 동적으로 확장 가능한 표현 (Dynamically expandable representation)

<br>

**Main contribution**:

- Dynamically expandable representation & Two-stage strategy for CIL
- Auxiliary loss: 새롭게 추가된 feature module이 새로운 class를 효과적으로 배우도록

<br>

# 2. Methodology

![figure2](/assets/img/CONT/img31.png)

<br>

## (1) Problem Setup & Method Overview

- **CIL (클래스 증분 학습)**: 
  - 모델은 순차적으로 새로운 클래스 그룹과 해당 데이터를 관찰
  - 모든 관찰된 클래스에 대해 잘 예측해야!
- **DER의 학습 전략**
  - Rehersal: 이전 task 데이터를 일부 저장
  - Two-stage training: 두 단계의 학습 과정을 통해 모델을 업데이트

<br>

## (2) Expandable Representation Learning

Step $$t$$: 아래의 둘로 구성됨

- Super-feature extractor $$\Phi_t$$ 
- Classifier $$\mathcal{H}_t$$

<br>

a) Super-feature extractor $$\Phi_t$$ : (1) + (2)

- (1) Super-feature extractor $$\Phi_{t-1}$$ 
- (2) (Newly created) feature extractor $$\mathcal{F}_t$$. 
- 예시) Image $$x \in \overline{\mathcal{D}}_t$$
  - $$\Phi_t$$ 에 의해 생성된 잠재벡터 $$u$$ : $$\boldsymbol{u}=\Phi_t(\boldsymbol{x})=\left[\Phi_{t-1}(\boldsymbol{x}), \mathcal{F}_t(\boldsymbol{x})\right]$$.
  - 즉,  과거의 $$\mathcal{F}_1, \ldots, \mathcal{F}_{t-1}$$ & 새로운 $$\mathcal{F}_t$$ 를 활용하여 new classes를 배움

<br>

b) Classifier $$\mathcal{H}_t$$ 

- $$P_{\mathcal{H}_t}(\boldsymbol{y} \mid \boldsymbol{x})=\operatorname{Softmax}\left(\mathcal{H}_t(\boldsymbol{u})\right)$$.
- Prediction:  $$\hat{y}=\arg \max p_{\mathcal{H}_t}(\boldsymbol{y} \mid \boldsymbol{x}), \hat{y} \in \overline{\mathcal{Y}}_t$$. 

<br>

기타 2가지 사항

- (1) Parameters of $$\mathcal{H}_t$$ : Inherited from $$\mathcal{H}_{t-1}$$ to retain old knowledge!

  ( + Newly added parameters are randomly initialized )

- (2) Freeze the learned function $$\Phi_{t-1}$$ at step $$t$$, 
  - 과거 task데이터의 본질을 잘 capture하므로

<br>

### Training Loss 

Cross-entropy loss 

- $$\mathcal{L}_{\mathcal{H}_t}=-\frac{1}{ \mid \tilde{\mathcal{D}}_t \mid } \sum_{i=1}^{ \mid \tilde{\mathcal{D}}_t \mid } \log \left(p_{\mathcal{H}_t}\left(y=y_i \mid x_i\right)\right)$$.

<br>

### Auxiliary loss 

(For novel feature $$\mathcal{F}_t(\boldsymbol{x})$$)

Auxiliary classifier $$\mathcal{H}_t^a$$

- $$p_{\mathcal{H}_i^c}(\boldsymbol{y} \mid \boldsymbol{x})=\operatorname{Softmax}\left(\mathcal{H}_i^a\left(\mathcal{F}_t(\boldsymbol{x})\right)\right.$$.

목표?

- 새로운 feature로 하여금 discriminate between old vs. new concepts
  - New = 새로운 카테고리 1개
  - Old = 나머지 모든 과거 카테고리들 1개로 묶어서

Loss: $$\mathcal{L}_{E R}=\mathcal{L}_{H_0}+\lambda_\omega \mathcal{L}_{H_5}$$.

<br>

## (3) Dynamical Expansion

목적: For 효율적인 모델

- Remove the model redundancy
- Maintain a compact representation

<br>

How? ***Dynamically expand the superfeature according to the complexity of novel concepts***

- Differentiable channel-level mask based method
- 불필요 channel pruning위해!
- 결과: Pruned network $$\mathcal{F}_1^P$$

<br>

### Channel-level Masks 

Differentiable channel-level masks를 제안 (feat. HAT [3])

<br>

Notation

- $$f_l$$: $$l$$번째 layer의 feature map
- $$m_l \in \mathbb{R}^{c_l}$$: 제안한 channel mask
  - $$m_l=\sigma\left(s e_l\right)$$를 통해 0~1사이로 ㅁmapping
    - $$e_l$$: learnavble mask param
    - $$s$$: scaling factor

$$\rightarrow$$: $$f_l^{\prime}=f_l \odot m_l$$:  Masked feature map

<br>

Super-feature $$\tilde{u}$$ of step $$t$$

- $$\tilde{u}_t^P(x) = \Phi_t^P(x) = [\mathcal{F}_1^P(x), \mathcal{F}_2^P(x), ..., \phi_t(x)]$$.

- For inference...

  Assign $$s$$ a large value to binarize masks & obtain pruned network $$\mathcal{F}_t^P$$

  $$\rightarrow$$  $$\phi_t(x) = \mathcal{F}_t^P(x)$$

<br>

**Mask Learning** 

Linear annealing schedule for $$s$$

$$s = \frac{1}{s_{\max}} + \left(s_{\max} - \frac{1}{s_{\max}} \right) \frac{b - 1}{B - 1} \tag{8}$$.

- $$b$$: batch index

<br>

### Sparsity Loss

- 목적: 성능 감소 최소화하면서, 최대한 파라미터 수 줄이도록!
- Sparsity loss based on the ratio of used weights 
- $$\mathcal{L}_S = \frac{\sum_{l=1}^L K_l \mid  \mid \mathbf{m}_{l-1}\mid  \mid _1 \mid  \mid \mathbf{m}_l\mid  \mid _1}{\sum_{l=1}^L K_l C_{l-1} C_l} \tag{10}$$.
  - $$L$$ : Number of layers
  - $$K_l$$: Kernel size of CNN

<br>

### 최종 Loss

$$\mathcal{L}_{DER} = \mathcal{L}_{\mathcal{H}_t} + \lambda_a \mathcal{L}_{\mathcal{H}_t^a} + \lambda_s \mathcal{L}_S \tag{11}$$.

<br>

# 3. Experiments

## (1) Dataset

**CIFAR-100**

- 32×32 RGB 컬러 이미지
- 100개 class
- 학습용 50,000장 (클래스당 500장), 테스트용 10,000장 (class당 100장)

**ImageNet-1000**

- 1,000개 class
- 학습용 약 120만 장, 검증용 50,000장

**ImageNet-100**

- ImageNet-1000에서 100개 class를 선택해 구성된 서브셋

<br>

## (2) Dataset for CL

### a) CIFAR100

1. **CIFAR100-B0** 

   - B0 = Base 없음

   - 요약: CIFAR-100 데이터셋을 사용하여, **모델이 처음부터 아무 클래스도 모르는 상태에서**, **100개 클래스를 여러 단계로 나누어 순차적으로 학습하는 프로토콜**

   - 100개 class를 여러 개의 task로 분할

   - 분할 수: 5, 10, 20, 50 단계 (step)

     - 5 task → task마다 20개 class
     - 10 task → task마다 10개 class
     - 20 task → task마다 5개 class
     - 50 task → task마다 2개 class

     ( **step 수가 많을수록 더 hard 설정** )

2. **CIFAR100-B50** ([12] 기반)

   - B50 = Base 50개
   - 처음 50개 class로 모델 사전 학습
   - 이후 나머지 50개 class를 task로 나눔
     - 분할 수: 2, 5, 10 단계
   - Class당 메모리 20장 유지

<br>

### b) ImageNet-100

1. **ImageNet100-B0** ([27] 기반)

   - 100개 클래스를 10개씩 분할하여 학습 시작 (from scratch)
   - 전체 메모리 예시 수: 2,000장

2. **ImageNet100-B50** ([12] 기반)

   - 먼저 50개 class로 학습된 모델에서 시작
   - 나머지 50개 class를 10단계로 증분 학습
   - Class당 메모리 20장 유지

   

<br>

## (3) Results

![figure2](/assets/img/CONT/img32.png)

![figure2](/assets/img/CONT/img33.png)

