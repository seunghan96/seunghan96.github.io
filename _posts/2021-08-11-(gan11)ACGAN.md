---
title: \[Paper Review\] 11.(conditioning) Conditional Image Synthesis with ACGANs
categories: [GAN]
tags: [GAN]
excerpt: 2017, ACGAN
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# \[Paper Review\] 11. Conditional Image Synthesis with ACGANs

<br>

### Contents

0. Abstract
1. Introduction
2. Related work
   1. Multi-modal Learning for Image labeling
3. Conditional Adversarial Nets
   1. GAN
   2. CGAN
4. Experimental Results
   1. Unimodal ( data : MNIST )
   2. Multimodal ( data : Flickr )

<br>

# 0. Abstract

construct a variant of GANs, employing **label conditioning**, 
that results in **128 $\times$ 128** resolution image samples, exhibiting **global coherence**

<br>

2 new analysis for assessing the **(1) discriminability** and **(2) diversity**

<br>

demonstrate that ***high resolution samples provide class information not present in low resolution samples***

<br>

# 1. Introduction

GANs can produce convincing image samples on datasets, with **LOW variability and LOW resolution**

However, GANs struggle to generate **globally coherent, high resolution samples**

- especially from datasets with **HIGH variability**

<br>
Show that adding **more structure** to GAN latent space ( + specialized cost function )

$\rightarrow$ **higher quality samples**

<br>

Exhibit **128x128 pixel** samples from all classes of **ImageNet dataset**

( with **increased global coherence** )

![figure2](/assets/img/gan/img20.png)

<br>

**Higher resolution** $\neq$ resizing of low resolution samples

<br>
Introduce new metric for assessing **variability**

<br>

# 2. Background

notation : 

- $S$ : source ( Fake / Real )
- $D,G$ : discriminator, generator
- generator : $X_{\text {fake }}=G(z)$
  - minimize $L=E\left[\log P\left(S=\text { fake } \mid X_{\text {fake }}\right)\right]$.
- discriminator : $P(S \mid X)=D(X)$
  - maximize $L=E\left[\log P\left(S=\text { real } \mid X_{\text {real }}\right)\right]+ E\left[\log P\left(S=\text { fake } \mid X_{\text {fake }}\right)\right]$.

<br>

### variants of GAN ( adding side information )

- [CGAN] supply both $G$ & $D$ with **class labels** 

  $\rightarrow$ improve the quality of generated samples

- 



A generative adversarial network (GAN) consists of two neural networks trained in opposition to one another. The generator $G$ takes as input a random noise vector $z$ and outputs an image $X_{\text {fake }}=G(z)$. The discriminator $D$ receives as input either a training image or a synthesized image from the generator and outputs a probability distribution $P(S \mid X)=D(X)$ over possible image sources. The discriminator is trained to maximize the log-likelihood it assigns to the correct source:
$$
\begin{array}{r}

\end{array}
$$