---
title: Lifelong Unsupervised Mixup (LUMP)
categories: [CONT, CV]
tags: []
excerpt: ICLR 2022
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<br>

# Representational Continuity for Unsupervised Continual Learning (ICLR 2022)

https://arxiv.org/pdf/2110.06976

```
Madaan, Divyam, et al. "Representational continuity for unsupervised continual learning." ICLR 2022
```

<br>

# Abstract

대부분의 Continual learning: **Supervised** 세팅

$\rightarrow$ This paper: **Unsupervised** 세팅 ... **UCL (Unsupervised Continual Learning)**

<br>

![figure2](/assets/img/CONT/img139.png)

<br>

#  1. Lifelong Unsupervised Mixup (LUMP)

![figure2](/assets/img/CONT/img140.png)

한 줄 요약:  **Mixup**을 통한 data augmentation 활용 

- (1) 현재 task 
- (2) 과거 task

<br>

$\mathcal{L}^{\text{Mixup}}(\tilde{x}, \tilde{y}) = \mathrm{CE}(h_\psi(f_\Theta(\tilde{x})), \tilde{y})$.

- $\tilde{x} = \lambda \cdot x_i + (1 - \lambda) \cdot x_j$.
-  $\tilde{y} = \lambda \cdot y_i + (1 - \lambda) \cdot y_j$.

<br>

# 2. Experiments

위 방법으로 pretrain이후, KNN classifier로 evaluation

![figure2](/assets/img/CONT/img141.png)

