---
title: GPU 설명
categories: [CV, MULT, LLM, NLP]
tags: []
excerpt: feat ChatGPT
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# GPU 설명

( feat. ChatGPT )

<br>

# 1. 주요 용어 설명

1. **아키텍처**

   - GPU 설계의 기본 구조
   - 세대별로 성능, 에너지 효율성, 지원 기능이 달라짐
   - e.g., Ampere, Hopper, Ada Lovelace.

2. **메모리 (VRAM)**

   - GPU에 탑재된 전용 메모리 용량

     $$\rightarrow$$ 대규모 데이터셋 및 모델을 처리하는 데 필수적.

   - 메모리가 클수록 더 많은 데이터를 병렬로 처리할 수 있음

3. **FP32/FP16 성능** 

   - FP32: 32비트 부동소수점 연산
   - FP16: 16비트 부동소수점 연산
   - 딥러닝에서는 FP16이 주로 사용되며, FP32에 비해 더 빠르고 적은 메모리를 사용.

4. **딥러닝 활용도**

   - GPU가 어떤 딥러닝 작업(훈련, 추론, 대규모 모델, 개인 연구 등)에 적합한지 나타냄

<br>

# 2. 아키텍처

1. **Ampere (암페어)**
   - **출시 시기**: 2020년
   - 특징
     - **FP16 Tensor Core**를 도입해 딥러닝 성능 대폭 향상
     - **Sparse Tensor** 지원으로 희소 데이터를 처리할 때 더 높은 효율 제공
     - 데이터 센터(A100)와 소비자용 GPU(RTX 3090, A6000) 모두에서 활용
2. **Hopper (호퍼)**
   - **출시 시기**: 2022년
   - 특징
     - **Transformer Engine** 추가로 대규모 AI 모델(예: GPT-4) 학습에 최적화
     - 더 높은 **FP8 성능**으로 정밀도를 희생하지 않고 연산 속도 증가
     - 대규모 데이터 처리와 초대형 언어 모델 학습에 강력
3. **Ada Lovelace (에이다 러브레이스)**
   - **출시 시기**: 2022년
   - 특징
     - 소비자용 GPU에 최적화된 아키텍처
     - 실시간 **레이 트레이싱 성능**과 **DLSS 3.0** 기술로 게임과 그래픽 작업에 탁월
     - 전력 효율성 개선과 높은 연산 성능 제공

| **아키텍처** | **주요 용도**               | **특징**                        | **적합한 사용자**          |
| ------------ | --------------------------- | ------------------------------- | -------------------------- |
| **Ampere**   | 딥러닝 연구 및 데이터 센터  | Tensor Core, Sparse Tensor 지원 | 연구자, 대규모 학습 환경   |
| **Hopper**   | 초대형 AI 모델 학습 및 추론 | Transformer Engine, FP8 지원    | 초대형 언어 모델 작업자    |
| **Ada**      | 소비자용 GPU 및 그래픽 작업 | 레이 트레이싱, DLSS 3.0         | 게임 애호가 및 개인 연구자 |

<br>

# 3. 비교 분석 표

| **모델**      | **아키텍처** | **메모리 (VRAM)** | **FP32 성능** | **FP16 성능** | **적합한 상황**                                              | **가격**             |
| ------------- | ------------ | ----------------- | ------------- | ------------- | ------------------------------------------------------------ | -------------------- |
| **A100**      | Ampere       | 40GB/80GB         | 19.5 TFLOPS   | 156 TFLOPS    | 데이터 센터 및 클라우드 환경에서 대규모 딥러닝 모델 훈련에 최적. 대규모 병렬 작업과 분산 학습, 멀티 태스크 처리에 탁월. | 약 \$10,000~\$15,000 |
| **H100**      | Hopper       | 80GB              | 60 TFLOPS     | 1000 TFLOPS   | 초대형 AI 모델(예: GPT-4)의 훈련 및 추론. 특히 Transformer Engine을 통해 자연어 처리, 이미지 생성 등 고성능 작업에 이상적. | 약 \$25,000 이상     |
| **RTX 4090**  | Ada Lovelace | 24GB              | 82.6 TFLOPS   | 330.2 TFLOPS  | 개인 연구자, 소규모 딥러닝 프로젝트 또는 혼합된 용도(게임 및 AI 연구)에서 최적의 비용 대비 성능. | 약 \$1,600~\$2,000   |
| **RTX A6000** | Ampere       | 48GB              | 38.7 TFLOPS   | 77.4 TFLOPS   | 안정성과 긴 작업 시간(예: 3D 렌더링, 영상 처리)이 중요한 환경. 대규모 모델 훈련에도 적합하며, 전문가용 워크스테이션에서 사용. | 약 \$4,500~\$5,000   |
| **RTX A5000** | Ampere       | 24GB              | 27.8 TFLOPS   | 55.6 TFLOPS   | 중규모 딥러닝 모델 훈련, 연구실 환경에서 사용. 적절한 가격과 성능으로 실험 및 개발 작업에 적합. | 약 \$2,000~\$2,500   |
| **RTX 3090**  | Ampere       | 24GB              | 35.6 TFLOPS   | 142.4 TFLOPS  | 개인 연구자 또는 개발자가 대규모 데이터셋 없이 딥러닝 연구를 진행할 때 적합. 게이밍과 딥러닝 작업을 병행하려는 사용자에게 추천. | 약 \$1,000~\$1,500   |

### 추가 설명

1. **A100 vs. H100**
   -  A100은 데이터 센터에서 효율적인 분산 학습을 위한 GPU로, 여러 작업을 동시에 처리하는 데 강점이 있음.
   -  H100은 최신 아키텍처로, 초대형 AI 모델과 같은 계산량이 많은 작업에 특화되어 있음.
2. **RTX 4090 vs. RTX 3090**
   - RTX 4090은 최신 소비자용 GPU로, 전 세대 대비 높은 성능과 에너지 효율성을 제공
   - RTX 3090은 여전히 강력한 성능을 제공하지만, 최신 작업에서는 4090에 비해 에너지 효율성이 낮음
3. **RTX A6000 vs. RTX A5000** 
   - A6000은 더 큰 VRAM 용량과 안정성을 요구하는 작업(예: 초고해상도 렌더링)에 적합
   - A5000은 중소규모 연구 환경에서 충분히 강력한 성능을 제공하며, 비용 효율적임.

