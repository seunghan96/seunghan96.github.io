# pg 1

네 저는 유저모델링 ai 팀의 이승한이라고 합니다.



그 다음으로 소개 드릴 논문은 **Time-VLM**이라는 논문으로

아실 수 있듯 

Time-series와 VLM이 결합된 형태의 연구라고 보실 수 있습니다.



그래서 에 대해 간략히 

- TS은  (비전이나 랭귀지 모델들에 비해) 아직까지 확실한한 foundation model 이 자리 잡지 못한 상황
- 비록 최근들어 몇개가 나오고 있기는 하지만, 여전히 아직 확실한 대세로는 자리 잡지 못하고 있는 상황
- 이러한 트렌드 속에서 나온 논문이라고 볼 수 있는데요



크게 두 가지 갈래로 연구가 나오고 있음

- 독자적으로 TS 데이터셋만으로 학습한 large model
- 다른 LLM/VLM등 다른 도메인의 힘을 빌려 사용한 모델

이 연구의 경우 후자라고 보시면 됩니다



이 논문도, 그 후자 계열로써, VLM에 time-series를 적용한 방법론으로 보면 됩니다

그러기 위해서는, 시계열을 다른 모달리티, 비전이나 텍스트가 되겠죠

로 변환할 필요가 있을 것입니다.

그렇게 변환한 뒤, 기존의 시계열 뿐만이아니라, 비전과 텍스트로써 표현된 데이터를 vlm에 입력으로 넣어 최종적으로 시계열 예측을 진행하는 모델로써 보시면 됩니다.



# pg 3

그래서 본 모델의 구성요소는 크게 세 가지로 구성

- 세부적으로 보실 것은 없고, 시계열을

  - 시계열 그 자체로
  - 이미지로 변환해서
  - 텍스트로 변환해서

  처리해주는 모듈로써 보시면 됩니다.





어찌보면 매우 간단해보일 수 있는 방법이나, 제가 본 논문을 선정하고 구성원 여러분께 소개한데에는 두가지 큰 이유가 있는데.

1.  멀티모달쪽에 계신분들께서 보시기엔 이게 꽤 단순한 아이디어 (?)라고 보실 수 있지만, 
   생각하시는 것 이상으로 TS에는 이러한 접목들이 비교적 최근에 이뤄지고 있다는 점
   (비록 LLM은 2년 전 즈음부터 있긴 했지만 (비록 대세로 자리잡지는 못했습니다))
   그리고 TS는 benchmark dataset의 크기가 상대적으로 작아서, 모델 사이즈도 그만큼 큰 것을 요구하지 않는 경우도 한 몫을 하는 것 같습니다.
2. 두번째로 이거를 선정한 이유가, 저희 팀에서 진행중인 안티치트 프로젝트도, 세부적인 디테일에서는 비록 차이가 나겠지만,
   장기적으로 이러한 방향성으로 나아가게 되지 않을까 해서 이를 공유드리고자 준비했습니다.



아시는 분들도 있으시겠지만, 모르시는 분들이 더 많다는 가정하에 말씀을 드리자면

- 현재 안티치트 프로젝트는 기본적으로 유저의 한 매치에서 남긴 로그들 및 과거 로그들을 aggregate해서 tabular data format으로 변환한 뒤, 이를 tabular 모델을 사용하여 분류를 하고 있습니다.

- 하지만, 이 과정에서 비록 효율화는 이뤄지겠지만, 정보 압축이나 temporal 정보들이 손실될 수 밖에 없고,

  그래서 비교적 최근에 VLM을 활용한 video classification task로 저희 안티치트 task를 formulate해서 풀고자 함.



이 때문에, 

- 유저의 플레이 영상, 즉 비전과 
- 유저의 기본적인 demographic한 정보를 텍스트로 줌으로써

분류를 할 수 있습니다.



기본적인 구조는 위와 같긴할텐데, 이제여기서 추가적으로 활용할 수 있는게

유저들의 로그 내역들도 함께 시계열 형식으로 계속해서 기록되고 있는데, 

이 정보들 또한 auxiliary하게 주면 좋겠다는 생각이 들어서 이러한 논문을 선정했습니다.



그래서 이러한 time series 정보를,  별도의 TS encoder와 별도의 projector로써 align 시킬수도 있고,

혹은 image로 변환한 뒤 기존의 pretrained image encoder로써 넣던지 할 수도 있을 것이라는 생각에

큰 틀에서보면 저희 팀이 향후 나아가려는 방향과 비슷하지 않을까해서 선정을 했습니다.







아시는 분들도 있으시겠지만, 모르시는 분들이 더 많다는 가정하에 말씀을 드리자면

- 현재 안티치트 프로젝트는 기본적으로 유저의 한 매치에서 남긴 로그들 및 과거 로그들을 aggregate해서 tabular data format으로 변환한 뒤, 이를 tabular 모델을 사용하여 분류를 하고 있습니다.

- 하지만, 이 과정에서 비록 효율화는 이뤄지겠지만, 정보 압축이나 temporal 정보들이 손실될 수 밖에 없고,

  그래서 비교적 최근에 VLM을 활용한 video classification task로 저희 안티치트 task를 formulate해서 풀고자 함.



이 때문에, 

- 유저의 플레이 영상, 즉 비전과 
- 유저의 기본적인 demographic한 정보를 텍스트로 줌으로써

분류를 할 수 있습니다.



기본적인 구조는 위와 같긴할텐데, 이제여기서 추가적으로 활용할 수 있는게

유저들의 로그 내역들도 함께 시계열 형식으로 계속해서 기록되고 있는데, 

이 정보들 또한 auxiliary하게 주면 좋겠다는 생각이 들어서 이러한 논문을 선정했습니다.



그래서 이러한 time series 정보를,  별도의 TS encoder와 별도의 projector로써 align 시킬수도 있고,

혹은 image로 변환한 뒤 기존의 pretrained image encoder로써 넣던지 할 수도 있을 것이라는 생각에

큰 틀에서보면 저희 팀이 향후 나아가려는 방향과 비슷하지 않을까해서 선정을 했습니다.







알겠습니다 👍 말씀해주신 내용을 발표용 **간단 영어 itemize** 형태로 정리해드릴게요.



------





- Current anti-cheat pipeline

  

  - Aggregate match logs into tabular format
  - Train tabular models for classification

  

- Limitation

  

  - Efficiency is gained, but
  - Loss of compressed and temporal information

  

- New approach

  

  - Formulate anti-cheat as **video classification** with VLMs
  - Use player gameplay video (vision)
  - Use player demographic info (text)

  

- Extension idea

  

  - Also leverage player **log history** (time series) as auxiliary input

  - Options:

    

    - Dedicated TS encoder + projector for alignment
    - Transform TS into images and use pretrained vision encoder

    

  

- Motivation for paper selection

  

  - Similar direction to our team’s future roadmap
  - Integrating vision, text, and time series for anti-cheat detection

  

