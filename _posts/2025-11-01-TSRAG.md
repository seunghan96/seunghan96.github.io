---
title: TS-RAG
categories: [TS, LLM, MULT]
tags: []
excerpt: arxiv 2025
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster

https://arxiv.org/pdf/2503.07649



# 1. Introduction

## (1) Motivation

기존의 TSFM & LLM-based TS forecaster:

- (장) 높은 정확도

- (단) **zero-shot forecasting** 상황에서는,

  - a) **non-stationary dynamics** 

  - b) **distribution shift** 

    에 대응하기 어렵다.

<br>

**문제점:**

- LLM fine-tuning: 
  - (장) Dataset별 적응력은 높지만
  - (단) **Cross-domain generalization** 이 약함
- TSFM :
  - (장) 강력하지만
  - (단) **외부 context** 를 활용 X

<br>

## (2) Proposal

**제안:** **TS-RAG** = RAG 개념을 TSF에 적용

- (요소 1) Pre-trained **retriever encoder** 
  - Query와 유사한 TS segment를 **knowledge base** 에서 검색.
- (요소 2)  **Adaptive Retrieval Mixer (ARM)** 
  - TSFM의 내부 representation과 융합

<br>

실험:  

- 7개 벤치마크에서 SOTA zero-shot 성능 (평균 6.84% 개선)
- **해석 가능성(interpretability)** 향상

<br>

# 2. Related Work

## (1) TSFM

(**Lag-Llama(2023)**, **TimeGPT-1(2023)**, **TimesFM(2023)**, **Chronos(2024)**, **Moirai(2024)**, **Time-MoE(2024)**)

- 공통점: 다양한 도메인 pretraining → strong generalization.
- 한계: 
  - **external context 통합 불가**
  - **zero-shot 적응력 부족**
  - **해석력 낮음** 



## (2) RAG for TSF

(**ReTime(2022)**, **RATD(2024)**, **RAFT(2025)**, **TimeRAG(2024)**)

- 한계: Retrieval을 활용하나 **fine-tuning 필요**!!

<br>

**RAF(2024)**: 

- Chronos를 backbone으로 사용하지만
- 한계점: 단순 concat 방식이라 **scalability** 와 **효율성** 문제

<br>

TS-RAG은 두 가지에서 차별점:

- (1) **fine-tuning 없이** 작동하고
- (2) **zero-shot forecasting** 을 위한 **adaptive retrieval fusion** 설계

<br>

# 3. TS-RAG for Zero-Shot Time Series Forecasting

## (1) Retrieval Knowledge Base

Dataset: knowledge base 구성은 어떻게?

- Chronos pretraining 데이터셋에서 **multi-domain subset** 을 샘플링

- 각 entry: **(context window xᵢ, embedding eᵢ, future horizon yᵢ)** 형태

<br>

Retriever encoder

- Pre-trained 상태
- **Embedding similarity (Euclidean distance)** 로 top-k retrieval 수행 .

<br>

## (2) Architecture

구성요소:

- (1) **TSFM Backbone** (예: Chronos-Bolt, GPT, T5, LLaMA 기반)
- (2) **Retriever Encoder** – pre-trained time series encoder
- (3) **Adaptive Retrieval Mixer (ARM)** – retrieved segments와 query representation 융합

![figure2](/assets/img/ts/img824.png)

<br>

## (3) Procedure (Forward)

1. Query embedding $$e_q$$ 생성
2. Knowledge base에서 top-k 유사 TS segment $${x_ᵢ, y_ᵢ}$$ 검색
3. Retrieved $$y_i$$ → MLP projector → embedding
4. Query + retrieved embeddings → **MHA** → **FFNN+ Dropout** → **Weighting & Mixing**
5. Output projection layer 

<br>

### **3.3 Pretraining & Inference**

[1] **Pretraining:**

- [Freeze] TSFM backbone & Retriever encoder는 **frozen**
- [Train] ARM & projector

<br>

[2] **Zero-shot inference:**

- (Task-specific fine-tuning 없이) 다양한 domain에 바로 적용 가능

<br>

# **4. Experiments**

## (1) Setup

Pretraining: 

- Chronos dataset 50M → Retrieval DB 5M pair (2.8M retrieval pairs).

Benchmarks: 

- **ETTh1, ETTh2, ETTm1, ETTm2, Weather, Electricity, Exchange Rate**.

Backbone: **Chronos-Bolt**.

Metrics: **MSE**, **MAE** .

<br>

## (2) Results

![figure2](/assets/img/ts/img825.png)

**TS-RAGChronos-bolt** 

- 모든 dataset에서 backbone 대비 평균 **3.54% (MSE)**, **1.43% (MAE)** 개선.
  - 특히 **Exchange Rate dataset** 에서 6.84% 향상.

- RAG의 retrieval이 **복잡한 temporal dependency** 를 잘 보완

<br>

## (3) Ablation

![figure2](/assets/img/ts/img826.png)

- **ARM vs Gate module:** 
  - ARM이 더 효과적 (adaptive attention 구조).

- **Retrieval Knowledge Base 유형 비교:**
  - In-domain > Multi-domain > Distribution-shift > Cross-domain.


<br>

![figure2](/assets/img/ts/img827.png)

- **Forecasting horizon 길이 증가 (96–720):**
  - RAG이 rolling forecasting 시 **error accumulation 완화**  

- **Retrieval 수(k) 및 lookback 길이 영향:**
  - k 증가 시 MSE 감소하나 일정 수준 이후 수렴
  - 긴 lookback window(512)가 가장 효과적 .


<br>

## (4) Comparison with RAF

![figure2](/assets/img/ts/img828.png)

- **Effectiveness:** TS-RAG 평균 MSE 0.1940 vs RAF 0.2320.
- **Efficiency:** Inference 속도 **3474 ms → 9.62 ms/iter**, 약 360× 빠름 (FAISS 기반)  (Table 3).

<br>

## (5) Interpretability

![figure2](/assets/img/ts/img829.png)

- **Retrieval-as-evidence:** top-k retrieved sequences 시각적으로 제공.
- **Transparent weighting:** 중요 retrieval 구간의 weight 확인 가능.
- 예시: Weather dataset에서 유사한 주기성 retrieval, ETTm1에서 급격한 추세 하락 구간 보완 (Fig 3–4) .

<br>

## **5. Conclusion**

- **TS-RAG**: RAG를 TSF로 확장한 zero-shot framework
- **ARM** 기반의 adaptive fusion
  - External knowledge를 효과적으로 통합

- 다양한 TSFM과 호환되며
- **Generalization + Interpretability** 를 동시에 달성
- 향후 연구: **multimodal TS-RAG** (예: text + series), **retrieval ranking optimization** 

<br>

**Limitations:**

- 현재는 unimodal (time series only).
- Public benchmark 중심 → real-world domain(예: finance, healthcare) 확장 필요.





