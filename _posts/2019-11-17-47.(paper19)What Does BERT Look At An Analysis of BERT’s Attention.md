---
title: 47.(paper) 19.What Does BERT Look At ; An Analysis of BERT’s Attention
categories: [DL,NLP]
tags: [Deep Learning, NLP]
excerpt: Paper Review by Seunghan Lee
---

# 19. What Does BERT Look At? An Analysis of BERT’s Attention (2019)

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

Large pre-trained NN such as BERT had great success!

Proposes methods for analyzing the **attention** mechanism of pre-trained models, and apply them to **BERT**

