# 1. Multi-scale temporal feature extraction based GCN with Attention for MTS Prediction (2022)[Permalink](https://seunghan96.github.io/gnn/ts/Multiscale-temporal-feature-extraction-based-GCN-with-Attention-for-MTS-Prediction/#multi-scale-temporal-feature-extraction-based-gcn-with-attention-for-mts-prediction-2022)

핵심 : 

1. **Multi-scale** temporal feature를 뽑아냄

2. 사용한 알고리즘 : EMD / GCN / TCN

   - EMD : time-domain 피쳐 추출
   - GCN : spatial 관계 포착 ( 노드 임베딩 생성/업데이트 )
   - TCN : temporal 관계 포착

3. 모든 시계열(D개) 이 각각 EMD를 거쳐, N+1개로 분해됨.

   1개의 그래프

   - D개의 노드 
     - 각 노드의 feature는 N+1 차원

   ( 시점에 따라 그래프가 다 다름 )

   이 1개의 그래프에 대해 K-head attention을 수행함.

   -> K개의 그래프가 생성됨 ( K개의 learned $A$ 행렬 )

   K개 그래프 각각이 GCN을 거침 & mean-pooling함

   마지막에 TCN 걸쳐서 예측 수행!

   ( 총 D개의 시계열에 대해, 미래 T만큼의 시점만큼 예측 진행! )

![figure2](https://seunghan96.github.io/assets/img/gnn/img428.png)



# 2. MTS forecasting with Latent Graph Inference (2021)[Permalink](https://seunghan96.github.io/gnn/ts/MTS-forecasting-with-Latent-Graph-Inference/#mts-forecasting-with-latent-graph-inference-2021)

핵심 : Latent Graph Inference

2. 정확도 & 복잡도의 trade-off 조정 가능

3. 2가지 케이스

   - (극단 1) fully connected

   - (극단 2) bipartite 

4. 노드들 간의 정보교환은 “time step 별로”가 아니라, “합쳐진 이후”에 이뤄져서 cheap

![figure2](https://seunghan96.github.io/assets/img/gnn/img421.png)



# 3. MTHetGNN : A Heterogeneous Graph Embedding Framework for MTS forecasting (2020)[Permalink](https://seunghan96.github.io/gnn/ts/MTHetGNN/#mthetgnn--a-heterogeneous-graph-embedding-framework-for-mts-forecasting-2020)

핵심 : MTHetGNN

1. 3종류의 임베딩

   1. RELATION 임베딩 ……………… **A** 역할

      1. similarity $A$
      2. causality $A$
      3. adaptive $A$

      ( 이 3개 각각 normalization & threshold 수행 )

   2. TEMPORAL 임베딩 : 여러 size의 1d CNN …….. **X** 역할

   3. HETEROGENEOUS GRAPH 임베딩 …….. **f(A여러개,X)**

![figure2](https://seunghan96.github.io/assets/img/gnn/img415.png)



# 4. MAGNN ( Multi-Scale Adaptive GNN ) for MTS Forecasting (2022)[Permalink](https://seunghan96.github.io/gnn/ts/MAGNN/#magnn--multi-scale-adaptive-gnn--for-mts-forecasting-2022)

핵심 : MAGNN

1. **MULTI-scale** temporal pattern 포착
2. 그러기 위해서, 아래의 두가지를 사용함
   1. multi-scale pyramid 네트워크
   2. adaptive graph learning 모듈

3. 마지막에, scale-wise fusion 수행

![figure2](https://seunghan96.github.io/assets/img/gnn/img424.png)



# 5. Discrete Graph Structure Learning for Forecasting Multiple Time Series (2021, 11)[Permalink](https://seunghan96.github.io/ts/gnn/ts23/#discrete-graph-structure-learning-for-forecasting-multiple-time-series-2021-11)

핵심 : GTS

1. **structure를 learn** 한다

   ( 그래프 구조가 항상 주어지는 것은 아니기 때문! )

2. GTS ( Graph for Time Series ) 알고리즘을 제안

3. (파트 1) Graph Structure PARAMETERIZATION

   - Adjacency matrix $A$ 를 **베르누이 분포 r.v** 행렬로 봄

     ( $A_{ij} \sim Ber(\theta_{ij})$ ) ... scalable하지 않을듯.

   - $\theta$ 모델링 방법 : X -> z -> link prediction ( 0 ~ 1) 

4. (파트 2) DCRNN의 **diffusion convolutional GRU**를 사용

![figure2](https://seunghan96.github.io/assets/img/ts/img208.png)



# 6. Diffusion Convolutional Recurrent Neural Network : Data-driven Traffic Forecasting[Permalink](https://seunghan96.github.io/ts/gnn/ts33/#diffusion-convolutional-recurrent-neural-network--data-driven-traffic-forecasting)

핵심 : DCRNN

1. spatial & temporal

   - spatial : bidirectional RANDOM WALK
   - temporal : SCHEDULED sampling ( enc- dec)

2. DIRECTED graph를 사용함 ( $W$ = weighted adjacency matrix )

3. traffic flow를 Diffusion 과정으로써 바라봄. 

   따라서, spatial dependency 잡아내기 위해 diffusion convolution제안

4. DCRNN = diffusion conv + seq2seq + scheduled sampling

5. Diffusion Process 상세 : 생략
6. seq2seq내의 Scheduled Sampling : 랜덤 확률로 예측값/정답값을 input으로

![figure2](https://seunghan96.github.io/assets/img/ts/img249.png)

<br>

# 7. Graph WaveNet for Deep Spatial-Temporal Graph Modeling[Permalink](https://seunghan96.github.io/ts/gnn/ts34/#graph-wavenet-for-deep-spatial-temporal-graph-modeling)

핵심 : Graph Wavenet

1. 주어진 그래프 구조는 완벽 X ... **ADAPTIVE dependency matrix** 

2. Long Sequence 다루기 위해... **stacked dilated 1d conv**
3. Graph Wavenet의 2개 블록 : GCN & TCN

- $\tilde{\mathbf{A}}_{a d p}=\operatorname{Soft} \operatorname{Max}\left(\operatorname{ReLU}\left(\mathbf{E}_{1} \mathbf{E}_{2}^{T}\right)\right)$...E1 & E2 : 소스 & 타겟 임베딩
- adaptive matrix $k$ 개 사용... $\mathbf{Z}=\sum_{k=0}^{K} \tilde{\mathbf{A}}_{a p t}^{k} \mathbf{X} \mathbf{W}_{k}$

![figure2](https://seunghan96.github.io/assets/img/ts/img253.png)

<br>

# 8. Multivariate Time Series Forecasting with Transfer Entropy Graph (2020, 5)[Permalink](https://seunghan96.github.io/ts/gnn/ts40/#multivariate-time-series-forecasting-with-transfer-entropy-graph-2020-5)

핵심 : CauGNN

1. node들 간의 관계는, 단순한 관계가 아닌 **인과 관계** (causality)
2. CauGNN = GNN + **Neural Granger Causality**
   - ($A$) node들 간의 pairwise한 **Transfer Entropy** 행렬 생성 ... 이를 $A$로 사용
   - ($X$) 여러 커널사이즈의 **1d cnn** 사용한후 concat -> 노드 피쳐로써 사용

![figure2](https://seunghan96.github.io/assets/img/ts/img267.png)



# 9. Connecting the Dots ; MTS Forecasting with GNNs (2020, 147)[Permalink](https://seunghan96.github.io/ts/gnn/ts41/#connecting-the-dots--mts-forecasting-with-gnns-2020-147)

핵심 : MTGNN

1. 3가지 핵심 :

   (1) graph learning

   (2) graph convolution

   (3) temporal convolution

2. Graph learning : node 사이의 pairwise relation 계산. 

   - 너무 계산복잡도 높아서, sampling 사용 ( 일부 pair만 사용 )
   - bidirectional해서, 인과관계 (방향성) 포착 가능

3. Graph Convolution : 2개의 mix-hop propagation layer 사용

   - step 1) information propagation
   - step 2) information selection

   ![figure2](https://seunghan96.github.io/assets/img/ts/img269.png)

4. Temporal Convolution : dilated 1d-conv

![figure2](https://seunghan96.github.io/assets/img/ts/img272.png)

<br>

![figure2](https://seunghan96.github.io/assets/img/ts/img271.png)

<br>

# 10. Multivariate Time Series Regression with Graph Neural Networks (2022)[Permalink](https://seunghan96.github.io/ts/gnn/ts45/#multivariate-time-series-regression-with-graph-neural-networks-20202)

핵심 : proposed GCN

1. 3가지 핵심
   - (1) 1d-conv 사용해서 노드 피쳐 얻기
   - (2) n개의 GNN layer
   - (3) flatten하고 FC layer 태우기



![figure2](https://seunghan96.github.io/assets/img/ts/img281.png)

![figure2](https://seunghan96.github.io/assets/img/ts/img282.png)

<br>

# 11. Multivariate Time Series Anomaly Detection via Graph Attention Network (2020, 44)[Permalink](https://seunghan96.github.io/ts/gnn/ts46/#multivariate-time-series-anomaly-detection-via-graph-attention-network-2020-44)

핵심 : MTAD-GAT

( Multivariate TS Anomaly Detection GAT )

1. 2개의 GAT : (1) spatial & (2) temporal
   - (1) spatial : **feature-oriented**
   - (2) temporal : **time-oriented**
2. process
   - step 1) 1-d conv로 노드 피쳐 뽑기
   - step 2) 2개의 병렬적 GAT
   - step 3) 아래의 3개 concat후, GRU로 보내기
     - 1) 1d-conv 결과
     - 2) GAT 1 결과
     - 3) GAT 2 결과
   - step 4) GRU의 아웃풋을, 아래의 2개모델로 보냄
     - 모델 1 : forecasting based model
     - 모델 2 : reconstruction based model

<br>

![figure2](https://seunghan96.github.io/assets/img/ts/img283.png)

<br>

# 12. Learning Graph Structures with Transformer for MTS Anomaly Detection in IoT (2022)[Permalink](https://seunghan96.github.io/ts/ts53/#learning-graph-structures-with-transformer-for-mts-anomaly-detection-in-iot-2022)

핵심 : GTA

1. anomaly detection 수행
2. MTGNN과 유사.
   - (1) learn graph structure
   - (2) graph convolution
   - (3) modeling temporal dependency ( via Transformer )
3. 제안 알고리즘들 : connection learning policy & IP convolution
4. connection learning policy
   - gumbel-softmax sampling strategy ( 계산복잡도 확 줄여 )
   - 자동으로 directed adjacency matrix 배움. 이걸 GCN에 넣음
5. IP (Influence Propagation) via GCN
   - node-wise symmetric aggregation operation
   - $\mathbf{x}_{i}^{\prime}=\sum_{j \in \mathcal{N}(i)} h_{\Theta}\left(\mathbf{x}_{i}\left\|\mathbf{x}_{j}-\mathbf{x}_{j}\right\| \mathbf{x}_{j}+\mathbf{x}_{i}\right)$.
6. Hierarchical Dilated Convolution
   - TCN & GCN 번갈아서 수행
7. Multi-branch Attention

![figure2](https://seunghan96.github.io/assets/img/ts/img290.png)

![figure2](https://seunghan96.github.io/assets/img/ts/img291.png)

![figure2](https://seunghan96.github.io/assets/img/ts/img292.png)

![figure2](https://seunghan96.github.io/assets/img/ts/img293.png)

<br>

# 13. STCGAT : Spatial-temporal Causal Networks for complex urban road traffic flow prediction (2022)[Permalink](https://seunghan96.github.io/ts/gnn/ts54/#stcgat--spatial-temporal-causal-networks-for-complex-urban-road-traffic-flow-prediction-2022)

핵심 : STCGAT

1. GAT + CTCN ( = **Causal Temporal CNN** )
   - GAT : spatial & CTCN : temporal
2. CTCN : BiLSTM + TCN
   - (2) Bi-LSTM의 인풋 : (1) GAT의 아웃풋
   - (3) TCN의 인풋 : (2) Bi-LSTM의 아웃풋
3. CTCN의 아웃풋이 FC layer통과해서 최종 예측

![figure2](https://seunghan96.github.io/assets/img/ts/img295.png)

![figure2](https://seunghan96.github.io/assets/img/ts/img296.png)

![figure2](https://seunghan96.github.io/assets/img/ts/img297.png)





# 14. A3T-GCN : Attention Temporal GCN for Traffic Forecasting (2020)[Permalink](https://seunghan96.github.io/gnn/ts/A3TGCN/#a3t-gcn--attention-temporal-gcn-for-traffic-forecasting-2020)

핵심 : A3T-GCN

- A3T = **Attention Temporal**
- (1) T-GCN
  - (1-1) spatial : GCN
  - (1-2) temporal : GRU

- (2) Attention
  - (1) + (2)의 결과로 얻어진 h를 사용하여 attention

![figure2](https://seunghan96.github.io/assets/img/gnn/img416.png)



# 15. Adaptive GCRN for Traffic Forecasting (2020)[Permalink](https://seunghan96.github.io/gnn/ts/AGCRN/#adaptive-gcrn-for-traffic-forecasting-2020)

핵심 : AGCRN

1. Traffic Forecasting에 있어서, **node-specific** 패턴 포착은 중요!

2. 2가지 모듈을 제안함

   1. NAPL ( = Node Adaptive Parameter Learning ) : **node specific** 패턴 포착 위해
   2. DAGG ( = Data Adaptive Graph Generation ) : TS 사이의 상호의존성 파악

3. NAPL

   - GCN의 파라미터를 **factorize**
   - 파라미터 = (1) node embedding matrix X (2) weight pool

4. DAGG

   - data로부터 node embedding을 유추

   - $E_A \cdot E_A^T$ 곱해서, adaptive graph structure 생성

     ( 이걸 마치 adjacency matrix 처럼 사용 )

     

# 16. ASTGCN : Attention Based Spatial-Temporal GCN for Traffic Flow Forecasting (2019)[Permalink](https://seunghan96.github.io/gnn/ts/ASTGCN/#astgcn--attention-based-spatial-temporal-gcn-for-traffic-flow-forecasting-2019)

핵심 : ASTGCN

1. 데이터를 3개로 나눠서 바라봄
   - recent / daily-periodic / weekly-periodic
2. 두 개의 메인 구조
   - (1) spatial temporal attention : SAtt & TAtt
   - (2) GCN+Conv
     - GCN = spatial-temporal CNN : spatial 
     - Conv = common standard CNN : temporal
   - SAtt를 통해, 변형된 $A$가!
   - TAtt를 통해, 변형된 $X$가!
3. 위 데이터 3개의 결과를 fuse하여 최종 결과!

![figure2](https://seunghan96.github.io/assets/img/gnn/img418.png)



# 17. T-GCN : A Temporal GCN for Traffic Prediction (2015)

핵심 : T-GCN

1. T-GCN = GCN + GRU

![figure2](https://seunghan96.github.io/assets/img/gnn/img441.png)

![figure2](https://seunghan96.github.io/assets/img/gnn/img444.png)



# 18. Predictive Temporal Embedding of Dynamic Graphs 

<br>

# 19. Transfer GNN for pandemic forecasting (2021)

1. MAML 사용하여, 데이터 많은 -> 적은 국가로 정보 전달
2. 팬대믹 데이터의 그래프 구조
   1. 엣지 : weighted & directed & self-loop
   2. 노드 : ***과거 window를 정보를 전부 "현재 시점"의 임베딩에 반영***



교훈 :

- (1) meta-learning 사용 
- (2) 특정 시점의 임베딩에, 과거 window 정보 반영



# 20. GMAN ; A Graph Multi-Attention Network for Traffic Prediction (2019)

핵심 : GMAN (Graph Multi-attention Network)

1. 장기 예측 (long-term prediction)
2. 2개의 블록 사용
   1. 인/디코더 "안"에 : spatio-temporal attention block 
   2. 인/디코더 "사이"에 : transform attention layer



![figure2](https://seunghan96.github.io/assets/img/gnn/img457.png)

<br>

# 21 .Multi-scale temporal feature extraction based GCN with Attention for MTS Prediction (2022)[Permalink](https://seunghan96.github.io/gnn/ts/Multiscale-temporal-feature-extraction-based-GCN-with-Attention-for-MTS-Prediction/#multi-scale-temporal-feature-extraction-based-gcn-with-attention-for-mts-prediction-2022)

핵심 : Multi-scale temporal feature extraction

1. 3가지 키포인트

   - EMD : time-domain 피쳐 뽑기 위해
   - GCN : spatial
   - TCN : temporal

2. EMD ( Empirical Mode Decomposition )

   1. unstable하고 non-linear sequence 취급 위해

      ( mitigate effect of noise )

   2. 여러 time scale의 temporal feature들을 뽑아냄

   ![figure2](https://seunghan96.github.io/assets/img/gnn/img427.png)

3. graph generation

   - 위에서 뽑아낸 여러 scale의 요소들을 각기 다른 차원으로 간주한 뒤,

     graph learning 수행

   - K-head attention 통해, K개의 learned adjacency matrix 얻어

4. 나머지 GCN/TCN은 동일

<br>

# 22. Predicting Path Failure in Time-Evolving Graphs (2019)[Permalink](https://seunghan96.github.io/gnn/ts/LRGCN/#predicting-path-failure-in-time-evolving-graphs-2019)

핵심 : LRGCN ( LSTM R-GCN )

1. time-evloving graph ( $G_1 , \cdots G_t$ )

   ( 메인 목표가 다르긴 함. path classification )

2. LRGC 특징

   1. time-adjacenct graph snapshot 사이의 temporal & spatial relation 포착

3. 4 types of relations to model in R-GCN

   - (1) intra-incoming
   - (2) intra-outgoing
   - (3) inter-incoming
   - (4) inter-outgoing

4. SAPE (Self-Attentive Path Embedding ) -> 우리와 무관.버려도 될듯

<br>

# 23. GC-LSTM : GCN embedded LSTM for Dynamic Network Link Prediction (2018)[Permalink](https://seunghan96.github.io/gnn/ts/GC-LSTM/#gc-lstm--gcn-embedded-lstm-for-dynamic-network-link-prediction-2018)

핵심 : GC-LSTM ( = GCN embedded LSTM )

1. Link Prediction 수행을 위한 모델
2. 그래프 구조가 evolve over time 한다는 dynamic한 특징 고려