# 04. Transfer Learning - Feature Extraction

### Contents

1. Using GPU
2. Transfer Learning with TF Hub
3. Callbacks
4. Create models using TF Hub
5. Comparing Models using TensorBoard

<br>

## (1) Using GPU

```bash
!nvidia-smi
```

<br>

## (2) Transfer Learning with TF Hub

[TensorFlow Hub](https://tfhub.dev/) 

- 유명한 모델 component들 담고 있는 repositorh
- 간단히 import 해서 URL 식으로 사용 가능

<br>

![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png)

<br>

## (3) Callbacks

Callbacks 

- 모델이 **학습 중**에 이루어지는 것들

<br>

종류

- (1) Experiment Tracking with **TENSORBOARD**
- (2) Model checkpointing
  - 중간 중간에 모델 weight 저장
- (3) Early Stopping

<br>

TensorBoard

- `tf.keras.callbacks.TensorBoard()`
- 모델의 performance들을 저장하는 경로 :
  - `[dir_name]/[experiment_name]/[current_timestamp]`

```python
import datetime
def TB_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"Saving TensorBoard log files to: {log_dir}")
  return tensorboard_callback
```

<br>

## (4) Create models using TF Hub

TF Hub로부터, 아래의 2개의 pre-trained model을 사용할 것

- ResNetV2 ( 2016 )
- EfficientNet ( 2019 )

<br>

Steps 

1. [tfhub.dev](https://tfhub.dev/) 에 접속
2. 풀고자하는 task 도메인 선택 ( ex. image )
3. TF 버전 선책
4. 풀고자하는 문제 제외한 Problem Domain 전부 체크 해제
5. 이때 뜨는 모델들이 선택 가능한 모델 후보들
6. 좌측의 Architecture Tab 클릭
7. 특정 모델 ( EfficientNetB0 ) 클릭
8. Copy URL
   - https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1

<br>

Feature Extraction Transfer Learning

- pre-trained model이 학습했던 패턴(weight)을 그대로 사용
- 본인 문제에 적합한 output으로 adjust

<br>

Fine-tuning Transfer Learning

- pre-trained model이 학습했던 패턴(weight)을 가져와서, 일부 layer를 본인에 문제에 맞게 약간 살짝쿵 (fine) 튜닝

<br>

![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png)

<br>

1. Import Packages

```python
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
```

<br>

2. Import URLs

```python
# Resnet 50 V2 feature vector
resnet_url = "https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4"

# Original: EfficientNetB0 feature vector (version 1)
efficientnet_url = "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"
```

<br>

3. Build Model

- argument : 
  - (1) model의 URL
  - (2) 내 task에 맞는 output 종류 수

```python
def create_model(model_url, num_classes=10):
  FE_layer = hub.KerasLayer(model_url,
                            trainable=False, # freeze 여부
                            name='feature_extraction_layer',
                            input_shape=IMAGE_SHAPE+(3,)) # 나의 input image shape
  
  model = tf.keras.Sequential([
    FE_layer, # back bone으로 위의 FE layer 사용
    layers.Dense(num_classes, activation='softmax', name='output_layer') # 내 task에 맞는 output layer
  ])

  return model
```

<br>

```python
resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)

resnet_model.compile(loss='categorical_crossentropy',
                     optimizer=tf.keras.optimizers.Adam(),
                     metrics=['accuracy'])
```

![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-resnet-feature-extractor.png)

<br>

4. Train Model

- 이때, callbacks에 tensorboard를 생성하는 함수를 넣는다.

```python
# Fit the model
resnet_history = resnet_model.fit(train_data_10_percent,
                                  epochs=5,
                                  steps_per_epoch=len(train_data_10_percent),
                                  validation_data=test_data,
                                  validation_steps=len(test_data),
                                  callbacks=[create_tensorboard_callback(dir_name="tensorflow_hub",
                                                                         experiment_name="resnet50V2")])
```

<br>

( 위와 유사하게, EfficientNet도 불러와서 사용한다 )

<br>

## (5) Comparing Models using TensorBoard

모델의 학습 로그들이 모두 자동으로 저장되었다 ( 위에서 callbacks에서 지정해줬으므로 )

이것들을 시각화하여 확인하기 위해, **TensorBoard.dev** 에 업로드해야 한다.

```bash
!tensorboard dev upload --logdir ./tensorflow_hub/ \
  --name "EfficientNetB0 vs. ResNet50V2" \
  --description "Comparing two different TF Hub feature extraction models architectures using 10% of training images" \
  --one_shot
```

- `--logdir`  : target upload directory

- `--name` : name of experiment

-  `--description` : brief description of experiment

-  `--one_shot` : exits the TensorBoard uploader once uploading is finished

<br>

TensorBoard에 올렸던 모든 experiment들 확인하기

```bash
!tensorboard dev list
```

<br>

TensorBoard에 올라와있는 experiment 제거하기

```bash
tensorboard dev delete --experiment_id [INSERT_EXPERIMENT_ID]
```