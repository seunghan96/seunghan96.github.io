---
title: Training Large Language Models to Reason in a Continuous Latent Space
categories: [LLM, NLP]
tags: []
excerpt: arxiv 2024
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# Training Large Language Models to Reason in a Continuous Latent Space

```
Hao, Shibo, et al. "Training large language models to reason in a continuous latent space." arXiv preprint arXiv:2412.06769 (2024).
```

참고: 

- https://aipapersacademy.com/chain-of-continuous-thought/
- https://arxiv.org/pdf/2412.06769

<br>

### Contents

1. Introduction
2. CoT vs. Chain of Continuous Though (Coconut)
   1. CoT
   2. Coconut

3. Training Coconut

<br>

# 1. Introduction

LLMs = Incredible reasoning abilities

**Chain-of-Thought (CoT)**

- A common and powerful method to **extract the most accurate responses from these models** 

- Encourage the model to generate solutions **step-by-step**, 

  **providing reasoning** for reaching the final answer. 

<br>

Limitation of CoT?

= Reasoning of LLMs must be generated ***in words***

$$\rightarrow$$ Imposes a ***fundamental constraint*** on the model

<br>

How do humans think?

- Region of the human brain responsible for language **"comprehension and production"** remains ***largely inactive*** during **"reasoning tasks"**

$$\rightarrow$$ Language is optimized for communication, ***not necessarily for complex problem-solving***

<br>

# 2. CoT vs. Chain of Continuous Though (Coconut)

![figure2](/assets/img/llm/img205.png)

<br>

## (1) CoT (Left)

- Step 1) Start with a **question**

  - Embedded into input tokens to be fed into the LLM

- Step 2) Receive the **first token** in the response

  ( = Start of the reasoning trace of the model )

- Step 3) Generate **first output token**
- Step 4) ....

<br>

## (2) Coconut (Right)

Alternates between ***language*** mode $$\rightarrow$$ ***latent*** (thought) mode

- [Language] mode: Operates as a standard language model, generating the **next token**
- [Latent] mode: Uses the **last hidden state** as the input for the next step. 
  - Last hidden state = Current reasoning state = ***"continuous thought”***

<br>

# 3. Training Coconut

![figure2](/assets/img/llm/img206.png)

Leverage existing language **Chain-of-Thought data**

- Each sample consists of a **(question, reasoning steps, answer)**

<br>

Training procedure

- Stage 0) Does not generate any thought tokens

  ( Just trained to yield the reasoning traces and correct answers for the CoT samples )

- Stage 1) **Remove** one "reasoning step" & **Add** one "thought token"
- Stage 2) same
- ...

<br>

Loss is only calculated on the ***remaining reasoning steps*** and the ***answer***

( Not on the **thought token**!! )

$$\rightarrow$$ But it's okay! Back-propagation!

<br>

