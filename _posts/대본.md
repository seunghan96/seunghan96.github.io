# Pg1

안녕하세요

연세대학교 통계데이터사이언스학과 통합과정 5학기에 재학중인 이승한입니다.

제가 오늘 컨퍼런스에서 발표드릴 연구 주제는,

- 다변량 시계열 예측을 위해 그래프 뉴럴 네트워크를 활용하는
- MAD-GL2라는 모델입니다.
- 이름에서도 알 수 있듯,
  - 시계열의 전역적/지역적 특징을 모두 고려하여
  - 동적인 다중 그래프를 학습합니다



# Pg 2

다음과 같은 순서를 발표를 진행 할 예정입니다



# Pg 3

다변량 시계열은, 우리 주위에 흔히 널려있습니다.

- 도로 곳곳에 설치된 교통량을 측정하는 트래픽 센서나,
- 상장된 여러 기업들의 일별 주가 등 모두 다변량 시계열의 예시입니다



이러한 다변량 시계열은, 

- 각각의 시계열 "내"에서 temporal dependency를 가질 뿐만 아니라
- 시계열들 "간"에 spatial dependency또한 가집니다.
  - ex) 가치주./성장주 /  반도체, 혹은 빅테크 등 같은 섹터에 있는 주식들은 같은 방향으로 움직입니다.



# Pg 4

이러한 다변량 시계열을, 그래프 뉴럴네트워크를 사용해서 예측한다고 말씀을 드렸는데,

그러기 위해서 아마 많은분들께서 알고게시겠지만, 

간단히만 그래프에 대한 기본 개념만 짚고 넘어가겠습니다.

- 다음과 같은, V,E 노테이션으로,
  - V는 vertices, 혹은 node
  - E는 노드들 간의 연결관계인 엣지를 나타냅니다.
- 이러한 연결 관계, 혹은 graph structure는, 다음과 같은 A라는 NxN짜리 adjacency matrix 인접 행렬 로써 나타낼 수 있습니다.

- 이러한 엣지의 방향성 여부에 따라 directed & undirected로 나뉠 수 있습니다



# Pg 5

이러한 그래프 구조를 다변량 시계열 예측에 적용하자면,

- 노드 하나하나는 시계열 하나하나를 의미하고
- 엣지는 시계열들 간의 연결관계를 나타냅니다.

하지만 여기서 문제점은,

- 이러한 엣지관계가 명시적으로 주어져있지 않다는 점입니다.
- SNS 서비스처럼, 사람 a와 사람 b가 팔로우를한다 등등 같이 1/0처럼 나타낼 수 있는 유형의 데이터와는 다르게,
- 다변량 시계열 데이터는, 이들 사이의 잠재적 연결관계가 존재할 것이라는 사실만 가정할 뿐, 이들간의 연결관계가 0/1 혹은 0.5 등 이러한 정도로 주어져 있지 않다는 점입니다.

- 다른 말로 하면, 앞선 페이지에서 말씀드린 graph structure, 혹은 nxn 행렬 A가 주어져있지 않다는 점입니다.



이를 위해, 제가 제안하는 알고리즘은, 

시계열 예측을 위한 이러한 "그래프 구조"를 학습하는 모델입니다.

즉, 시게열 데이터를 통해 시계열 간의 spatial dependency를 모델링하는게 제안 알고리즘의 핵심이라고 보시면 됩니다.

이렇게 해서 파악된 그래프 구조는, 미래 time step의 값을 예측하기 위한 temporal prediction에 주어지게 됩니다.



# Pg 6

제안 알고리즘을 이해하기 위해서, 

다음과 같이 기본적인 GNN에 대한 이해가 선행되어야 할 것 같아서,

이에 대해서도 간략히 집고 넢어가고자 합니다.

- 그래서, Graph Neural Network GNN과, 

  이의 일종인 GCN, Graph Convolutional Network에 대해 설명드리겠습니다.



# Pg 7

GNN은 말 그대로, 그래프 구조를 가진 데이터를 위한 Neural Network입니다.

당연히 데이터의 형식에 따라, 

모델 아키텍처 또한 저희가 흔히 알고잇는 뉴럴 네트워크와는 다릅니다.



여기서 핵심은,

- 결국 각 노드를 일종의 latent space / embedding space로 매핑을 시킬 것인데,
- 실제로 유사한 성격을 띈 노드가 이 매핑된 공간에서의 거리가 가깝도록 만드는 인코더를 학습시키는 것이라고 볼 수 있습니다.



그래서 이 GNN이 주로 활용된느 분야는,

노드들 간의 "spatial connection"을 잘 캡쳐하는 것이 중요한 영역에서 자주 사용됩니다.

그래서 추천 시스템이나, 커뮤니티 디텍션 등에서 자주 활용이 됩니다.



# Pg 8

앞으로 자주 사용될 개념이기때문에, 노테이션을 간단히 말씀드리자면,

- V는 노드/vertext set

- A는 ( 그래프의 구조를 나타내는 ) 인접행렬이라고 보시면 됩니다

  - 노드 개수가 n이라고 한다면, nxn 매트릭스가 될 것이고

  - (i,j) 번째 element는 i와 j의 연결 여부를 나타냅니다.

  - 이때 연결 여부는 1/0으로 바이너리일수도 있으나,

    연결 강도를 고려할 경우 continuous value가 될 수 있습니다

- X의 경우, 각 노드의 feature vector를 모아둔 matrix 라고 할 수 있습니다

- N(v)의 경우는 ~



그래서, GNN의 input으로는, 일반적으로 다음과 같이

- (1) 각 노드의 특징을 담은 X와
- (2) 노드 간의 연결관계/혹은 그래프 구조/혹은 인접행렬을 의미하는 A가 같이 들어가게 됩니다.



# Pg 9

GCN은, 이러한 GNN의 일종으로,

특정 노드에 대한 임베딩을, 주변 노드 ( 즉 해당 노드의 이웃 노드 )로부터 정보/information/message를 수합하여 업데이트하는 알고리즘입니다.



그래서 아래 그림을 보시면, 총 6개의 노드가 있고,

이 경우에는 A가 타겟노드라고 보시면 됩니다.

그래서 해당 A라는 노드는, 본인의 이웃인 빨간/초록/파랑노드의 정보를 수합한 뒤, 해당 정보가 NN를 통과하여 A에게 전달되는 것을 볼 수 있습니다.



그래서 예를 들면, 2-layer network라고 한다면, 본인으로부터 2단계 건너서 떨어진 이웃 노드로부터까지 정보를 수한다는 의미를 가집니다.



이와 같은 방식으로, 모든 노드는 오른쪽 그림과 같이 전부 타겟노드가 되어 해당 과정을 반복적으로 수행하며 노드 임베딩을 학습해나갑니다.



# Pg 10, 11 생략




# Pg 12

Spatital-Temporal GNN의 경우에는,

이러한 GNN/GCN구조를 시계열에 적용한 알고리즘이라고 생각하시면 됩니다.



그래서 이름에서도 알 수 있듯,

- Spatial의 경우, 일반적인 GNN 처럼 노드 "간"의 관계를 포착하는 것을 의미하고,

- Temporal의 경우 : 노드 "내"의 관계를 포착하는 것을 의미합니다.

  - 여기서 노드 하나하나는 시계열 하나가 될 것이기 때문에,

    이는 곳 시계열 내의 관계, 즉 시간 축방향의 temporal 관계를 포착하는 것을 의미합니다.



그래서 이러한 Spatial Temporal GNN의 input과 output의 경우,

- input은 앞서 말씀드린 것과 같이 A와 X
  - A) 그래프 구조/인접행렬 등을 의미하고,
  - X)의 경우 노드의 특징이기 때문에 시계열 데이터 값을 의미합니다
- 이를 통해 예측하고자 하는 output은,
  - 모든 시계열 (즉 모든 노드)의 미래 값들을 의미합니다.



이러한 구조를 띈 대표적인 모델에는 다음과 같이 DCRNN, TGCN등이 있습니다.



# Pg 13

하지만 여기에 문제가 있습니다.

바로, 위의 input인 A, 즉 그래프 구조/인접행렬 가 주어지지 않는다는 것입니다.



예를들어, SNS 연결망 데이터의 경우,

누구와 누구가 친구이고, 친구가 아닌지를 알 수 있기 때문에 adjacency matrix가 1/0 등으로 주어질 수 있습니다.



하지만, 시계열의 경우는 그렇지 않습니다.

예를 들어, 저희가 나스닥 시총 상위 100개의 주식을 대상으로 시계열 예측 모델을 구현한다고 했을때, 어떤 주식과 어떤 주식이 연결되어있다/안되어있다를 판단할 수 없습니다.

물론, 같은 섹터에 있는 것끼리 연결되어있고, 그렇지 않은 애들끼리는 연결되어있지 않다!라고  가정을 해서 어찌어찌 결과를 낼수는 있겠지만,

이는 domain knowledge가 필요할 뿐만 아니라, 노드 간의 정보가 propagation되는 최적의 optimal이 아니기도 합니다. 



이에 따라, 시계열 예측을 하기 위해 필요한 이러한 그래프 구조/ 인접행렬 A를 "학습"하지는 필요성이 되두되고 있는 추세이고, 이를 저희는 말 그대로 "Graph Structure Learning"이라고 부릅니다.



그래서 최근에 나온 Spatial-Temporal GNN의 구조를 보면, 다음과 같은 2개의 모듈로 구성이 됩니다.

- (1) 첫번째는 graph learning module로써, 
  - 앞서 말한 graph structure learning을 수행하는 모듈입니다.
  - 그래서 노드 피쳐 X를 사용하여, 그래프 구조 A를 학습하는 모델입니다
- (2) 두번째는 prediction module입니다
  - 앞선 단계에서 학습한 그래프 구조 A와, (시계열 값을 의미하는) 노드 피쳐 X 를 input으로 받아서 미래 시계열 값을 예측하는 모듈입니다.



그래서 논문에 따라서, 

- (1)만을 제안하는 논문
- (2)만을 제안하는 논문
- (1), (2)를 전부제안하는 논문 등이 있습니다.



제가 제안하는 알고리즘은, (2)는 기존에 Graph Wavenet이라는 논문에서 제안한 prediction module을 사용하고,

(1) graph learning module을 제안합니다.

즉, 제 알고리즘의 핵심을 한 줄로 요약하자면,

***어떻게하면 미래 예측에 도움이 되는 방향으로 노드/시계열 간의 관계를 잘 잡아낼까***라고 보시면 될 것 같습니다.



# Pg 14

기존의 알고리즘 및 제안 알고리즘을 비교해보자면, 다음과 같습니다.

총 3개의 베이스라인, GW GTS, NRI를 가져왔고, 이에 대한 비교를 다음과 같은 한장의 그림으로 시각화 할 수 있을 것습니다.

- 가장 왼쪽의 GW의 경우는, 그래프 관계를 학습하기 위해 그 어떠한 데이터도 사용하지 않고, random initialize된 노드 벡터를 가진 뒤, 이 벡터들 간의 similarity matrix를 형성하여 그래프 구조를 학습합니다.

- 나머지 방법론들도 마찬가지로 node별 벡터를 학습하는데,
  - GTS의 경우에는, 전체 시계열, 즉 시계열의 global information을 가지고 ~
  - NRI의 경우에는, input 시계열, 다른 말로는 ""예측을 위해 input으로 들어가는 window 범위의 시계열"을 가지고~ 점에서 local information ~
- 하지만 제가 제안하는 알고리즘은, 이 두 가지 information을 전부 활용하여, 한개가 아닌 multi-modal graph를 생성합니다.



# Pg 15

이를 요약한 표는 다음과 같습니다. 앞선 4개의 알고리즘은...

- 노드 간의 벡터를 학습한 뒤, 이의 similarity matrix를 그래프 구조로써 사용하기 때문에 전부 1/0 binary값이 아닌 continous 값을 가질 수 있습니다

- 또한, 저의 알고리즘과 NRI의 경우, input 시게열을 사용하여 예측하기 때문에, 입력 시게열 값에 따라 그래프구조가 바뀌는 dynamic한 그래프를 학습합니다.

- 그리고 앞서 말씀드렸듯, 학습한 그래프 구조의 경우,

  - GTS는 global info를, NRI의 경우 local info, 저의 알고리즘은 둘 다 담고 있습니다

- 그 밖에도, 제가 제안한 알고리즘은 노드 별로 서로 다른 connectivity strength를 가질 수 있다는 점을 활용합니다.

  - 예를 들어, 주식으로 비유를 하자면, 대형주의 소형주보다 주가 변동이 다른 주가의 변동에 더 영향을 많이 줄 수 있고, 

  - 반대로 소형주의 경우에는 대형주보다 다른 요소에 의해 변동폭이 클 수 있습니다. 즉, inward connectivity가 더 클 수 있습니다. 

    이러한 사실을 반영하기 위한 추가적인 auxiliary module인 connectivity strength matrix, CSM을 제안합니다.

- 마지막으로, 앞선 알고리즘과는 다르게 제안한 알고리즘은 1개가 아닌 여러 개의 그래프를 학습합니다.



# Pg 16

이제 본격적으로, 제안드린 알고리즘에 대해 설명드리겟습니다.

그러기 위해서 notation을 정리해드리자면,

- x_t는 N차원 벡터로써, N개의 시계열의 t시점에서의 값
- 그 다음 아래 notation이 
  - t+1~t+W :  W범위만큼의 input 시계열값
  - t+W+1 ~ t+W+H : H범위만큼의 예측하고자하는 시계열값

- 아무런 notation이 없는 X는
  - 모든 시계열의 / 모든 timestep에서의 값이라고 생각하시면 됩니다
- 그리고 그래프와 인접행렬은 각각 다음과 같이 G,A라고 ~



# Pg 17

그래서 앞서 말씀드린 2개의 모듈은, 다음과 같이 나타낼 수 있습니다.

- g는 graph learning module로써~
- f는 prediction ~



이 둘은 따로 학습하는 것이 아니라,

prediction module의 최종 output인 실제 시계열값과 시계열 예측값의 차이를 minimize하는 방향으로 end-to-end방식으로 학습이됩니다.

따라서, graph learning module g에서는

***시계열 예측에 가장 도움이 되는 노드간의 연결관계***를 학습하게 됩니다.



# Pg 18

제안 알고리즘을 도식화한 그림은 다음과 같습니다.

- (1) 파란색 : ~
- (2) 빨간색 : ~
- 왼쪽 상단 시계열은 ( global info를 담고 있는 ) 전체 시게열 X 
- 왼쪽 하단 ~ ( local info ~ ) 입력 시계열



step 1) 파란색 설명 :

- 이미지 변환

- GTI 모듈 ( Graph generation with Timeseries Image )

- 통과해서 다음과 같은 검은색 K개의 global graph

- 그런뒤 해당 그래프는 CSM이라는 connectivity strengt matrix에 곱해지게 되는데,

  이게 앞서 말씀드린 노드 간의 connectivity strength를 조정해주는 matrix



step 2) 빨간색 부분 :

- input TS간의 유사도를 바탕으로, NxN similiarity matrix 생성



이 빨간색 부분에서 생성된 SM를 사용하여,

위의 파란색 K개의 global graphs에 각기 다른 비중으로 attention을 겁니다.

그래서 만약 노란색 SM이 2번째 그래프와 유사하다! 싶으면 alpha_{t,2}값이 높을 것이고, 더 높은 비중으로 해당 그래프를 사용하게 될 것입니다.



이렇게 사용된 K개의 그래프를, input TS와 함께 prediction module $f$에 input으로 집어넣어서, 최종 시계열 예측을 진행하게 됩니다.



시사하는 바는 다음과 같습니다.

~

# Pg 19

제가 제안드린 알고리즘은, 크게 다음과 같이 3가지 ( GTI, CSM, GNM )으로 구성됩니다.

하지만 핵심은 첫번째 GTI모듈이고, 

나머지 두개 CSM, GNM은 약간의 성능 개선을 위해 sub정도의 auxiliary module정도의 낌으로만 생각하시면 됩니다.



그래서 순서는 다음과 같습니다.

step 1) ~

step 2)

step 3) 

이렇게 세 단계를 거쳐서 학습된 K개의 그래프가, prediction module의 input으로 주어지게 됩니다.



# Pg 20

다음과 같은 순서로, 제안 알고리즘들에 대한 세부 내용들을 소개드리고자 합니다.



# Pg 21

가장먼저, global graph를 생성해내는 global feature extraction 과정입니다.

- 가장 먼저 TS imaging을 수행합니다.
  - 이는 말 그대로 전체 시계열을 이미지로 변환하는 것을 의미합니다
- 그 다음으론, 해당 이미지로부터 graph를 생성하는 과정입니다
  - 이것이 곧 최종 global graph가 아니라
- 그 다음에 노드 별 각기 다른 connectivity strength를 반영해주기 위한 CSM을 곱해진 뒤 나오는 그래프가 최종적인 global graph가 됩니다.



# Pg 22

TS imaging에는 여러 방법들이 있습니다. 

이러한 대표적인 방법에는 GAF, MTF, RP등이 있는데, 

이 중에서 저는 GAF를 사용했습니다.

- 해당 이미지는, 픽셀의 좌측 상단에서 우측하단으로 갈 수록 더 멀리 떨어져있는 시간을 의미한다는 점에서 temporal dependency를 반영한 이미지입니다.
- 쉽게 말해, 시계열 내의 여러 Time step간의 관계를 시각화한 그림이라고 보시면 됩니다.



무엇보다 해당 이미지 변환의 장점은, 파라미터 수를 줄일 수 있다는 것입니다.

해당 이미지 변환은, 

- window 길이 만큼의 input TS가 아니라
- 전체 길이의 entire TS를 사용하기 때문에, 이를 하나의 벡터로 축약하기위해 파라미터수가 많이 필요할 수 있습니다.
- 그래서 기존의 GTS의 경우에는, 1d-convolution과 fully connected layer 등을 쌓아서 매우 많은 파라미터 수를 요구했으나,
- 제안 알고리즘의 경우에는 이미지로 변환한뒤, cnn 과 pooling등의 과정을 통해 보다 적은 수의 파라미터로 효과적으로 global information을 뽑아낼 수 있었습니다.



위 그림은, 2만 time step 이상이 되는 2개의 traffic dataset에 적용했을 경우, 요구되는 파라미터 수입니다. 



# Pg 23

해당 이미지로부터, graph를 생성하기 위해 GTI 모듈을 사용한다고 말씀드렸습니다.

가장먼저, 일반적인 CNN layer를 태워서, 다음과 같은 output channel인 2K인 feature map을 뽑아냅니다.

여기서 K는 저희가 pre-define한 생성할 multiple-graph의 수입니다.

이것의 2배만큼을 output channel로 정하는 이유는,

이 feature map을 flatten한 뒤 노드별 벡터로 사용할 것인데, 

- 제가 생성할 그래프가 "directed graph"가 되기 위해서입니다.



예를 들면, 

- i번째 node의 output vector (여기 그림에서는 파란색 벡터)와

- j번째 node의 input vector (여기 그림에서는 주황색 벡터)가 내적하여 

- 그래프 구조를 의미하는 adjacency matrix의 (i,j)번째 element가 될 것입니

  ( 반대로, j번째 node의 ~와 i번째 ~을 하게되면, (j,i)~r )

이럴 경우, assymetric한 directed graph를 생성할 수 있습니다.



이렇게 내적된 값들이 최종적으ㅡ로 softmax를 통과하여, Rowsum이 1이되도록 normalize를 하게 됩니다. 이는 요약하자면, 각 노드별로 본인이 가진 1만큼의 information propagation 힘을 나머지 노드에 0~1사이 비율로 할당하는 것이라고 보시면 됩니다.



# Pg 24

방금 말씀드린 것에 대한 정리 및 수식적 표현을 나타내자면, 다음과 같습니다.

- (1) input :
- (2) output
- (3) 2가지 과정으로 구성
  - (3-1) CNN을 사용하여 feature map을 뽑은 뒤 이를 flatten하여 feature vector를 뽑아내는 과정
  - (3-2) 해당 feature vector간의 유사도를 바탕으로 노드 간의 similarity matrix들을 형성하는 과정



# Pg 25

- 소개



# Pg 26

- 앞서 말씀드렸듯, softmax의 결과로 rowsum이 1이된다고 말씀드렸습니다.
- 즉, node별로 영향을 끼칠 수 있는 정도가 1로 동일하게 정해져있다는 가정과 동일하다는 뜻입니다.
- 이러한 사실은, gards the fact that the importance of network nodes can vary



그래서 도입한 것이  learnable CSM

그 목적은, 말 그대로  adjusts the connectivity strengths of nodes

- 이러한 CSM은 adjacency matrix와 동일하게 NxN 크기를 가지며, element-wise하게 adjacency matrix에 곱해집니다.



# Pg 27

이러한 CSM은, 2개의 CSV (Connectivity Strength Vector)의 외적으로 곱해집니다.

- 이를 각각 저희는 CSV-in 과 CSV-out이라고 부르고, 각각은 초기값1을 가진채로 학습 과정에서 update됩니다.



지금 여기서 초록색 값은, 4번째 node의 inward- connectivity strengt를 의미하며,

만약 "외부로부터 영향을 받는 힘이 상대적으로 작다"면 해당 값도 작을 것이고,

반대로 ~.



이러한 matrix를 위해서 필요한 추가적인파라미터는 단지 2N개에 불과합니다.



# Pg 28

방금 말씀드린 사항을 정리하자면, 다음과 같습니다.



# Pg 29

수식적으로 표현하자면, 다음과 같습니다.

앞서 말씀드린 CSV 2개가 외적해서 CSM이 되고, 이것이 앞서 생성된 similarity matrix에 elementwise하게 곱해져서 global graph가 됩니다.



# Pg 30

지금까지는, 어떻게 하면 전체 entire TS 사용하여 K개의 global graph들을 학습하는지를 알아봣습니다.



이제는, 제안한 그래프를 동적으로 만들기 위해 

input TS의 local information을 활용하는 방법에 대해서 소개드리겠습니다.

( 즉 시간에 따라 **노드 간의 관계가 변할 수 있다는 점**을 모델링한 것이라고 보시면 됩니다 )



# Pg 31

우선, 앞에 보이시는 바와 같이, Window 범위 만큼의 N개의 multivariate time series를 사용하여 similarity matrix를 만듭니다.

이는, 내적한 뒤, ReLU와 softmax를 씌움으로써 완성이 됩니다.

해당 similarity matrix와, 앞서 만든 K개의 global graph와의 코사인 유사도를 계산합니다.

이를  softmax를씌워서, K개의 그래프를 input TS에 따라 각기다른 비중으로 참고합니다.



# Pg 32

그렇게해서 최종적으로 나오게 된 것이, 오른쪽의 weighted global graphs입니다.

해당 그래프들을 요약하자면, 다음과 같은 2가지 특징을 가집니다.

- (1) 첫째, global information을 담은 global graph를 바탕으로
- (2) 둘째, local information을 담은 global graph에 대한 weight

global information은 input TS에 따라 무관한 basis 혹은 mode로 생각하시면 되고,

해당 basis에 대한 coefficient 혹은 가중치 weight는 input TS에 depend하는 dynamic한 값이라고 보시면 됩니다.



# Pg 33

이제 마지막으로, minor한 contribution인 GNM에 대해서 소개해드리겠습니다.

오른쪽 그림을 보시면, 앞서 생성된 K개의 weighted global graph들이 어떤 같은 크기의 검은색 mask에 곱해지신 것을 알 수 있습니다.

이는, test data에 대한 예측 성능을 높이기 위해 

학습과정에서, 앞서 생성된 그래프에 일부러 노이즈를 주면서 학습을 시키는 일종의 regulaization을 부여한 것이라고 보시면 됩니다.



# Pg 34

해당 noise는 다음의 gaussian 분포에서 샘플을 하고,

노드 개수와 무관하게 variance를 동일하게 만들기 위해, 분산은 1/N (노드개수)로 설정하였습니다.

이러한 mask는 training 과정에서만 곱해지고 testing/inference 단께에는 적용하지 않습니다.



앞서 말씀드린 connectivity strength matrix인 CSM 와, 방금 말씀드린 graph noise mask GNM 모두 

그 어떠한 grpah learning algorithm에 손쉽게 적용할 수 있습니다.







```
import numpy as np
import torch
from lib import utils
#device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")

class LayerParams:
    def __init__(self, rnn_network: torch.nn.Module, layer_type: str, device):
        self._rnn_network = rnn_network
        self._params_dict = {}
        self._biases_dict = {}
        self._type = layer_type
        self.device =device

    def get_weights(self, shape):
        if shape not in self._params_dict:
            nn_param = torch.nn.Parameter(torch.empty(*shape, device=self.device))
            torch.nn.init.xavier_normal_(nn_param)
            self._params_dict[shape] = nn_param
            self._rnn_network.register_parameter('{}_weight_{}'.format(self._type, str(shape)),
                                                 nn_param)
        return self._params_dict[shape]

    def get_biases(self, length, bias_start=0.0):
        if length not in self._biases_dict:
            biases = torch.nn.Parameter(torch.empty(length, device=self.device))
            torch.nn.init.constant_(biases, bias_start)
            self._biases_dict[length] = biases
            self._rnn_network.register_parameter('{}_biases_{}'.format(self._type, str(length)),
                                                 biases)

        return self._biases_dict[length]


class DCGRUCell(torch.nn.Module):
    def __init__(self, num_units, max_diffusion_step, num_nodes, nonlinearity='tanh',
                 filter_type="laplacian", use_gc_for_ru=True, device='cuda:0'):
        """

        :param num_units:
        :param adj_mx:
        :param max_diffusion_step:
        :param num_nodes:
        :param nonlinearity:
        :param filter_type: "laplacian", "random_walk", "dual_random_walk".
        :param use_gc_for_ru: whether to use Graph convolution to calculate the reset and update gates.
        """

        super().__init__()
        self.device = device
        self._activation = torch.tanh if nonlinearity == 'tanh' else torch.relu
        # support other nonlinearities up here?
        self._num_nodes = num_nodes
        self._num_units = num_units
        self._max_diffusion_step = max_diffusion_step
        self._supports = []
        self._use_gc_for_ru = use_gc_for_ru
        
        '''
        Option:
        if filter_type == "laplacian":
            supports.append(utils.calculate_scaled_laplacian(adj_mx, lambda_max=None))
        elif filter_type == "random_walk":
            supports.append(utils.calculate_random_walk_matrix(adj_mx).T)
        elif filter_type == "dual_random_walk":
            supports.append(utils.calculate_random_walk_matrix(adj_mx).T)
            supports.append(utils.calculate_random_walk_matrix(adj_mx.T).T)
        else:
            supports.append(utils.calculate_scaled_laplacian(adj_mx))
        for support in supports:
            self._supports.append(self._build_sparse_matrix(support))
        '''

        self._fc_params = LayerParams(self, 'fc', self.device)
        self._gconv_params = LayerParams(self, 'gconv', self.device)

    @staticmethod
    def _build_sparse_matrix(L):
        L = L.tocoo()
        indices = np.column_stack((L.row, L.col))
        # this is to ensure row-major ordering to equal torch.sparse.sparse_reorder(L)
        indices = indices[np.lexsort((indices[:, 0], indices[:, 1]))]
        L = torch.sparse_coo_tensor(indices.T, L.data, L.shape, device=self.device)
        return L

    def _calculate_random_walk_matrix(self, adj_mx):

        ###adj_mx = adj_mx + torch.eye(int(adj_mx.shape[0])).to(device)
        
        adj_mx = adj_mx + torch.eye(int(adj_mx.shape[-1])).to(self.device)
        
    
        d = torch.sum(adj_mx, 3)
        d_inv = 1. / d
        d_inv = torch.where(torch.isinf(d_inv), torch.zeros(d_inv.shape).to(self.device), d_inv)
        ### d_mat_inv = torch.diag(d_inv)
        d_mat_inv = torch.diag_embed(d_inv)
        
        ### random_walk_mx = torch.mm(d_mat_inv, adj_mx)
        #random_walk_mx = torch.bmm(d_mat_inv, adj_mx)
        random_walk_mx = torch.einsum('abcd,abde->abce', [d_mat_inv, adj_mx])
        
        return random_walk_mx

    def forward(self, inputs, hx, adj):
        """Gated recurrent unit (GRU) with Graph Convolution.
        :param inputs: (B, num_nodes * input_dim)
        :param hx: (B, num_nodes * rnn_units)

        :return
        - Output: A `2-D` tensor with shape `(B, num_nodes * rnn_units)`.
        """
        #### adj_mx = self._calculate_random_walk_matrix(adj).t()
        adj_mx = self._calculate_random_walk_matrix(adj).permute(0,1,3,2)
        output_size = 2 * self._num_units
        if self._use_gc_for_ru:
            fn = self._gconv
        else:
            fn = self._fc
        value = torch.sigmoid(fn(inputs, adj_mx, hx, output_size, bias_start=1.0))
        value = torch.reshape(value, (-1, self._num_nodes, output_size))
        r, u = torch.split(tensor=value, split_size_or_sections=self._num_units, dim=-1)
        r = torch.reshape(r, (-1, self._num_nodes * self._num_units))
        u = torch.reshape(u, (-1, self._num_nodes * self._num_units))

        c = self._gconv(inputs, adj_mx, r * hx, self._num_units)
        if self._activation is not None:
            c = self._activation(c)

        new_state = u * hx + (1.0 - u) * c
        return new_state
    '''
    @staticmethod
    def _concat(x, x_):
        x_ = x_.unsqueeze(0)
        return torch.cat([x, x_], dim=0)
    '''
    @staticmethod
    def _concat(x, x_):
        if x.dim()==x_.dim():
            return torch.cat([x, x_], dim=0)
        else:
            return torch.cat([x.expand(x.size(0),x_.size(1), x.size(1),x.size(2)), x_], dim=0)
    

    def _fc(self, inputs, state, output_size, bias_start=0.0):
        batch_size = inputs.shape[0]
        inputs = torch.reshape(inputs, (batch_size * self._num_nodes, -1))
        state = torch.reshape(state, (batch_size * self._num_nodes, -1))
        inputs_and_state = torch.cat([inputs, state], dim=-1)
        input_size = inputs_and_state.shape[-1]
        weights = self._fc_params.get_weights((input_size, output_size))
        value = torch.sigmoid(torch.matmul(inputs_and_state, weights))
        biases = self._fc_params.get_biases(output_size, bias_start)
        value += biases
        return value

    def _gconv(self, inputs, adj_mx, state, output_size, bias_start=0.0):

        batch_size = inputs.shape[0]
        inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1)) # (64, 207, 2)
        state = torch.reshape(state, (batch_size, self._num_nodes, -1)) # (64, 207, 64)
        inputs_and_state = torch.cat([inputs, state], dim=2) # (64, 207, 66)
        input_size = inputs_and_state.size(2) # 66
        '''
        x = inputs_and_state # x : (64, 207, dim=64+2)
        x0 = x.permute(1, 2, 0)  # x0 : (207, dim=64+2, 64)
        x0 = torch.reshape(x0, shape=[self._num_nodes, input_size * batch_size]) # x0 : (207, 66 * 64)
        x = torch.unsqueeze(x0, 0) # (1,207,4224) = (1, num_nodes, input_size * batch_size) # x : (1, 207, 66*64)
        x0 = torch.reshape(x0, shape=[batch_size, self._num_nodes, input_size]) # x0 : (64, 207, 66)
        '''
        x0 = inputs_and_state # x0 : (64, 207, 66)
        x = x0.permute(1,2,0) # x : (207, 66,64)
        x = torch.reshape(x, shape=[self._num_nodes, input_size * batch_size])  # x : (207, 66,64)
        x = torch.unsqueeze(x,0)  # x : (1, 207, 66,64)
        #x = x0.permute(1,2,0).view(self._num_nodes, -1).unsqueeze(0) 
        # inputs_and_state : (64, 207, dim=64+2)
        # x : (1, 207, 66*64)
        # x0 : (64, 207, 66)
        
        if self._max_diffusion_step == 0:
            pass
        else:
            x1 = adj_mx.matmul(x0)
            x1 = x1.permute(0,2,3,1) # 0m2m1m3
            x1 = torch.reshape(x1, shape=[x1.size(0),self._num_nodes,batch_size*input_size])
            ############# x1 = torch.mm(adj_mx, x0)
            x = self._concat(x, x1)

            x0 = x0.view(x0.size(1),-1)
            for k in range(2, self._max_diffusion_step + 1):
                x2 = 2 * torch.einsum('abcd,abde->abce',  [adj_mx, x1.view(x1.size(0), batch_size, self._num_nodes, input_size)]) 
                #x2 = 2 * torch.einsum('abcd,abde->abce',  [adj_mx,  torch.reshape(x1, shape=[x1.size(0),self._num_nodes, batch_size, input_size]).permute(0,2,1,3)]) 
                #x2 = x2.view(x2.size(0),x2.size(2),-1) - x0
                
                x2 = x2.permute(0,2,3,1) # 0,2,1,3
                x2 = torch.reshape(x2, shape=[x2.size(0),self._num_nodes,batch_size*input_size]) - x0
                ######## x2 = 2 * torch.bmm(adj_mx, x1) - x0
                ######### x2 = 2 * torch.mm(adj_mx, x1) - x0
                x = self._concat(x, x2)

                x1, x0 = x2, x1

            
        ######## num_matrices = self._max_diffusion_step + 1  # Adds for x itself.
        num_matrices = self._max_diffusion_step*adj_mx.size(0) + 1
        x = torch.reshape(x, shape=[num_matrices, self._num_nodes, input_size, batch_size])
        x = x.permute(3, 1, 2, 0)  # (batch_size, num_nodes, input_size, order)
        x = torch.reshape(x, shape=[batch_size * self._num_nodes, input_size * num_matrices])
        weights = self._gconv_params.get_weights((input_size * num_matrices, output_size))
        x = torch.matmul(x, weights)  # (batch_size * self._num_nodes, output_size)
        biases = self._gconv_params.get_biases(output_size, bias_start)
        x += biases
        # Reshape res back to 2D: (batch_size, num_node, state_dim) -> (batch_size, num_node * state_dim)
        final_return = torch.reshape(x, [batch_size, self._num_nodes * output_size])
        return final_return


```



```
import numpy as np
import torch
from lib import utils
#device = torch.device("cuda:3" if torch.cuda.is_available() else "cpu")

class LayerParams:
    def __init__(self, rnn_network: torch.nn.Module, layer_type: str, device):
        self._rnn_network = rnn_network
        self._params_dict = {}
        self._biases_dict = {}
        self._type = layer_type
        self.device =device

    def get_weights(self, shape):
        if shape not in self._params_dict:
            nn_param = torch.nn.Parameter(torch.empty(*shape, device=self.device))
            torch.nn.init.xavier_normal_(nn_param)
            self._params_dict[shape] = nn_param
            self._rnn_network.register_parameter('{}_weight_{}'.format(self._type, str(shape)),
                                                 nn_param)
        return self._params_dict[shape]

    def get_biases(self, length, bias_start=0.0):
        if length not in self._biases_dict:
            biases = torch.nn.Parameter(torch.empty(length, device=self.device))
            torch.nn.init.constant_(biases, bias_start)
            self._biases_dict[length] = biases
            self._rnn_network.register_parameter('{}_biases_{}'.format(self._type, str(length)),
                                                 biases)

        return self._biases_dict[length]


class DCGRUCell(torch.nn.Module):
    def __init__(self, num_units, max_diffusion_step, num_nodes, nonlinearity='tanh',
                 filter_type="laplacian", use_gc_for_ru=True, device='cuda:0'):
        """

        :param num_units:
        :param adj_mx:
        :param max_diffusion_step:
        :param num_nodes:
        :param nonlinearity:
        :param filter_type: "laplacian", "random_walk", "dual_random_walk".
        :param use_gc_for_ru: whether to use Graph convolution to calculate the reset and update gates.
        """

        super().__init__()
        self.device = device
        self._activation = torch.tanh if nonlinearity == 'tanh' else torch.relu
        # support other nonlinearities up here?
        self._num_nodes = num_nodes
        self._num_units = num_units
        self._max_diffusion_step = max_diffusion_step
        self._supports = []
        self._use_gc_for_ru = use_gc_for_ru
        
        '''
        Option:
        if filter_type == "laplacian":
            supports.append(utils.calculate_scaled_laplacian(adj_mx, lambda_max=None))
        elif filter_type == "random_walk":
            supports.append(utils.calculate_random_walk_matrix(adj_mx).T)
        elif filter_type == "dual_random_walk":
            supports.append(utils.calculate_random_walk_matrix(adj_mx).T)
            supports.append(utils.calculate_random_walk_matrix(adj_mx.T).T)
        else:
            supports.append(utils.calculate_scaled_laplacian(adj_mx))
        for support in supports:
            self._supports.append(self._build_sparse_matrix(support))
        '''

        self._fc_params = LayerParams(self, 'fc', self.device)
        self._gconv_params = LayerParams(self, 'gconv', self.device)

    @staticmethod
    def _build_sparse_matrix(L):
        L = L.tocoo()
        indices = np.column_stack((L.row, L.col))
        # this is to ensure row-major ordering to equal torch.sparse.sparse_reorder(L)
        indices = indices[np.lexsort((indices[:, 0], indices[:, 1]))]
        L = torch.sparse_coo_tensor(indices.T, L.data, L.shape, device=self.device)
        return L

    def _calculate_random_walk_matrix(self, adj_mx):

        ###adj_mx = adj_mx + torch.eye(int(adj_mx.shape[0])).to(device)
        
        adj_mx = adj_mx + torch.eye(int(adj_mx.shape[-1])).to(self.device)
        
    
        d = torch.sum(adj_mx, 3)
        d_inv = 1. / d
        d_inv = torch.where(torch.isinf(d_inv), torch.zeros(d_inv.shape).to(self.device), d_inv)
        ### d_mat_inv = torch.diag(d_inv)
        d_mat_inv = torch.diag_embed(d_inv)
        
        ### random_walk_mx = torch.mm(d_mat_inv, adj_mx)
        #random_walk_mx = torch.bmm(d_mat_inv, adj_mx)
        random_walk_mx = torch.einsum('abcd,abde->abce', [d_mat_inv, adj_mx])
        
        return random_walk_mx

    def forward(self, inputs, hx, adj):
        """Gated recurrent unit (GRU) with Graph Convolution.
        :param inputs: (B, num_nodes * input_dim)
        :param hx: (B, num_nodes * rnn_units)

        :return
        - Output: A `2-D` tensor with shape `(B, num_nodes * rnn_units)`.
        """
        #### adj_mx = self._calculate_random_walk_matrix(adj).t()
        adj_mx = self._calculate_random_walk_matrix(adj).permute(0,1,3,2)
        output_size = 2 * self._num_units
        if self._use_gc_for_ru:
            fn = self._gconv
        else:
            fn = self._fc
        value = torch.sigmoid(fn(inputs, adj_mx, hx, output_size, bias_start=1.0))
        value = torch.reshape(value, (-1, self._num_nodes, output_size))
        r, u = torch.split(tensor=value, split_size_or_sections=self._num_units, dim=-1)
        r = torch.reshape(r, (-1, self._num_nodes * self._num_units))
        u = torch.reshape(u, (-1, self._num_nodes * self._num_units))

        c = self._gconv(inputs, adj_mx, r * hx, self._num_units)
        if self._activation is not None:
            c = self._activation(c)

        new_state = u * hx + (1.0 - u) * c
        return new_state
    '''
    @staticmethod
    def _concat(x, x_):
        x_ = x_.unsqueeze(0)
        return torch.cat([x, x_], dim=0)
    '''
    @staticmethod
    def _concat(x, x_):
        if x.dim()==x_.dim():
            return torch.cat([x, x_], dim=0)
        else:
            return torch.cat([x.expand(x.size(0),x_.size(1), x.size(1),x.size(2)), x_], dim=0)
    

    def _fc(self, inputs, state, output_size, bias_start=0.0):
        batch_size = inputs.shape[0]
        inputs = torch.reshape(inputs, (batch_size * self._num_nodes, -1))
        state = torch.reshape(state, (batch_size * self._num_nodes, -1))
        inputs_and_state = torch.cat([inputs, state], dim=-1)
        input_size = inputs_and_state.shape[-1]
        weights = self._fc_params.get_weights((input_size, output_size))
        value = torch.sigmoid(torch.matmul(inputs_and_state, weights))
        biases = self._fc_params.get_biases(output_size, bias_start)
        value += biases
        return value

    def _gconv(self, inputs, adj_mx, state, output_size, bias_start=0.0):

        batch_size = inputs.shape[0]
        inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1)) # (64, 207, dim=2)
        state = torch.reshape(state, (batch_size, self._num_nodes, -1)) # (64, 207, dim=64)
        inputs_and_state = torch.cat([inputs, state], dim=2) # (64, 207, dim=64+2)
        input_size = inputs_and_state.size(2) # 66

        x = inputs_and_state # x : (64, 207, dim=64+2)
        x0 = x.permute(1, 2, 0)  # x0 : (207, dim=64+2, 64)
        x0 = torch.reshape(x0, shape=[self._num_nodes, input_size * batch_size]) # x0 : (207, 66 * 64)
        x = torch.unsqueeze(x0, 0) # (1,207,4224) = (1, num_nodes, input_size * batch_size) # x : (1, 207, 66*64)
        x0 = torch.reshape(x0, shape=[batch_size, self._num_nodes, input_size]) # x0 : (64, 207, 66)
        
        # x : (64, 207, dim=64+2)
        # x : (1, 207, 66*64)
        # x0 : (64, 207, 66)
        if self._max_diffusion_step == 0:
            pass
        else:
            x1 = adj_mx.matmul(x0)
            x1 = x1.view(x1.shape[0],x1.shape[2],-1)
            ############# x1 = torch.mm(adj_mx, x0)
            x = self._concat(x, x1)

            x0 = x0.view(x0.size(1),-1)
            for k in range(2, self._max_diffusion_step + 1):
                #random_walk_mx = torch.einsum('abcd,abde->abce', [adj_mx, x1])

                x2 = 2 * torch.einsum('abcd,abde->abce', 
                                      [adj_mx, x1.view(x1.size(0), batch_size, self._num_nodes, input_size)]) 
                x2 = x2.view(x2.size(0),x2.size(2),-1) - x0
                ######## x2 = 2 * torch.bmm(adj_mx, x1) - x0
                ######### x2 = 2 * torch.mm(adj_mx, x1) - x0
                x = self._concat(x, x2)

                x1, x0 = x2, x1

            
        ######## num_matrices = self._max_diffusion_step + 1  # Adds for x itself.
        num_matrices = self._max_diffusion_step*adj_mx.size(0) + 1
        x = torch.reshape(x, shape=[num_matrices, self._num_nodes, input_size, batch_size])
        x = x.permute(3, 1, 2, 0)  # (batch_size, num_nodes, input_size, order)
        x = torch.reshape(x, shape=[batch_size * self._num_nodes, input_size * num_matrices])
        weights = self._gconv_params.get_weights((input_size * num_matrices, output_size))
        x = torch.matmul(x, weights)  # (batch_size * self._num_nodes, output_size)
        biases = self._gconv_params.get_biases(output_size, bias_start)
        x += biases
        # Reshape res back to 2D: (batch_size, num_node, state_dim) -> (batch_size, num_node * state_dim)
        final_return = torch.reshape(x, [batch_size, self._num_nodes * output_size])
        return final_return

```

