---
title: MLLM Benchmarks
categories: [MULT, LLM, NLP, CV]
tags: []
excerpt: MME, MMMU, GQA, ChartQA, POPE, NoCaps, TextVQA
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# MLLM Benchmarks

1. **MME**
   - **Multi-modal Model Evaluation (MME)**
   - 대형 멀티모달 모델의 성능을 평가하기 위한 벤치마크
   - 다양한 멀티모달 태스크(예: 이미지-텍스트 이해, 논리적 추론)에 대해 모델의 한계를 분석
   - https://arxiv.org/pdf/2306.13394
2. **MMMU**
   - **Massive Multi-discipline Multimodal Understanding (MMMU)**
   - **다양한 분야의 문제 포함:** MMMU는 예술 및 디자인, 비즈니스, 과학, 건강 및 의학, 인문사회과학, 기술 및 공학 등 6개의 주요 분야를 아우르는 30개의 주제와 183개의 세부 분야에서 수집된 11,500개의 멀티모달 질문을 포함
   - **다양한 이미지 유형:** 차트, 다이어그램, 지도, 표, 악보, 화학 구조 등 32가지의 다양한 이미지 유형을 포함하여, 모델의 시각적 이해와 추론 능력을 종합적으로 평가
   - https://arxiv.org/pdf/2311.16502
3. **GQA**
   - **Graph Question Answering (GQA)**
   - 구조화된 장면 그래프(Scene Graph)를 활용한 비주얼 QA 데이터셋
   - 객체 간의 관계를 이해하고 논리적으로 답변하는 능력을 테스트
   - https://arxiv.org/pdf/1902.09506
4. **ChartQA**
   - **Chart Question Answering (CQA)**
   - 차트(Chart)와 표(Table)를 포함하는 QA 데이터셋
   - 시각적 데이터를 해석하고 질문에 답변하는 능력을 평가
   - https://arxiv.org/pdf/2203.10244
6. **NoCaps**
   - **Novel Object Captioning (NoCaps)**
   - 기존 캡션 데이터셋에 없는 새로운 객체(novel objects)를 캡션에 포함하는 데이터셋
   - Open Vocabulary Image Captioning 성능을 평가
7. **TextVQA**
   - **Text-based Visual Question Answering (TextVQA)**
   - 이미지 내 OCR 텍스트를 활용하여 질문에 답하는 비주얼 QA 데이터셋
   - 일반적인 VQA 모델이 아닌, OCR과 자연어 이해를 결합한 모델 성능을 측정
