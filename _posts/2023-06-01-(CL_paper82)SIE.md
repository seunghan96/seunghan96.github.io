---
title: (paper 82) Self-supervised learning of Split Invariant Equivariant representations
categories: [CV, CL]
tags: []
excerpt: 2023
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
# SSL of Split Invariant Equivariant representations

<br>

## Contents

0. Abstract
1. 


<br>

# 0. Abstract

Towards learning **INVARIANT** or **EQUIVARIANT** representations with SSL

Evaluation

- **Invariant** methods : on **LARGE** scale datasets

- **Equivariant** methods : in **SMALLER**, more controlled, settings. 

![figure2](/assets/img/cl/img206.png)

<br>

Bridging the gap between the two

$\rightarrow$ to learn more diverse representations that are suitable for a wide range of tasks. 

<br>

New dataset : ***3DIEBench***

- consisting of renderings from 3D models over 55 classes
-  more than 2.5 million images 
  - full control on the transformations applied to the objects. 

<br>

**Predictor architecture** 

- based on hypernetworks to learn equivariant representations with no possible collapse to invariance. 

<br>

**SIE (Split Invariant Equivariant)**  : combines the hypernetwork based predictor,

with representations split in 2 parts

- (1) invariant
- (2) equivariant

<br>

# 1. Introduction

SSL of image representations … catch up SL baselines

Most of the works : **Joint-embedding framework**

= **2 augmented views** from a source image. 

<br>

These ***invariance based approaches*** have been very successful for classification when using augmentations that preserve the semantic information of the image,  ***this removal of information may be problematic for downstream tasks***.

-  ex) color-jitter removes color information $\rightarrow$ Bad for flower classification (Lee et al., 2021a). 

$\rightarrow$ motivates the goal of introducing equivariance to representations

- to learn more general representations for more varied downstream tasks. 

<br>

Previous works : ways to enrich usually invariant representations,

**by keeping information about the augmentations**

- ex) use subsets of augmentations to construct partially invariant representations

- ex) predicting rotations

- ex) preserving augmentation strengths in the representations

- ex) predicting all of the augmentation parameters

  - do not give a way to transform the representations directly even if the information is present in them

    $\rightarrow$ cannot be considered as equivariant. 

<br>

Learning **equivariant** representations :

$\rightarrow$ ***requires being able to predict a representation from another in latent space***,

- can be done by a simple prediction head

  ( ex. reconstruction task )

<br>

***(1) Parameter prediction based methods***

- have been done on ImageNet
  - no clear equivariant task and where augmentations happen in pixel space with no loss of information. 

<br>

***(2) Equivariance based methods*** 

- have been used on simpler synthetic datasets 
  - where we can evaluate equivariance
  - but where it is hard to evaluate other CV tasks ( ex. classification )

<br>

To bridge the gap between those two 

- (a) Introduce NEW datsaset, **3DIEBench**
- (b) Introduce a **hypernetwork based predictor**

<br>

## (1) 3DIEBench

- renderings of over fifty-thousand 3D objects 
- can study both
  - equivariance related task (3D rotation prediction)
  - invariant related task (image classification). 
- allows us to measure more precisely how invariant classical SSL are
- Shows limitations of existing equivariant approaches where predictors often collapse to the identity, leading to invariant representations. 

<br>

## (2) Hypernetwork based predictor

- avoids a collapse to the identity by design
- show how it can outperform existing predictor architectures. 

<br>

Also show that by **separating the representations** in **(a) equivariant** and **(b) invariant** parts, 

$\rightarrow$ can significantly improve performance on equivariance related tasks!!

<br>

Also analyze qualitatively the learned split invariant-equivariant representations 

$\rightarrow$ see that all **invariant information is not discarded from the equivariant part**

& and that the predictor offers a meaningful way to steer the latent space.

<br>

# 2. Related Works

## (1) Invariant SSL

Two main families of methods

-  (1) CL

  - mostly rely on the InfoNCE 

  - clustering variant of contrastive learning

    ( between cluster centroids instead of samples )

- (2) Non CL 

  - bringing together embeddings of positive samples, similar to contrastive learning. 
  - key difference ( with CL ) : lies in how those methods prevent a representational collapse
    - (CL) pushes away negative
    - (Non CL) the criterion considers the embeddings as a whole & encourages information content maximization
      - ex)  by regularizing the empirical covariance matrix of the embeddings. 

- Thy have been shown to lead to very similar representations

<br>

## (2) Introducing Equivariance in Invariant SSL

( Invariant SSL : focus on learning representations that are invariant to augmentations )

$\leftrightarrow$ Tried to learn representations where information about certain transformations is preserved. 

- ex) predicting the augmentation parameters
- ex) introducing other transformations such as image rotations 
- ex) preserving the augmentations’ strength in the representations 

$\rightarrow$  these approaches*** cannot be characterized as equivariant*** ,

since they offer no meaningful way to apply transformations in latent space.

<br>

## (3) Equivariant Representation Learning

Autoencoders

- transforming autoencoders
- Homeomorphic VAEs
- EquiMod (Devillers & Lefort, 2022) or SEN (Park et al., 2022) 
  - included a predictor that enables the steering of representations in latent space, without requiring reconstruction. 
  - Forms the basis for our comparisons. 

<br>

(Marchetti et al., 2022)

- representations are split in class and pose ( i.e. invariant and equivariant )
- assumes a simple equivariant latent space 
  - the group action is the same as in the underlying data, e.g. 3 dimensions to represent pose. 
  - assumes prior knowledge on the group of transformations
- This paper : aim at deriving a more general predictor architecture with no such priors

<br>

# 3. 3DIEBench: A new benchmark for invariant-equivariant SSL

### Problems with previous datasets

Datasets to evaluate …

- Equivariance : due to the need to control how transformations are applied 

- Invariance : limited in the sense that position and shape of the objects in these dataset can not be parameterized by controllable transformations

  ( = only pixel-level transformations can be applied )

<br>

Introduce a new dataset, ***3D Invariant Equivariant Benchmark (3DIEBench)***

- Bridge the gap between the two
  - Not trivial for an invariant task (image classification) 
  - Still have control on the parameter of the scene and the objects within it to learn meaningful equivariant representations. 
- Use renderings of 3D objects from the subset of ShapeNetCore (Chang et al., 2015) originating from 3d Warehouse (Trimble Inc). 
- \# of datasets :  total 52472 objects spread across 55 classes. 

<br>

Details : 

- Adjust various factors of variations

  ( ex. object rotation, the lighting color, or the floor color )

- Focus on learning representations that are …

  - equivariant w.r.t object rotations of arbitrary strength 

- constrain the range of rotations to Euler angles between $-\frac{\pi}{2}$ ~ $\frac{\pi}{2}$

  - arbitrary rotations on arbitrary objects : make the task close to impossible

- or each object, we generate 50 random values for the factors of variation

  $\rightarrow$ total of around 2.5 million images.

<br>

![figure2](/assets/img/cl/img207.png)

<br>

# 4. Creating a general predictor

## (1) Background and notation

